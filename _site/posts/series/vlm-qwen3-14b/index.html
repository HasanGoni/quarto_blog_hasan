<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hasan">
<meta name="dcterms.date" content="2025-05-03">

<title>Hasan’s Data Science &amp; AI Blog - Hands-On with Qwen3-14B: A Reasoning-Centric LLM for Data Scientists</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://hypothes.is/embed.js"></script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hasan’s Data Science &amp; AI Blog - Hands-On with Qwen3-14B: A Reasoning-Centric LLM for Data Scientists">
<meta property="og:description" content="">
<meta property="og:image" content="https://hasangoni.quarto.pub/hasan-blog-post/posts/series/vlm-qwen3-14b/qwen3-14b.png">
<meta property="og:site-name" content="Hasan's Data Science &amp; AI Blog">
<meta property="og:image:height" content="2048">
<meta property="og:image:width" content="2048">
<meta name="twitter:title" content="Hasan’s Data Science &amp; AI Blog - Hands-On with Qwen3-14B: A Reasoning-Centric LLM for Data Scientists">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://hasangoni.quarto.pub/hasan-blog-post/posts/series/vlm-qwen3-14b/qwen3-14b.png">
<meta name="twitter:image-height" content="2048">
<meta name="twitter:image-width" content="2048">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hasan’s Data Science &amp; AI Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-series" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Series</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-series">    
        <li>
    <a class="dropdown-item" href="../../../posts/series/data-science-steps.html" rel="" target="">
 <span class="dropdown-text">Data Science Steps</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/computer-vision-with-pytorch.qmd" rel="" target="">
 <span class="dropdown-text">Computer Vision</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/vlm.html" rel="" target="">
 <span class="dropdown-text">VLM Series</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/anomaly-detection/index.html" rel="" target="">
 <span class="dropdown-text">Anomaly Detection</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../categories.html" rel="" target="">
 <span class="menu-text">Categories</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../tags.html" rel="" target="">
 <span class="menu-text">Tags</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/HasanGoni" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/hasangoni" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../posts/series/vlm.html">VLM Series</a></li><li class="breadcrumb-item"><a href="../../../posts/series/vlm-qwen3-14b/index.html">Qwen3-14B</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Hands-On with Qwen3-14B: A Reasoning-Centric LLM for Data Scientists</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">LLM</div>
                <div class="quarto-category">Reasoning</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">HuggingFace</div>
                <div class="quarto-category">Colab</div>
                <div class="quarto-category">Transformers</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Hasan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 3, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">May 3, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Data Science</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/data-science-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps Series</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part01/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 01</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part02/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 02</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part03/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 03</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part04/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 04</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part05/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 05</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part06/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 06</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Computer Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">posts/series/computer-vision-with-pytorch.qmd</span>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Anomaly Detection</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/anomaly-detection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/anomaly-detection/finding-the-oddballs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Finding the Oddballs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">VLM Series</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/vlm-qwen3-14b/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Qwen3-14B</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-what-if-llms-could-actually-reason" id="toc-introduction-what-if-llms-could-actually-reason" class="nav-link active" data-scroll-target="#introduction-what-if-llms-could-actually-reason"><span class="header-section-number">0.1</span> Introduction: What If LLMs Could <em>Actually</em> Reason?</a></li>
  <li><a href="#model-and-tokenizer-loading" id="toc-model-and-tokenizer-loading" class="nav-link" data-scroll-target="#model-and-tokenizer-loading"><span class="header-section-number">0.2</span> Model and Tokenizer Loading</a></li>
  <li><a href="#example-the-reasoning-difference" id="toc-example-the-reasoning-difference" class="nav-link" data-scroll-target="#example-the-reasoning-difference"><span class="header-section-number">0.3</span> Example: The Reasoning Difference</a></li>
  <li><a href="#system-prompts-and-personality" id="toc-system-prompts-and-personality" class="nav-link" data-scroll-target="#system-prompts-and-personality"><span class="header-section-number">0.4</span> System Prompts and Personality</a></li>
  <li><a href="#fine-tuning-and-customization-optional" id="toc-fine-tuning-and-customization-optional" class="nav-link" data-scroll-target="#fine-tuning-and-customization-optional"><span class="header-section-number">0.5</span> Fine-Tuning and Customization (Optional)</a></li>
  <li><a href="#performance-on-data-science-tasks" id="toc-performance-on-data-science-tasks" class="nav-link" data-scroll-target="#performance-on-data-science-tasks"><span class="header-section-number">0.6</span> Performance on Data Science Tasks</a></li>
  <li><a href="#tldr" id="toc-tldr" class="nav-link" data-scroll-target="#tldr"><span class="header-section-number">0.7</span> TL;DR</a></li>
  <li><a href="#bonus-prompt-engineering-tips" id="toc-bonus-prompt-engineering-tips" class="nav-link" data-scroll-target="#bonus-prompt-engineering-tips"><span class="header-section-number">0.8</span> Bonus: Prompt Engineering Tips</a></li>
  <li><a href="#why-qwen3-14b" id="toc-why-qwen3-14b" class="nav-link" data-scroll-target="#why-qwen3-14b"><span class="header-section-number">0.9</span> Why Qwen3-14B?</a></li>
  <li><a href="#setup-running-a-14b-model-in-google-colab" id="toc-setup-running-a-14b-model-in-google-colab" class="nav-link" data-scroll-target="#setup-running-a-14b-model-in-google-colab"><span class="header-section-number">0.10</span> Setup: Running a 14B Model in Google Colab?</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps"><span class="header-section-number">0.11</span> Next Steps</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">0.12</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction-what-if-llms-could-actually-reason" class="level2" data-number="0.1">
<h2 data-number="0.1" class="anchored" data-anchor-id="introduction-what-if-llms-could-actually-reason"><span class="header-section-number">0.1</span> Introduction: What If LLMs Could <em>Actually</em> Reason?</h2>
<p>As data scientists, we constantly move between raw data and real-world decisions. Whether you’re explaining anomalies, generating insights, or deploying models, reasoning is core to our work. But most large language models (LLMs) are still <em>parrots</em>—pattern matchers without deeper understanding.</p>
<p>Enter <strong>Qwen3-14B</strong>, Alibaba’s newest open-source model. It’s not just another massive transformer—it’s been designed and instruction-tuned with <em>reasoning</em> and <em>conversation</em> in mind. And thanks to the amazing open-source work by <strong>Unsloth</strong>, we get a full-featured Colab notebook that lets us try it right now, without needing a GPU cluster.</p>
<p>This post is a walkthrough of that notebook:<br>
<a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb">Colab Notebook: Qwen3 (14B) - Reasoning &amp; Conversational</a><br>
We’ll unpack each section, explain how things work, and give you hands-on examples to help you integrate Qwen3 into your own workflow.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post is part of the <a href="../../../posts/series/vlm.html">VLM Series</a>. Feedback and questions are welcome!</p>
</div>
</div>
</section>
<section id="model-and-tokenizer-loading" class="level2" data-number="0.2">
<h2 data-number="0.2" class="anchored" data-anchor-id="model-and-tokenizer-loading"><span class="header-section-number">0.2</span> Model and Tokenizer Loading</h2>
<p>Let’s get started by loading the model and tokenizer using HuggingFace Transformers:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb1-2"><a href="#cb1-2"></a>model_id <span class="op">=</span> <span class="st">"unsloth/qwen2-14b-chat-gptq"</span></span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb1-5"><a href="#cb1-5"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_id, device_map<span class="op">=</span><span class="st">"auto"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="example-the-reasoning-difference" class="level2" data-number="0.3">
<h2 data-number="0.3" class="anchored" data-anchor-id="example-the-reasoning-difference"><span class="header-section-number">0.3</span> Example: The Reasoning Difference</h2>
<p>To see the power of Qwen3, consider this classic chain-of-thought task:</p>
<p><strong>Prompt:</strong></p>
<p>Alice has 3 apples. She gives 1 to Bob, then buys 5 more. How many apples does she have?</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>prompt <span class="op">=</span> <span class="st">"Alice has 3 apples. She gives 1 to Bob, then buys 5 more. How many apples does she have?"</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Expected Output:</strong></p>
<p>Let’s break it down. Alice starts with 3 apples. She gives 1 to Bob → 3 - 1 = 2. She buys 5 more → 2 + 5 = 7. Answer: 7 apples.</p>
</section>
<section id="system-prompts-and-personality" class="level2" data-number="0.4">
<h2 data-number="0.4" class="anchored" data-anchor-id="system-prompts-and-personality"><span class="header-section-number">0.4</span> System Prompts and Personality</h2>
<p>Qwen3 supports “system prompts” that define tone and behavior:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>prompt <span class="op">=</span> <span class="st">"&lt;|im_start|&gt;system</span><span class="ch">\n</span><span class="st">You are a sarcastic data science tutor.&lt;|im_end|&gt;</span><span class="ch">\n</span><span class="st">&lt;|im_start|&gt;user</span><span class="ch">\n</span><span class="st">Why is my model overfitting?&lt;|im_end|&gt;"</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Output:</strong></p>
<p>Oh, I don’t know… maybe because you fed it every single variable and forgot cross-validation? Classic!</p>
</section>
<section id="fine-tuning-and-customization-optional" class="level2" data-number="0.5">
<h2 data-number="0.5" class="anchored" data-anchor-id="fine-tuning-and-customization-optional"><span class="header-section-number">0.5</span> Fine-Tuning and Customization (Optional)</h2>
<p>Unsloth supports fine-tuning with LoRA or QLoRA. You could:</p>
<ul>
<li>Feed your company’s docs and fine-tune a chatbot</li>
<li>Inject private datasets and business-specific reasoning</li>
<li>Modify for multi-modal pipelines</li>
</ul>
<p><em>Not covered directly in the notebook—see <a href="../../../posts/series/vlm-qwen3-14b/finetune-qwen3-14b.html">the next blog post for a tutorial</a>!</em></p>
</section>
<section id="performance-on-data-science-tasks" class="level2" data-number="0.6">
<h2 data-number="0.6" class="anchored" data-anchor-id="performance-on-data-science-tasks"><span class="header-section-number">0.6</span> Performance on Data Science Tasks</h2>
<p>Qwen3-14B shines at:</p>
<ul>
<li>EDA Explanations</li>
<li>Math QA</li>
<li>Prompt Chaining</li>
<li>Code Review</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>prompt <span class="op">=</span> <span class="st">"Explain what this code does:</span><span class="ch">\n</span><span class="st">df.groupby('region')['sales'].mean().sort_values(ascending=False)"</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb4-3"><a href="#cb4-3"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Answer:</strong></p>
<p>This groups the dataframe df by the ‘region’ column, computes the mean sales for each group, and sorts the results in descending order.</p>
</section>
<section id="tldr" class="level2" data-number="0.7">
<h2 data-number="0.7" class="anchored" data-anchor-id="tldr"><span class="header-section-number">0.7</span> TL;DR</h2>
<p>If you’re a data scientist looking for:</p>
<ul>
<li>Open, commercial-friendly LLMs</li>
<li>Strong reasoning abilities</li>
<li>Easy deployment via Colab</li>
</ul>
<p>Qwen3-14B is worth your time.</p>
</section>
<section id="bonus-prompt-engineering-tips" class="level2" data-number="0.8">
<h2 data-number="0.8" class="anchored" data-anchor-id="bonus-prompt-engineering-tips"><span class="header-section-number">0.8</span> Bonus: Prompt Engineering Tips</h2>
<ul>
<li><strong>Be Explicit:</strong> Add “Step-by-step reasoning” to prompts.</li>
<li><strong>Use System Prompts:</strong> Tailor tone and format.</li>
<li><strong>Limit Token Budget:</strong> Keep max tokens reasonable for speed + clarity.</li>
</ul>
<hr>
</section>
<section id="why-qwen3-14b" class="level2" data-number="0.9">
<h2 data-number="0.9" class="anchored" data-anchor-id="why-qwen3-14b"><span class="header-section-number">0.9</span> Why Qwen3-14B?</h2>
<p>Before diving into code, here’s what makes Qwen3 interesting:</p>
<ul>
<li><strong>Size and Performance:</strong> 14B parameters—big enough to be powerful, small enough to run locally with quantization.</li>
<li><strong>Open Weight License:</strong> Truly open, including for commercial use.</li>
<li><strong>Reasoning Optimized:</strong> Trained with a focus on multi-step logical tasks, coding, math, and chain-of-thought.</li>
</ul>
</section>
<section id="setup-running-a-14b-model-in-google-colab" class="level2" data-number="0.10">
<h2 data-number="0.10" class="anchored" data-anchor-id="setup-running-a-14b-model-in-google-colab"><span class="header-section-number">0.10</span> Setup: Running a 14B Model in Google Colab?</h2>
<p>The notebook from Unsloth uses the HuggingFace <code>transformers</code> library, <code>AutoGPTQ</code>, and 4-bit quantized weights. That means we can run Qwen3-14B on a free Colab GPU (ideally a T4 or A100) without melting our RAM.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="op">!</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet transformers accelerate auto<span class="op">-</span>gptq</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Run the cell above in your Colab notebook before anything else.</li>
<li>For best results, use a GPU runtime (T4 or A100 preferred).</li>
</ul>
</div>
</div>
</section>
<section id="next-steps" class="level2" data-number="0.11">
<h2 data-number="0.11" class="anchored" data-anchor-id="next-steps"><span class="header-section-number">0.11</span> Next Steps</h2>
<ul>
<li><a href="../../../posts/series/vlm.html">Back to VLM Series Overview</a></li>
<li><a href="../../../posts/series/vlm-qwen3-14b/finetune-qwen3-14b.html">Fine-Tuning Qwen3-14B with Unsloth (next post)</a></li>
<li>Try the <a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb">Colab Notebook</a></li>
</ul>
</section>
<section id="references" class="level2" data-number="0.12">
<h2 data-number="0.12" class="anchored" data-anchor-id="references"><span class="header-section-number">0.12</span> References</h2>
<ol type="1">
<li><a href="https://huggingface.co/Qwen/Qwen1.5-14B">Qwen3-14B on HuggingFace</a></li>
<li><a href="https://arxiv.org/abs/2403.05530">Qwen3-14B Paper</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb">Unsloth Qwen3-14B Colab Notebook</a></li>
<li><a href="../../../posts/series/vlm.html">VLM Series Overview</a></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This post is part of the <a href="../../../posts/series/vlm.html">VLM Series</a>. Feedback and questions are welcome!</p>
</div>
</div>


<!-- -->

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>CC BY-NC-SA 4.0</div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{2025,
  author = {, Hasan},
  title = {Hands-On with {Qwen3-14B:} {A} {Reasoning-Centric} {LLM} for
    {Data} {Scientists}},
  date = {2025-05-03},
  url = {https://hasangoni.quarto.pub/hasan-blog-post/posts/series/vlm-qwen3-14b},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Hasan. 2025. <span>“Hands-On with Qwen3-14B: A Reasoning-Centric LLM for
Data Scientists.”</span> May 3, 2025. <a href="https://hasangoni.quarto.pub/hasan-blog-post/posts/series/vlm-qwen3-14b">https://hasangoni.quarto.pub/hasan-blog-post/posts/series/vlm-qwen3-14b</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="yourusername/quarto_blog_hasan" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<script src="https://giscus.app/client.js" data-repo="HasanGoni/quarto_blog_hasan" data-repo-id="" data-category="General" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="an">title:</span><span class="co"> "Hands-On with Qwen3-14B: A Reasoning-Centric LLM for Data Scientists"</span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="an">author:</span><span class="co"> "Hasan"</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="an">date:</span><span class="co"> 2025-05-03</span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="an">categories:</span><span class="co"> [AI, LLM, Reasoning, NLP, HuggingFace, Colab, Transformers]</span></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="an">tags:</span><span class="co"> [Qwen3, HuggingFace Transformers, Colab, Instruction Tuning, Conversational AI]</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="an">image:</span><span class="co"> "qwen3-14b.png"</span></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="an">series:</span></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="co">  name: "VLM Series"</span></span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="co">  number: 1</span></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="an">format:</span></span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="co">  html: default</span></span>
<span id="cb6-14"><a href="#cb6-14"></a><span class="co">---</span></span>
<span id="cb6-15"><a href="#cb6-15"></a></span>
<span id="cb6-16"><a href="#cb6-16"></a><span class="fu">## Introduction: What If LLMs Could *Actually* Reason?</span></span>
<span id="cb6-17"><a href="#cb6-17"></a></span>
<span id="cb6-18"><a href="#cb6-18"></a>As data scientists, we constantly move between raw data and real-world decisions. Whether you're explaining anomalies, generating insights, or deploying models, reasoning is core to our work. But most large language models (LLMs) are still *parrots*—pattern matchers without deeper understanding.</span>
<span id="cb6-19"><a href="#cb6-19"></a></span>
<span id="cb6-20"><a href="#cb6-20"></a>Enter **Qwen3-14B**, Alibaba's newest open-source model. It's not just another massive transformer—it's been designed and instruction-tuned with *reasoning* and *conversation* in mind. And thanks to the amazing open-source work by **Unsloth**, we get a full-featured Colab notebook that lets us try it right now, without needing a GPU cluster.</span>
<span id="cb6-21"><a href="#cb6-21"></a></span>
<span id="cb6-22"><a href="#cb6-22"></a>This post is a walkthrough of that notebook:  </span>
<span id="cb6-23"><a href="#cb6-23"></a><span class="co">[</span><span class="ot">Colab Notebook: Qwen3 (14B) - Reasoning &amp; Conversational</span><span class="co">]</span>(https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb)  </span>
<span id="cb6-24"><a href="#cb6-24"></a>We'll unpack each section, explain how things work, and give you hands-on examples to help you integrate Qwen3 into your own workflow.</span>
<span id="cb6-25"><a href="#cb6-25"></a></span>
<span id="cb6-26"><a href="#cb6-26"></a>:::{.callout-tip}</span>
<span id="cb6-27"><a href="#cb6-27"></a>This post is part of the <span class="co">[</span><span class="ot">VLM Series</span><span class="co">](../vlm.qmd)</span>. Feedback and questions are welcome!</span>
<span id="cb6-28"><a href="#cb6-28"></a>:::</span>
<span id="cb6-29"><a href="#cb6-29"></a></span>
<span id="cb6-30"><a href="#cb6-30"></a><span class="fu">## Model and Tokenizer Loading</span></span>
<span id="cb6-31"><a href="#cb6-31"></a></span>
<span id="cb6-32"><a href="#cb6-32"></a>Let's get started by loading the model and tokenizer using HuggingFace Transformers:</span>
<span id="cb6-33"><a href="#cb6-33"></a></span>
<span id="cb6-34"><a href="#cb6-34"></a><span class="in">```python</span></span>
<span id="cb6-35"><a href="#cb6-35"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb6-36"><a href="#cb6-36"></a>model_id <span class="op">=</span> <span class="st">"unsloth/qwen2-14b-chat-gptq"</span></span>
<span id="cb6-37"><a href="#cb6-37"></a></span>
<span id="cb6-38"><a href="#cb6-38"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb6-39"><a href="#cb6-39"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_id, device_map<span class="op">=</span><span class="st">"auto"</span>, trust_remote_code<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-40"><a href="#cb6-40"></a><span class="in">```</span></span>
<span id="cb6-41"><a href="#cb6-41"></a></span>
<span id="cb6-42"><a href="#cb6-42"></a><span class="fu">## Example: The Reasoning Difference</span></span>
<span id="cb6-43"><a href="#cb6-43"></a></span>
<span id="cb6-44"><a href="#cb6-44"></a>To see the power of Qwen3, consider this classic chain-of-thought task:</span>
<span id="cb6-45"><a href="#cb6-45"></a></span>
<span id="cb6-46"><a href="#cb6-46"></a>**Prompt:**</span>
<span id="cb6-47"><a href="#cb6-47"></a></span>
<span id="cb6-48"><a href="#cb6-48"></a>Alice has 3 apples. She gives 1 to Bob, then buys 5 more. How many apples does she have?</span>
<span id="cb6-49"><a href="#cb6-49"></a></span>
<span id="cb6-50"><a href="#cb6-50"></a><span class="in">```python</span></span>
<span id="cb6-51"><a href="#cb6-51"></a>prompt <span class="op">=</span> <span class="st">"Alice has 3 apples. She gives 1 to Bob, then buys 5 more. How many apples does she have?"</span></span>
<span id="cb6-52"><a href="#cb6-52"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb6-53"><a href="#cb6-53"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb6-54"><a href="#cb6-54"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb6-55"><a href="#cb6-55"></a><span class="in">```</span></span>
<span id="cb6-56"><a href="#cb6-56"></a></span>
<span id="cb6-57"><a href="#cb6-57"></a>**Expected Output:**</span>
<span id="cb6-58"><a href="#cb6-58"></a></span>
<span id="cb6-59"><a href="#cb6-59"></a>Let's break it down.</span>
<span id="cb6-60"><a href="#cb6-60"></a>Alice starts with 3 apples.</span>
<span id="cb6-61"><a href="#cb6-61"></a>She gives 1 to Bob → 3 - 1 = 2.</span>
<span id="cb6-62"><a href="#cb6-62"></a>She buys 5 more → 2 + 5 = 7.</span>
<span id="cb6-63"><a href="#cb6-63"></a>Answer: 7 apples.</span>
<span id="cb6-64"><a href="#cb6-64"></a></span>
<span id="cb6-65"><a href="#cb6-65"></a><span class="fu">## System Prompts and Personality</span></span>
<span id="cb6-66"><a href="#cb6-66"></a></span>
<span id="cb6-67"><a href="#cb6-67"></a>Qwen3 supports "system prompts" that define tone and behavior:</span>
<span id="cb6-68"><a href="#cb6-68"></a></span>
<span id="cb6-69"><a href="#cb6-69"></a><span class="in">```python</span></span>
<span id="cb6-70"><a href="#cb6-70"></a>prompt <span class="op">=</span> <span class="st">"&lt;|im_start|&gt;system</span><span class="ch">\n</span><span class="st">You are a sarcastic data science tutor.&lt;|im_end|&gt;</span><span class="ch">\n</span><span class="st">&lt;|im_start|&gt;user</span><span class="ch">\n</span><span class="st">Why is my model overfitting?&lt;|im_end|&gt;"</span></span>
<span id="cb6-71"><a href="#cb6-71"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb6-72"><a href="#cb6-72"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb6-73"><a href="#cb6-73"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb6-74"><a href="#cb6-74"></a><span class="in">```</span></span>
<span id="cb6-75"><a href="#cb6-75"></a></span>
<span id="cb6-76"><a href="#cb6-76"></a>**Output:**</span>
<span id="cb6-77"><a href="#cb6-77"></a></span>
<span id="cb6-78"><a href="#cb6-78"></a>Oh, I don't know... maybe because you fed it every single variable and forgot cross-validation? Classic!</span>
<span id="cb6-79"><a href="#cb6-79"></a></span>
<span id="cb6-80"><a href="#cb6-80"></a><span class="fu">## Fine-Tuning and Customization (Optional)</span></span>
<span id="cb6-81"><a href="#cb6-81"></a></span>
<span id="cb6-82"><a href="#cb6-82"></a>Unsloth supports fine-tuning with LoRA or QLoRA. You could:</span>
<span id="cb6-83"><a href="#cb6-83"></a></span>
<span id="cb6-84"><a href="#cb6-84"></a><span class="ss">- </span>Feed your company's docs and fine-tune a chatbot</span>
<span id="cb6-85"><a href="#cb6-85"></a><span class="ss">- </span>Inject private datasets and business-specific reasoning</span>
<span id="cb6-86"><a href="#cb6-86"></a><span class="ss">- </span>Modify for multi-modal pipelines</span>
<span id="cb6-87"><a href="#cb6-87"></a></span>
<span id="cb6-88"><a href="#cb6-88"></a>_Not covered directly in the notebook—see [the next blog post for a tutorial](finetune-qwen3-14b.qmd)!_</span>
<span id="cb6-89"><a href="#cb6-89"></a></span>
<span id="cb6-90"><a href="#cb6-90"></a><span class="fu">## Performance on Data Science Tasks</span></span>
<span id="cb6-91"><a href="#cb6-91"></a></span>
<span id="cb6-92"><a href="#cb6-92"></a>Qwen3-14B shines at:</span>
<span id="cb6-93"><a href="#cb6-93"></a></span>
<span id="cb6-94"><a href="#cb6-94"></a><span class="ss">- </span>EDA Explanations</span>
<span id="cb6-95"><a href="#cb6-95"></a><span class="ss">- </span>Math QA</span>
<span id="cb6-96"><a href="#cb6-96"></a><span class="ss">- </span>Prompt Chaining</span>
<span id="cb6-97"><a href="#cb6-97"></a><span class="ss">- </span>Code Review</span>
<span id="cb6-98"><a href="#cb6-98"></a></span>
<span id="cb6-99"><a href="#cb6-99"></a><span class="in">```python</span></span>
<span id="cb6-100"><a href="#cb6-100"></a>prompt <span class="op">=</span> <span class="st">"Explain what this code does:</span><span class="ch">\n</span><span class="st">df.groupby('region')['sales'].mean().sort_values(ascending=False)"</span></span>
<span id="cb6-101"><a href="#cb6-101"></a>inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).to(<span class="st">"cuda"</span>)</span>
<span id="cb6-102"><a href="#cb6-102"></a>outputs <span class="op">=</span> model.generate(<span class="op">**</span>inputs, max_new_tokens<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb6-103"><a href="#cb6-103"></a><span class="bu">print</span>(tokenizer.decode(outputs[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb6-104"><a href="#cb6-104"></a><span class="in">```</span></span>
<span id="cb6-105"><a href="#cb6-105"></a></span>
<span id="cb6-106"><a href="#cb6-106"></a>**Answer:**</span>
<span id="cb6-107"><a href="#cb6-107"></a></span>
<span id="cb6-108"><a href="#cb6-108"></a>This groups the dataframe df by the 'region' column, computes the mean sales for each group, and sorts the results in descending order.</span>
<span id="cb6-109"><a href="#cb6-109"></a></span>
<span id="cb6-110"><a href="#cb6-110"></a><span class="fu">## TL;DR</span></span>
<span id="cb6-111"><a href="#cb6-111"></a></span>
<span id="cb6-112"><a href="#cb6-112"></a>If you're a data scientist looking for:</span>
<span id="cb6-113"><a href="#cb6-113"></a></span>
<span id="cb6-114"><a href="#cb6-114"></a><span class="ss">- </span>Open, commercial-friendly LLMs</span>
<span id="cb6-115"><a href="#cb6-115"></a><span class="ss">- </span>Strong reasoning abilities</span>
<span id="cb6-116"><a href="#cb6-116"></a><span class="ss">- </span>Easy deployment via Colab</span>
<span id="cb6-117"><a href="#cb6-117"></a></span>
<span id="cb6-118"><a href="#cb6-118"></a>Qwen3-14B is worth your time.</span>
<span id="cb6-119"><a href="#cb6-119"></a></span>
<span id="cb6-120"><a href="#cb6-120"></a><span class="fu">## Bonus: Prompt Engineering Tips</span></span>
<span id="cb6-121"><a href="#cb6-121"></a></span>
<span id="cb6-122"><a href="#cb6-122"></a><span class="ss">- </span>**Be Explicit:** Add "Step-by-step reasoning" to prompts.</span>
<span id="cb6-123"><a href="#cb6-123"></a><span class="ss">- </span>**Use System Prompts:** Tailor tone and format.</span>
<span id="cb6-124"><a href="#cb6-124"></a><span class="ss">- </span>**Limit Token Budget:** Keep max tokens reasonable for speed + clarity.</span>
<span id="cb6-125"><a href="#cb6-125"></a></span>
<span id="cb6-126"><a href="#cb6-126"></a>---</span>
<span id="cb6-127"><a href="#cb6-127"></a></span>
<span id="cb6-128"><a href="#cb6-128"></a><span class="fu">## Why Qwen3-14B?</span></span>
<span id="cb6-129"><a href="#cb6-129"></a></span>
<span id="cb6-130"><a href="#cb6-130"></a>Before diving into code, here's what makes Qwen3 interesting:</span>
<span id="cb6-131"><a href="#cb6-131"></a></span>
<span id="cb6-132"><a href="#cb6-132"></a><span class="ss">- </span>**Size and Performance:** 14B parameters—big enough to be powerful, small enough to run locally with quantization.</span>
<span id="cb6-133"><a href="#cb6-133"></a><span class="ss">- </span>**Open Weight License:** Truly open, including for commercial use.</span>
<span id="cb6-134"><a href="#cb6-134"></a><span class="ss">- </span>**Reasoning Optimized:** Trained with a focus on multi-step logical tasks, coding, math, and chain-of-thought.</span>
<span id="cb6-135"><a href="#cb6-135"></a></span>
<span id="cb6-136"><a href="#cb6-136"></a><span class="fu">## Setup: Running a 14B Model in Google Colab?</span></span>
<span id="cb6-137"><a href="#cb6-137"></a></span>
<span id="cb6-138"><a href="#cb6-138"></a>The notebook from Unsloth uses the HuggingFace <span class="in">`transformers`</span> library, <span class="in">`AutoGPTQ`</span>, and 4-bit quantized weights. That means we can run Qwen3-14B on a free Colab GPU (ideally a T4 or A100) without melting our RAM.</span>
<span id="cb6-139"><a href="#cb6-139"></a></span>
<span id="cb6-140"><a href="#cb6-140"></a><span class="in">```python</span></span>
<span id="cb6-141"><a href="#cb6-141"></a><span class="op">!</span>pip install <span class="op">--</span>upgrade <span class="op">--</span>quiet transformers accelerate auto<span class="op">-</span>gptq</span>
<span id="cb6-142"><a href="#cb6-142"></a><span class="in">```</span></span>
<span id="cb6-143"><a href="#cb6-143"></a></span>
<span id="cb6-144"><a href="#cb6-144"></a>:::{.callout-important}</span>
<span id="cb6-145"><a href="#cb6-145"></a><span class="ss">- </span>Run the cell above in your Colab notebook before anything else.</span>
<span id="cb6-146"><a href="#cb6-146"></a><span class="ss">- </span>For best results, use a GPU runtime (T4 or A100 preferred).</span>
<span id="cb6-147"><a href="#cb6-147"></a>:::</span>
<span id="cb6-148"><a href="#cb6-148"></a></span>
<span id="cb6-149"><a href="#cb6-149"></a><span class="fu">## Next Steps</span></span>
<span id="cb6-150"><a href="#cb6-150"></a></span>
<span id="cb6-151"><a href="#cb6-151"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Back to VLM Series Overview</span><span class="co">](../vlm.qmd)</span></span>
<span id="cb6-152"><a href="#cb6-152"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Fine-Tuning Qwen3-14B with Unsloth (next post)</span><span class="co">](finetune-qwen3-14b.qmd)</span></span>
<span id="cb6-153"><a href="#cb6-153"></a><span class="ss">- </span>Try the <span class="co">[</span><span class="ot">Colab Notebook</span><span class="co">]</span>(https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb)</span>
<span id="cb6-154"><a href="#cb6-154"></a></span>
<span id="cb6-155"><a href="#cb6-155"></a><span class="fu">## References</span></span>
<span id="cb6-156"><a href="#cb6-156"></a></span>
<span id="cb6-157"><a href="#cb6-157"></a><span class="ss">1. </span><span class="co">[</span><span class="ot">Qwen3-14B on HuggingFace</span><span class="co">](https://huggingface.co/Qwen/Qwen1.5-14B)</span></span>
<span id="cb6-158"><a href="#cb6-158"></a><span class="ss">2. </span><span class="co">[</span><span class="ot">Qwen3-14B Paper</span><span class="co">](https://arxiv.org/abs/2403.05530)</span></span>
<span id="cb6-159"><a href="#cb6-159"></a><span class="ss">3. </span><span class="co">[</span><span class="ot">Unsloth Qwen3-14B Colab Notebook</span><span class="co">]</span>(https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb)</span>
<span id="cb6-160"><a href="#cb6-160"></a><span class="ss">4. </span><span class="co">[</span><span class="ot">VLM Series Overview</span><span class="co">](../vlm.qmd)</span></span>
<span id="cb6-161"><a href="#cb6-161"></a></span>
<span id="cb6-162"><a href="#cb6-162"></a>:::{.callout-note}</span>
<span id="cb6-163"><a href="#cb6-163"></a>This post is part of the <span class="co">[</span><span class="ot">VLM Series</span><span class="co">](../vlm.qmd)</span>. Feedback and questions are welcome!</span>
<span id="cb6-164"><a href="#cb6-164"></a>::: </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>