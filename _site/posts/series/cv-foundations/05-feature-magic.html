<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Hasan">
<meta name="dcterms.date" content="2025-01-22">

<title>Hasan’s Data Science &amp; AI Blog - Feature Magic: What Makes Images Unique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://hypothes.is/embed.js"></script>


<link rel="stylesheet" href="../../../styles.css">
<meta property="og:title" content="Hasan’s Data Science &amp; AI Blog - Feature Magic: What Makes Images Unique">
<meta property="og:description" content="">
<meta property="og:image" content="https://images.unsplash.com/photo-1555664424-778a1e5e1b48?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=2070&amp;q=80">
<meta property="og:site-name" content="Hasan's Data Science &amp; AI Blog">
<meta name="twitter:title" content="Hasan’s Data Science &amp; AI Blog - Feature Magic: What Makes Images Unique">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://images.unsplash.com/photo-1555664424-778a1e5e1b48?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=2070&amp;q=80">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Hasan’s Data Science &amp; AI Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-series" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Series</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-series">    
        <li>
    <a class="dropdown-item" href="../../../posts/series/data-science-steps.html" rel="" target="">
 <span class="dropdown-text">Data Science Steps</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/computer-vision-with-pytorch.qmd" rel="" target="">
 <span class="dropdown-text">Computer Vision</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/vlm.html" rel="" target="">
 <span class="dropdown-text">VLM Series</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../posts/series/anomaly-detection/index.html" rel="" target="">
 <span class="dropdown-text">Anomaly Detection</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../categories.html" rel="" target="">
 <span class="menu-text">Categories</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../tags.html" rel="" target="">
 <span class="menu-text">Tags</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/HasanGoni" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/hasangoni" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Feature Magic: What Makes Images Unique</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Feature Magic: What Makes Images Unique</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">computer-vision</div>
                <div class="quarto-category">features</div>
                <div class="quarto-category">keypoints</div>
                <div class="quarto-category">matching</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Hasan </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 22, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">June 28, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Data Science</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/data-science-steps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps Series</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part01/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 01</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part02/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 02</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part03/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 03</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part04/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 04</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part05/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 05</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/data-science-steps-to-follow-part06/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Science Steps to Follow - 06</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Computer Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
 <span class="menu-text">posts/series/computer-vision-with-pytorch.qmd</span>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Anomaly Detection</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/anomaly-detection/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/anomaly-detection/finding-the-oddballs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Finding the Oddballs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">VLM Series</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/vlm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../posts/series/vlm-qwen3-14b/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Qwen3-14B</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-puzzle-piece-problem" id="toc-the-puzzle-piece-problem" class="nav-link active" data-scroll-target="#the-puzzle-piece-problem"><span class="header-section-number">0.1</span> The Puzzle Piece Problem</a></li>
  <li><a href="#what-are-features" id="toc-what-are-features" class="nav-link" data-scroll-target="#what-are-features"><span class="header-section-number">0.2</span> What Are Features?</a></li>
  <li><a href="#your-first-feature-detector-sift" id="toc-your-first-feature-detector-sift" class="nav-link" data-scroll-target="#your-first-feature-detector-sift"><span class="header-section-number">0.3</span> Your First Feature Detector: SIFT</a></li>
  <li><a href="#the-faster-alternative-orb" id="toc-the-faster-alternative-orb" class="nav-link" data-scroll-target="#the-faster-alternative-orb"><span class="header-section-number">0.4</span> The Faster Alternative: ORB</a></li>
  <li><a href="#feature-matching-finding-connections" id="toc-feature-matching-finding-connections" class="nav-link" data-scroll-target="#feature-matching-finding-connections"><span class="header-section-number">0.5</span> Feature Matching: Finding Connections</a></li>
  <li><a href="#understanding-feature-descriptors" id="toc-understanding-feature-descriptors" class="nav-link" data-scroll-target="#understanding-feature-descriptors"><span class="header-section-number">0.6</span> Understanding Feature Descriptors</a></li>
  <li><a href="#real-world-application-panorama-stitching" id="toc-real-world-application-panorama-stitching" class="nav-link" data-scroll-target="#real-world-application-panorama-stitching"><span class="header-section-number">0.7</span> Real-World Application: Panorama Stitching</a></li>
  <li><a href="#object-recognition-with-feature-matching" id="toc-object-recognition-with-feature-matching" class="nav-link" data-scroll-target="#object-recognition-with-feature-matching"><span class="header-section-number">0.8</span> Object Recognition with Feature Matching</a></li>
  <li><a href="#feature-detection-comparison" id="toc-feature-detection-comparison" class="nav-link" data-scroll-target="#feature-detection-comparison"><span class="header-section-number">0.9</span> Feature Detection Comparison</a></li>
  <li><a href="#your-challenge-build-a-photo-organizer" id="toc-your-challenge-build-a-photo-organizer" class="nav-link" data-scroll-target="#your-challenge-build-a-photo-organizer"><span class="header-section-number">0.10</span> Your Challenge: Build a Photo Organizer</a></li>
  <li><a href="#whats-coming-next" id="toc-whats-coming-next" class="nav-link" data-scroll-target="#whats-coming-next"><span class="header-section-number">0.11</span> What’s Coming Next?</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">0.12</span> Key Takeaways</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="the-puzzle-piece-problem" class="level2" data-number="0.1">
<h2 data-number="0.1" class="anchored" data-anchor-id="the-puzzle-piece-problem"><span class="header-section-number">0.1</span> The Puzzle Piece Problem</h2>
<p>Imagine you’re doing a 1000-piece jigsaw puzzle. How do you know which pieces fit together? You look for <strong>unique features</strong>—distinctive colors, patterns, corners, and edges that help you match pieces.</p>
<p>Computer vision faces the same challenge: How do we find the same object in different photos? The answer lies in <strong>feature detection</strong>—finding unique, recognizable points that remain consistent even when the image changes.</p>
<p>Today, we’ll unlock this superpower and teach computers to recognize objects across different photos, lighting conditions, and viewing angles!</p>
</section>
<section id="what-are-features" class="level2" data-number="0.2">
<h2 data-number="0.2" class="anchored" data-anchor-id="what-are-features"><span class="header-section-number">0.2</span> What Are Features?</h2>
<p><strong>Features</strong> are distinctive points in an image that are: - <strong>Unique</strong>: Stand out from their surroundings - <strong>Repeatable</strong>: Can be found again in different images - <strong>Stable</strong>: Don’t change much with lighting or viewpoint - <strong>Informative</strong>: Carry enough information for matching</p>
<p>Think of features as the “fingerprints” of an image!</p>
</section>
<section id="your-first-feature-detector-sift" class="level2" data-number="0.3">
<h2 data-number="0.3" class="anchored" data-anchor-id="your-first-feature-detector-sift"><span class="header-section-number">0.3</span> Your First Feature Detector: SIFT</h2>
<p><strong>SIFT</strong> (Scale-Invariant Feature Transform) is like having a super-detective that can find the same clues even if they’re rotated, scaled, or slightly changed:</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> cv2</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co"># Load two images of the same scene (or object from different angles)</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>img1 <span class="op">=</span> cv2.imread(<span class="st">'image1.jpg'</span>)</span>
<span id="cb1-7"><a href="#cb1-7"></a>img2 <span class="op">=</span> cv2.imread(<span class="st">'image2.jpg'</span>)</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a>img1_rgb <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)</span>
<span id="cb1-10"><a href="#cb1-10"></a>img2_rgb <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co"># Convert to grayscale</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>gray1 <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span>
<span id="cb1-14"><a href="#cb1-14"></a>gray2 <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co"># Create SIFT detector</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>sift <span class="op">=</span> cv2.SIFT_create()</span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="co"># Find keypoints and descriptors</span></span>
<span id="cb1-20"><a href="#cb1-20"></a>keypoints1, descriptors1 <span class="op">=</span> sift.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb1-21"><a href="#cb1-21"></a>keypoints2, descriptors2 <span class="op">=</span> sift.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss"> keypoints in image 1"</span>)</span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss"> keypoints in image 2"</span>)</span>
<span id="cb1-25"><a href="#cb1-25"></a></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="co"># Draw keypoints</span></span>
<span id="cb1-27"><a href="#cb1-27"></a>img1_with_keypoints <span class="op">=</span> cv2.drawKeypoints(img1_rgb, keypoints1, <span class="va">None</span>, flags<span class="op">=</span>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span>
<span id="cb1-28"><a href="#cb1-28"></a>img2_with_keypoints <span class="op">=</span> cv2.drawKeypoints(img2_rgb, keypoints2, <span class="va">None</span>, flags<span class="op">=</span>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span>
<span id="cb1-29"><a href="#cb1-29"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="co"># Display results</span></span>
<span id="cb1-31"><a href="#cb1-31"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb1-34"><a href="#cb1-34"></a>plt.imshow(img1_rgb)</span>
<span id="cb1-35"><a href="#cb1-35"></a>plt.title(<span class="st">"Original Image 1"</span>)</span>
<span id="cb1-36"><a href="#cb1-36"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-37"><a href="#cb1-37"></a></span>
<span id="cb1-38"><a href="#cb1-38"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb1-39"><a href="#cb1-39"></a>plt.imshow(img2_rgb)</span>
<span id="cb1-40"><a href="#cb1-40"></a>plt.title(<span class="st">"Original Image 2"</span>)</span>
<span id="cb1-41"><a href="#cb1-41"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb1-44"><a href="#cb1-44"></a>plt.imshow(img1_with_keypoints)</span>
<span id="cb1-45"><a href="#cb1-45"></a>plt.title(<span class="ss">f"SIFT Keypoints: </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-46"><a href="#cb1-46"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb1-49"><a href="#cb1-49"></a>plt.imshow(img2_with_keypoints)</span>
<span id="cb1-50"><a href="#cb1-50"></a>plt.title(<span class="ss">f"SIFT Keypoints: </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-51"><a href="#cb1-51"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb1-52"><a href="#cb1-52"></a></span>
<span id="cb1-53"><a href="#cb1-53"></a>plt.tight_layout()</span>
<span id="cb1-54"><a href="#cb1-54"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><strong>🎯 Try it yourself!</strong> <a href="https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-05-feature-magic.ipynb">Open in Colab</a></p>
</section>
<section id="the-faster-alternative-orb" class="level2" data-number="0.4">
<h2 data-number="0.4" class="anchored" data-anchor-id="the-faster-alternative-orb"><span class="header-section-number">0.4</span> The Faster Alternative: ORB</h2>
<p><strong>ORB</strong> (Oriented FAST and Rotated BRIEF) is like SIFT’s speedy cousin—faster and free to use in commercial applications:</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Create ORB detector</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>orb <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># Find keypoints and descriptors</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>orb_kp1, orb_desc1 <span class="op">=</span> orb.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a>orb_kp2, orb_desc2 <span class="op">=</span> orb.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb2-7"><a href="#cb2-7"></a></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="bu">print</span>(<span class="ss">f"ORB found </span><span class="sc">{</span><span class="bu">len</span>(orb_kp1)<span class="sc">}</span><span class="ss"> keypoints in image 1"</span>)</span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="bu">print</span>(<span class="ss">f"ORB found </span><span class="sc">{</span><span class="bu">len</span>(orb_kp2)<span class="sc">}</span><span class="ss"> keypoints in image 2"</span>)</span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co"># Draw ORB keypoints</span></span>
<span id="cb2-12"><a href="#cb2-12"></a>img1_orb <span class="op">=</span> cv2.drawKeypoints(img1_rgb, orb_kp1, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), flags<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-13"><a href="#cb2-13"></a>img2_orb <span class="op">=</span> cv2.drawKeypoints(img2_rgb, orb_kp2, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), flags<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb2-14"><a href="#cb2-14"></a></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co"># Compare SIFT vs ORB</span></span>
<span id="cb2-16"><a href="#cb2-16"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb2-17"><a href="#cb2-17"></a></span>
<span id="cb2-18"><a href="#cb2-18"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb2-19"><a href="#cb2-19"></a>plt.imshow(img1_with_keypoints)</span>
<span id="cb2-20"><a href="#cb2-20"></a>plt.title(<span class="ss">f"SIFT: </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb2-21"><a href="#cb2-21"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-22"><a href="#cb2-22"></a></span>
<span id="cb2-23"><a href="#cb2-23"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb2-24"><a href="#cb2-24"></a>plt.imshow(img1_orb)</span>
<span id="cb2-25"><a href="#cb2-25"></a>plt.title(<span class="ss">f"ORB: </span><span class="sc">{</span><span class="bu">len</span>(orb_kp1)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb2-26"><a href="#cb2-26"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-27"><a href="#cb2-27"></a></span>
<span id="cb2-28"><a href="#cb2-28"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb2-29"><a href="#cb2-29"></a>plt.imshow(img2_with_keypoints)</span>
<span id="cb2-30"><a href="#cb2-30"></a>plt.title(<span class="ss">f"SIFT: </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb2-31"><a href="#cb2-31"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-32"><a href="#cb2-32"></a></span>
<span id="cb2-33"><a href="#cb2-33"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb2-34"><a href="#cb2-34"></a>plt.imshow(img2_orb)</span>
<span id="cb2-35"><a href="#cb2-35"></a>plt.title(<span class="ss">f"ORB: </span><span class="sc">{</span><span class="bu">len</span>(orb_kp2)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb2-36"><a href="#cb2-36"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb2-37"><a href="#cb2-37"></a></span>
<span id="cb2-38"><a href="#cb2-38"></a>plt.tight_layout()</span>
<span id="cb2-39"><a href="#cb2-39"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="feature-matching-finding-connections" class="level2" data-number="0.5">
<h2 data-number="0.5" class="anchored" data-anchor-id="feature-matching-finding-connections"><span class="header-section-number">0.5</span> Feature Matching: Finding Connections</h2>
<p>Now comes the exciting part—matching features between images to find the same objects or scenes:</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="kw">def</span> match_features(desc1, desc2, matcher_type<span class="op">=</span><span class="st">'bf'</span>):</span>
<span id="cb3-2"><a href="#cb3-2"></a>    <span class="co">"""Match features between two images"""</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>    </span>
<span id="cb3-4"><a href="#cb3-4"></a>    <span class="cf">if</span> matcher_type <span class="op">==</span> <span class="st">'bf'</span>:</span>
<span id="cb3-5"><a href="#cb3-5"></a>        <span class="co"># Brute Force matcher</span></span>
<span id="cb3-6"><a href="#cb3-6"></a>        bf <span class="op">=</span> cv2.BFMatcher()</span>
<span id="cb3-7"><a href="#cb3-7"></a>        matches <span class="op">=</span> bf.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-8"><a href="#cb3-8"></a>    <span class="cf">else</span>:</span>
<span id="cb3-9"><a href="#cb3-9"></a>        <span class="co"># FLANN matcher (faster for large datasets)</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>        FLANN_INDEX_KDTREE <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb3-11"><a href="#cb3-11"></a>        index_params <span class="op">=</span> <span class="bu">dict</span>(algorithm<span class="op">=</span>FLANN_INDEX_KDTREE, trees<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb3-12"><a href="#cb3-12"></a>        search_params <span class="op">=</span> <span class="bu">dict</span>(checks<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb3-13"><a href="#cb3-13"></a>        flann <span class="op">=</span> cv2.FlannBasedMatcher(index_params, search_params)</span>
<span id="cb3-14"><a href="#cb3-14"></a>        matches <span class="op">=</span> flann.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-15"><a href="#cb3-15"></a>    </span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="co"># Apply Lowe's ratio test to filter good matches</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>    good_matches <span class="op">=</span> []</span>
<span id="cb3-18"><a href="#cb3-18"></a>    <span class="cf">for</span> match_pair <span class="kw">in</span> matches:</span>
<span id="cb3-19"><a href="#cb3-19"></a>        <span class="cf">if</span> <span class="bu">len</span>(match_pair) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb3-20"><a href="#cb3-20"></a>            m, n <span class="op">=</span> match_pair</span>
<span id="cb3-21"><a href="#cb3-21"></a>            <span class="cf">if</span> m.distance <span class="op">&lt;</span> <span class="fl">0.7</span> <span class="op">*</span> n.distance:</span>
<span id="cb3-22"><a href="#cb3-22"></a>                good_matches.append(m)</span>
<span id="cb3-23"><a href="#cb3-23"></a>    </span>
<span id="cb3-24"><a href="#cb3-24"></a>    <span class="cf">return</span> good_matches</span>
<span id="cb3-25"><a href="#cb3-25"></a></span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="co"># Match SIFT features</span></span>
<span id="cb3-27"><a href="#cb3-27"></a>good_matches <span class="op">=</span> match_features(descriptors1, descriptors2)</span>
<span id="cb3-28"><a href="#cb3-28"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(good_matches)<span class="sc">}</span><span class="ss"> good matches"</span>)</span>
<span id="cb3-29"><a href="#cb3-29"></a></span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="co"># Draw matches</span></span>
<span id="cb3-31"><a href="#cb3-31"></a>matched_img <span class="op">=</span> cv2.drawMatches(</span>
<span id="cb3-32"><a href="#cb3-32"></a>    img1_rgb, keypoints1,</span>
<span id="cb3-33"><a href="#cb3-33"></a>    img2_rgb, keypoints2,</span>
<span id="cb3-34"><a href="#cb3-34"></a>    good_matches, <span class="va">None</span>,</span>
<span id="cb3-35"><a href="#cb3-35"></a>    flags<span class="op">=</span>cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span>
<span id="cb3-36"><a href="#cb3-36"></a>)</span>
<span id="cb3-37"><a href="#cb3-37"></a></span>
<span id="cb3-38"><a href="#cb3-38"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb3-39"><a href="#cb3-39"></a>plt.imshow(matched_img)</span>
<span id="cb3-40"><a href="#cb3-40"></a>plt.title(<span class="ss">f"Feature Matching: </span><span class="sc">{</span><span class="bu">len</span>(good_matches)<span class="sc">}</span><span class="ss"> matches found"</span>)</span>
<span id="cb3-41"><a href="#cb3-41"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb3-42"><a href="#cb3-42"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="understanding-feature-descriptors" class="level2" data-number="0.6">
<h2 data-number="0.6" class="anchored" data-anchor-id="understanding-feature-descriptors"><span class="header-section-number">0.6</span> Understanding Feature Descriptors</h2>
<p>Each keypoint comes with a <strong>descriptor</strong>—a numerical “fingerprint” that describes the local area around that point:</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> visualize_feature_descriptors(image, keypoints, descriptors, num_features<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb4-2"><a href="#cb4-2"></a>    <span class="co">"""Visualize what feature descriptors look like"""</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>    </span>
<span id="cb4-4"><a href="#cb4-4"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb4-5"><a href="#cb4-5"></a>    </span>
<span id="cb4-6"><a href="#cb4-6"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(num_features, <span class="bu">len</span>(keypoints))):</span>
<span id="cb4-7"><a href="#cb4-7"></a>        kp <span class="op">=</span> keypoints[i]</span>
<span id="cb4-8"><a href="#cb4-8"></a>        desc <span class="op">=</span> descriptors[i]</span>
<span id="cb4-9"><a href="#cb4-9"></a>        </span>
<span id="cb4-10"><a href="#cb4-10"></a>        <span class="co"># Extract patch around keypoint</span></span>
<span id="cb4-11"><a href="#cb4-11"></a>        x, y <span class="op">=</span> <span class="bu">int</span>(kp.pt[<span class="dv">0</span>]), <span class="bu">int</span>(kp.pt[<span class="dv">1</span>])</span>
<span id="cb4-12"><a href="#cb4-12"></a>        size <span class="op">=</span> <span class="bu">int</span>(kp.size)</span>
<span id="cb4-13"><a href="#cb4-13"></a>        </span>
<span id="cb4-14"><a href="#cb4-14"></a>        <span class="co"># Make sure we don't go out of bounds</span></span>
<span id="cb4-15"><a href="#cb4-15"></a>        x1 <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, x <span class="op">-</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-16"><a href="#cb4-16"></a>        y1 <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, y <span class="op">-</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-17"><a href="#cb4-17"></a>        x2 <span class="op">=</span> <span class="bu">min</span>(image.shape[<span class="dv">1</span>], x <span class="op">+</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-18"><a href="#cb4-18"></a>        y2 <span class="op">=</span> <span class="bu">min</span>(image.shape[<span class="dv">0</span>], y <span class="op">+</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb4-19"><a href="#cb4-19"></a>        </span>
<span id="cb4-20"><a href="#cb4-20"></a>        patch <span class="op">=</span> image[y1:y2, x1:x2]</span>
<span id="cb4-21"><a href="#cb4-21"></a>        </span>
<span id="cb4-22"><a href="#cb4-22"></a>        <span class="co"># Plot patch</span></span>
<span id="cb4-23"><a href="#cb4-23"></a>        plt.subplot(<span class="dv">2</span>, num_features, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb4-24"><a href="#cb4-24"></a>        <span class="cf">if</span> <span class="bu">len</span>(patch.shape) <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb4-25"><a href="#cb4-25"></a>            plt.imshow(patch)</span>
<span id="cb4-26"><a href="#cb4-26"></a>        <span class="cf">else</span>:</span>
<span id="cb4-27"><a href="#cb4-27"></a>            plt.imshow(patch, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb4-28"><a href="#cb4-28"></a>        plt.title(<span class="ss">f"Keypoint </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-29"><a href="#cb4-29"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-30"><a href="#cb4-30"></a>        </span>
<span id="cb4-31"><a href="#cb4-31"></a>        <span class="co"># Plot descriptor</span></span>
<span id="cb4-32"><a href="#cb4-32"></a>        plt.subplot(<span class="dv">2</span>, num_features, i <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> num_features)</span>
<span id="cb4-33"><a href="#cb4-33"></a>        plt.plot(desc)</span>
<span id="cb4-34"><a href="#cb4-34"></a>        plt.title(<span class="ss">f"Descriptor (128 values)"</span>)</span>
<span id="cb4-35"><a href="#cb4-35"></a>        plt.xlabel(<span class="st">"Dimension"</span>)</span>
<span id="cb4-36"><a href="#cb4-36"></a>        plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb4-37"><a href="#cb4-37"></a>    </span>
<span id="cb4-38"><a href="#cb4-38"></a>    plt.tight_layout()</span>
<span id="cb4-39"><a href="#cb4-39"></a>    plt.show()</span>
<span id="cb4-40"><a href="#cb4-40"></a></span>
<span id="cb4-41"><a href="#cb4-41"></a><span class="co"># Visualize some feature descriptors</span></span>
<span id="cb4-42"><a href="#cb4-42"></a>visualize_feature_descriptors(img1_rgb, keypoints1, descriptors1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="real-world-application-panorama-stitching" class="level2" data-number="0.7">
<h2 data-number="0.7" class="anchored" data-anchor-id="real-world-application-panorama-stitching"><span class="header-section-number">0.7</span> Real-World Application: Panorama Stitching</h2>
<p>Let’s build something amazing—a panorama stitcher that combines multiple photos into one wide image:</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">class</span> PanoramaStitcher:</span>
<span id="cb5-2"><a href="#cb5-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb5-3"><a href="#cb5-3"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.SIFT_create()</span>
<span id="cb5-4"><a href="#cb5-4"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher()</span>
<span id="cb5-5"><a href="#cb5-5"></a>    </span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="kw">def</span> find_homography(<span class="va">self</span>, img1, img2):</span>
<span id="cb5-7"><a href="#cb5-7"></a>        <span class="co">"""Find transformation between two images"""</span></span>
<span id="cb5-8"><a href="#cb5-8"></a>        <span class="co"># Convert to grayscale</span></span>
<span id="cb5-9"><a href="#cb5-9"></a>        gray1 <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)</span>
<span id="cb5-10"><a href="#cb5-10"></a>        gray2 <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)</span>
<span id="cb5-11"><a href="#cb5-11"></a>        </span>
<span id="cb5-12"><a href="#cb5-12"></a>        <span class="co"># Find keypoints and descriptors</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>        kp1, desc1 <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb5-14"><a href="#cb5-14"></a>        kp2, desc2 <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb5-15"><a href="#cb5-15"></a>        </span>
<span id="cb5-16"><a href="#cb5-16"></a>        <span class="co"># Match features</span></span>
<span id="cb5-17"><a href="#cb5-17"></a>        matches <span class="op">=</span> <span class="va">self</span>.matcher.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb5-18"><a href="#cb5-18"></a>        </span>
<span id="cb5-19"><a href="#cb5-19"></a>        <span class="co"># Filter good matches</span></span>
<span id="cb5-20"><a href="#cb5-20"></a>        good_matches <span class="op">=</span> []</span>
<span id="cb5-21"><a href="#cb5-21"></a>        <span class="cf">for</span> match_pair <span class="kw">in</span> matches:</span>
<span id="cb5-22"><a href="#cb5-22"></a>            <span class="cf">if</span> <span class="bu">len</span>(match_pair) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb5-23"><a href="#cb5-23"></a>                m, n <span class="op">=</span> match_pair</span>
<span id="cb5-24"><a href="#cb5-24"></a>                <span class="cf">if</span> m.distance <span class="op">&lt;</span> <span class="fl">0.7</span> <span class="op">*</span> n.distance:</span>
<span id="cb5-25"><a href="#cb5-25"></a>                    good_matches.append(m)</span>
<span id="cb5-26"><a href="#cb5-26"></a>        </span>
<span id="cb5-27"><a href="#cb5-27"></a>        <span class="cf">if</span> <span class="bu">len</span>(good_matches) <span class="op">&lt;</span> <span class="dv">10</span>:</span>
<span id="cb5-28"><a href="#cb5-28"></a>            <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb5-29"><a href="#cb5-29"></a>        </span>
<span id="cb5-30"><a href="#cb5-30"></a>        <span class="co"># Extract matched points</span></span>
<span id="cb5-31"><a href="#cb5-31"></a>        src_pts <span class="op">=</span> np.float32([kp1[m.queryIdx].pt <span class="cf">for</span> m <span class="kw">in</span> good_matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-32"><a href="#cb5-32"></a>        dst_pts <span class="op">=</span> np.float32([kp2[m.trainIdx].pt <span class="cf">for</span> m <span class="kw">in</span> good_matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-33"><a href="#cb5-33"></a>        </span>
<span id="cb5-34"><a href="#cb5-34"></a>        <span class="co"># Find homography</span></span>
<span id="cb5-35"><a href="#cb5-35"></a>        homography, mask <span class="op">=</span> cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, <span class="fl">5.0</span>)</span>
<span id="cb5-36"><a href="#cb5-36"></a>        </span>
<span id="cb5-37"><a href="#cb5-37"></a>        <span class="cf">return</span> homography, mask</span>
<span id="cb5-38"><a href="#cb5-38"></a>    </span>
<span id="cb5-39"><a href="#cb5-39"></a>    <span class="kw">def</span> stitch_images(<span class="va">self</span>, img1, img2):</span>
<span id="cb5-40"><a href="#cb5-40"></a>        <span class="co">"""Stitch two images together"""</span></span>
<span id="cb5-41"><a href="#cb5-41"></a>        <span class="co"># Find homography</span></span>
<span id="cb5-42"><a href="#cb5-42"></a>        H, mask <span class="op">=</span> <span class="va">self</span>.find_homography(img1, img2)</span>
<span id="cb5-43"><a href="#cb5-43"></a>        </span>
<span id="cb5-44"><a href="#cb5-44"></a>        <span class="cf">if</span> H <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-45"><a href="#cb5-45"></a>            <span class="bu">print</span>(<span class="st">"Could not find enough matches to stitch images"</span>)</span>
<span id="cb5-46"><a href="#cb5-46"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-47"><a href="#cb5-47"></a>        </span>
<span id="cb5-48"><a href="#cb5-48"></a>        <span class="co"># Get dimensions</span></span>
<span id="cb5-49"><a href="#cb5-49"></a>        h1, w1 <span class="op">=</span> img1.shape[:<span class="dv">2</span>]</span>
<span id="cb5-50"><a href="#cb5-50"></a>        h2, w2 <span class="op">=</span> img2.shape[:<span class="dv">2</span>]</span>
<span id="cb5-51"><a href="#cb5-51"></a>        </span>
<span id="cb5-52"><a href="#cb5-52"></a>        <span class="co"># Get corners of both images</span></span>
<span id="cb5-53"><a href="#cb5-53"></a>        corners1 <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w1, <span class="dv">0</span>], [w1, h1], [<span class="dv">0</span>, h1]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-54"><a href="#cb5-54"></a>        corners2 <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w2, <span class="dv">0</span>], [w2, h2], [<span class="dv">0</span>, h2]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb5-55"><a href="#cb5-55"></a>        </span>
<span id="cb5-56"><a href="#cb5-56"></a>        <span class="co"># Transform corners of first image</span></span>
<span id="cb5-57"><a href="#cb5-57"></a>        corners1_transformed <span class="op">=</span> cv2.perspectiveTransform(corners1, H)</span>
<span id="cb5-58"><a href="#cb5-58"></a>        </span>
<span id="cb5-59"><a href="#cb5-59"></a>        <span class="co"># Combine all corners</span></span>
<span id="cb5-60"><a href="#cb5-60"></a>        all_corners <span class="op">=</span> np.concatenate((corners2, corners1_transformed), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-61"><a href="#cb5-61"></a>        </span>
<span id="cb5-62"><a href="#cb5-62"></a>        <span class="co"># Find bounding rectangle</span></span>
<span id="cb5-63"><a href="#cb5-63"></a>        [x_min, y_min] <span class="op">=</span> np.int32(all_corners.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">0</span>).ravel())</span>
<span id="cb5-64"><a href="#cb5-64"></a>        [x_max, y_max] <span class="op">=</span> np.int32(all_corners.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">0</span>).ravel())</span>
<span id="cb5-65"><a href="#cb5-65"></a>        </span>
<span id="cb5-66"><a href="#cb5-66"></a>        <span class="co"># Create translation matrix</span></span>
<span id="cb5-67"><a href="#cb5-67"></a>        translation <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span>x_min], [<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span>y_min], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]])</span>
<span id="cb5-68"><a href="#cb5-68"></a>        </span>
<span id="cb5-69"><a href="#cb5-69"></a>        <span class="co"># Warp first image</span></span>
<span id="cb5-70"><a href="#cb5-70"></a>        warped_img1 <span class="op">=</span> cv2.warpPerspective(img1, translation.dot(H), (x_max <span class="op">-</span> x_min, y_max <span class="op">-</span> y_min))</span>
<span id="cb5-71"><a href="#cb5-71"></a>        </span>
<span id="cb5-72"><a href="#cb5-72"></a>        <span class="co"># Place second image</span></span>
<span id="cb5-73"><a href="#cb5-73"></a>        warped_img1[<span class="op">-</span>y_min:h2 <span class="op">+</span> (<span class="op">-</span>y_min), <span class="op">-</span>x_min:w2 <span class="op">+</span> (<span class="op">-</span>x_min)] <span class="op">=</span> img2</span>
<span id="cb5-74"><a href="#cb5-74"></a>        </span>
<span id="cb5-75"><a href="#cb5-75"></a>        <span class="cf">return</span> warped_img1</span>
<span id="cb5-76"><a href="#cb5-76"></a></span>
<span id="cb5-77"><a href="#cb5-77"></a><span class="co"># Test panorama stitching (works best with overlapping images)</span></span>
<span id="cb5-78"><a href="#cb5-78"></a>stitcher <span class="op">=</span> PanoramaStitcher()</span>
<span id="cb5-79"><a href="#cb5-79"></a>panorama <span class="op">=</span> stitcher.stitch_images(img1_rgb, img2_rgb)</span>
<span id="cb5-80"><a href="#cb5-80"></a></span>
<span id="cb5-81"><a href="#cb5-81"></a><span class="cf">if</span> panorama <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-82"><a href="#cb5-82"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb5-83"><a href="#cb5-83"></a>    plt.imshow(panorama)</span>
<span id="cb5-84"><a href="#cb5-84"></a>    plt.title(<span class="st">"Panorama Stitched from Two Images"</span>)</span>
<span id="cb5-85"><a href="#cb5-85"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb5-86"><a href="#cb5-86"></a>    plt.show()</span>
<span id="cb5-87"><a href="#cb5-87"></a><span class="cf">else</span>:</span>
<span id="cb5-88"><a href="#cb5-88"></a>    <span class="bu">print</span>(<span class="st">"Could not create panorama - images might not overlap enough"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="object-recognition-with-feature-matching" class="level2" data-number="0.8">
<h2 data-number="0.8" class="anchored" data-anchor-id="object-recognition-with-feature-matching"><span class="header-section-number">0.8</span> Object Recognition with Feature Matching</h2>
<p>Let’s build a simple object recognition system:</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="kw">class</span> ObjectRecognizer:</span>
<span id="cb6-2"><a href="#cb6-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb6-3"><a href="#cb6-3"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb6-4"><a href="#cb6-4"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a>        <span class="va">self</span>.reference_objects <span class="op">=</span> {}</span>
<span id="cb6-6"><a href="#cb6-6"></a>    </span>
<span id="cb6-7"><a href="#cb6-7"></a>    <span class="kw">def</span> add_reference_object(<span class="va">self</span>, name, image):</span>
<span id="cb6-8"><a href="#cb6-8"></a>        <span class="co">"""Add a reference object to recognize"""</span></span>
<span id="cb6-9"><a href="#cb6-9"></a>        gray <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb6-10"><a href="#cb6-10"></a>        keypoints, descriptors <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray, <span class="va">None</span>)</span>
<span id="cb6-11"><a href="#cb6-11"></a>        </span>
<span id="cb6-12"><a href="#cb6-12"></a>        <span class="va">self</span>.reference_objects[name] <span class="op">=</span> {</span>
<span id="cb6-13"><a href="#cb6-13"></a>            <span class="st">'keypoints'</span>: keypoints,</span>
<span id="cb6-14"><a href="#cb6-14"></a>            <span class="st">'descriptors'</span>: descriptors,</span>
<span id="cb6-15"><a href="#cb6-15"></a>            <span class="st">'image'</span>: image</span>
<span id="cb6-16"><a href="#cb6-16"></a>        }</span>
<span id="cb6-17"><a href="#cb6-17"></a>        </span>
<span id="cb6-18"><a href="#cb6-18"></a>        <span class="bu">print</span>(<span class="ss">f"Added '</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">' with </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb6-19"><a href="#cb6-19"></a>    </span>
<span id="cb6-20"><a href="#cb6-20"></a>    <span class="kw">def</span> recognize_objects(<span class="va">self</span>, scene_image, min_matches<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb6-21"><a href="#cb6-21"></a>        <span class="co">"""Find reference objects in a scene"""</span></span>
<span id="cb6-22"><a href="#cb6-22"></a>        scene_gray <span class="op">=</span> cv2.cvtColor(scene_image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb6-23"><a href="#cb6-23"></a>        scene_kp, scene_desc <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(scene_gray, <span class="va">None</span>)</span>
<span id="cb6-24"><a href="#cb6-24"></a>        </span>
<span id="cb6-25"><a href="#cb6-25"></a>        results <span class="op">=</span> []</span>
<span id="cb6-26"><a href="#cb6-26"></a>        </span>
<span id="cb6-27"><a href="#cb6-27"></a>        <span class="cf">for</span> obj_name, obj_data <span class="kw">in</span> <span class="va">self</span>.reference_objects.items():</span>
<span id="cb6-28"><a href="#cb6-28"></a>            <span class="co"># Match features</span></span>
<span id="cb6-29"><a href="#cb6-29"></a>            matches <span class="op">=</span> <span class="va">self</span>.matcher.match(obj_data[<span class="st">'descriptors'</span>], scene_desc)</span>
<span id="cb6-30"><a href="#cb6-30"></a>            </span>
<span id="cb6-31"><a href="#cb6-31"></a>            <span class="co"># Sort matches by distance (best first)</span></span>
<span id="cb6-32"><a href="#cb6-32"></a>            matches <span class="op">=</span> <span class="bu">sorted</span>(matches, key<span class="op">=</span><span class="kw">lambda</span> x: x.distance)</span>
<span id="cb6-33"><a href="#cb6-33"></a>            </span>
<span id="cb6-34"><a href="#cb6-34"></a>            <span class="cf">if</span> <span class="bu">len</span>(matches) <span class="op">&gt;=</span> min_matches:</span>
<span id="cb6-35"><a href="#cb6-35"></a>                <span class="co"># Extract matched points</span></span>
<span id="cb6-36"><a href="#cb6-36"></a>                obj_pts <span class="op">=</span> np.float32([obj_data[<span class="st">'keypoints'</span>][m.queryIdx].pt <span class="cf">for</span> m <span class="kw">in</span> matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-37"><a href="#cb6-37"></a>                scene_pts <span class="op">=</span> np.float32([scene_kp[m.trainIdx].pt <span class="cf">for</span> m <span class="kw">in</span> matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-38"><a href="#cb6-38"></a>                </span>
<span id="cb6-39"><a href="#cb6-39"></a>                <span class="co"># Find homography</span></span>
<span id="cb6-40"><a href="#cb6-40"></a>                H, mask <span class="op">=</span> cv2.findHomography(obj_pts, scene_pts, cv2.RANSAC, <span class="fl">5.0</span>)</span>
<span id="cb6-41"><a href="#cb6-41"></a>                </span>
<span id="cb6-42"><a href="#cb6-42"></a>                <span class="cf">if</span> H <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-43"><a href="#cb6-43"></a>                    <span class="co"># Get object dimensions</span></span>
<span id="cb6-44"><a href="#cb6-44"></a>                    h, w <span class="op">=</span> obj_data[<span class="st">'image'</span>].shape[:<span class="dv">2</span>]</span>
<span id="cb6-45"><a href="#cb6-45"></a>                    corners <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w, <span class="dv">0</span>], [w, h], [<span class="dv">0</span>, h]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-46"><a href="#cb6-46"></a>                    </span>
<span id="cb6-47"><a href="#cb6-47"></a>                    <span class="co"># Transform corners to scene</span></span>
<span id="cb6-48"><a href="#cb6-48"></a>                    scene_corners <span class="op">=</span> cv2.perspectiveTransform(corners, H)</span>
<span id="cb6-49"><a href="#cb6-49"></a>                    </span>
<span id="cb6-50"><a href="#cb6-50"></a>                    results.append({</span>
<span id="cb6-51"><a href="#cb6-51"></a>                        <span class="st">'name'</span>: obj_name,</span>
<span id="cb6-52"><a href="#cb6-52"></a>                        <span class="st">'corners'</span>: scene_corners,</span>
<span id="cb6-53"><a href="#cb6-53"></a>                        <span class="st">'matches'</span>: <span class="bu">len</span>(matches),</span>
<span id="cb6-54"><a href="#cb6-54"></a>                        <span class="st">'confidence'</span>: np.<span class="bu">sum</span>(mask) <span class="op">/</span> <span class="bu">len</span>(matches)</span>
<span id="cb6-55"><a href="#cb6-55"></a>                    })</span>
<span id="cb6-56"><a href="#cb6-56"></a>        </span>
<span id="cb6-57"><a href="#cb6-57"></a>        <span class="cf">return</span> results</span>
<span id="cb6-58"><a href="#cb6-58"></a>    </span>
<span id="cb6-59"><a href="#cb6-59"></a>    <span class="kw">def</span> visualize_recognition(<span class="va">self</span>, scene_image, results):</span>
<span id="cb6-60"><a href="#cb6-60"></a>        <span class="co">"""Visualize recognition results"""</span></span>
<span id="cb6-61"><a href="#cb6-61"></a>        result_img <span class="op">=</span> scene_image.copy()</span>
<span id="cb6-62"><a href="#cb6-62"></a>        </span>
<span id="cb6-63"><a href="#cb6-63"></a>        <span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb6-64"><a href="#cb6-64"></a>            <span class="co"># Draw bounding box</span></span>
<span id="cb6-65"><a href="#cb6-65"></a>            corners <span class="op">=</span> np.int32(result[<span class="st">'corners'</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-66"><a href="#cb6-66"></a>            cv2.polylines(result_img, [corners], <span class="va">True</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">3</span>)</span>
<span id="cb6-67"><a href="#cb6-67"></a>            </span>
<span id="cb6-68"><a href="#cb6-68"></a>            <span class="co"># Add label</span></span>
<span id="cb6-69"><a href="#cb6-69"></a>            cv2.putText(result_img, <span class="ss">f"</span><span class="sc">{</span>result[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>result[<span class="st">'confidence'</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>, </span>
<span id="cb6-70"><a href="#cb6-70"></a>                       <span class="bu">tuple</span>(corners[<span class="dv">0</span>]), cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.7</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb6-71"><a href="#cb6-71"></a>        </span>
<span id="cb6-72"><a href="#cb6-72"></a>        <span class="cf">return</span> result_img</span>
<span id="cb6-73"><a href="#cb6-73"></a></span>
<span id="cb6-74"><a href="#cb6-74"></a><span class="co"># Example usage (you would add your own reference objects)</span></span>
<span id="cb6-75"><a href="#cb6-75"></a>recognizer <span class="op">=</span> ObjectRecognizer()</span>
<span id="cb6-76"><a href="#cb6-76"></a></span>
<span id="cb6-77"><a href="#cb6-77"></a><span class="co"># Add a reference object (crop a distinctive part of your image)</span></span>
<span id="cb6-78"><a href="#cb6-78"></a>reference_obj <span class="op">=</span> img1_rgb[<span class="dv">100</span>:<span class="dv">300</span>, <span class="dv">100</span>:<span class="dv">300</span>]  <span class="co"># Example crop</span></span>
<span id="cb6-79"><a href="#cb6-79"></a>recognizer.add_reference_object(<span class="st">"Sample Object"</span>, reference_obj)</span>
<span id="cb6-80"><a href="#cb6-80"></a></span>
<span id="cb6-81"><a href="#cb6-81"></a><span class="co"># Try to find it in the scene</span></span>
<span id="cb6-82"><a href="#cb6-82"></a>recognition_results <span class="op">=</span> recognizer.recognize_objects(img2_rgb)</span>
<span id="cb6-83"><a href="#cb6-83"></a></span>
<span id="cb6-84"><a href="#cb6-84"></a><span class="cf">if</span> recognition_results:</span>
<span id="cb6-85"><a href="#cb6-85"></a>    result_img <span class="op">=</span> recognizer.visualize_recognition(img2_rgb, recognition_results)</span>
<span id="cb6-86"><a href="#cb6-86"></a>    </span>
<span id="cb6-87"><a href="#cb6-87"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb6-88"><a href="#cb6-88"></a>    </span>
<span id="cb6-89"><a href="#cb6-89"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb6-90"><a href="#cb6-90"></a>    plt.imshow(reference_obj)</span>
<span id="cb6-91"><a href="#cb6-91"></a>    plt.title(<span class="st">"Reference Object"</span>)</span>
<span id="cb6-92"><a href="#cb6-92"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb6-93"><a href="#cb6-93"></a>    </span>
<span id="cb6-94"><a href="#cb6-94"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-95"><a href="#cb6-95"></a>    plt.imshow(result_img)</span>
<span id="cb6-96"><a href="#cb6-96"></a>    plt.title(<span class="st">"Recognition Results"</span>)</span>
<span id="cb6-97"><a href="#cb6-97"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb6-98"><a href="#cb6-98"></a>    </span>
<span id="cb6-99"><a href="#cb6-99"></a>    plt.tight_layout()</span>
<span id="cb6-100"><a href="#cb6-100"></a>    plt.show()</span>
<span id="cb6-101"><a href="#cb6-101"></a>    </span>
<span id="cb6-102"><a href="#cb6-102"></a>    <span class="cf">for</span> result <span class="kw">in</span> recognition_results:</span>
<span id="cb6-103"><a href="#cb6-103"></a>        <span class="bu">print</span>(<span class="ss">f"Found '</span><span class="sc">{</span>result[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">' with </span><span class="sc">{</span>result[<span class="st">'matches'</span>]<span class="sc">}</span><span class="ss"> matches (confidence: </span><span class="sc">{</span>result[<span class="st">'confidence'</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb6-104"><a href="#cb6-104"></a><span class="cf">else</span>:</span>
<span id="cb6-105"><a href="#cb6-105"></a>    <span class="bu">print</span>(<span class="st">"No objects recognized in the scene"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="feature-detection-comparison" class="level2" data-number="0.9">
<h2 data-number="0.9" class="anchored" data-anchor-id="feature-detection-comparison"><span class="header-section-number">0.9</span> Feature Detection Comparison</h2>
<p>Let’s compare different feature detectors to understand their strengths:</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">def</span> compare_feature_detectors(image):</span>
<span id="cb7-2"><a href="#cb7-2"></a>    <span class="co">"""Compare different feature detection algorithms"""</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>    gray <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb7-4"><a href="#cb7-4"></a>    </span>
<span id="cb7-5"><a href="#cb7-5"></a>    <span class="co"># Different detectors</span></span>
<span id="cb7-6"><a href="#cb7-6"></a>    detectors <span class="op">=</span> {</span>
<span id="cb7-7"><a href="#cb7-7"></a>        <span class="st">'SIFT'</span>: cv2.SIFT_create(),</span>
<span id="cb7-8"><a href="#cb7-8"></a>        <span class="st">'ORB'</span>: cv2.ORB_create(),</span>
<span id="cb7-9"><a href="#cb7-9"></a>        <span class="st">'FAST'</span>: cv2.FastFeatureDetector_create(),</span>
<span id="cb7-10"><a href="#cb7-10"></a>        <span class="st">'BRISK'</span>: cv2.BRISK_create()</span>
<span id="cb7-11"><a href="#cb7-11"></a>    }</span>
<span id="cb7-12"><a href="#cb7-12"></a>    </span>
<span id="cb7-13"><a href="#cb7-13"></a>    results <span class="op">=</span> {}</span>
<span id="cb7-14"><a href="#cb7-14"></a>    </span>
<span id="cb7-15"><a href="#cb7-15"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb7-16"><a href="#cb7-16"></a>    </span>
<span id="cb7-17"><a href="#cb7-17"></a>    <span class="cf">for</span> i, (name, detector) <span class="kw">in</span> <span class="bu">enumerate</span>(detectors.items()):</span>
<span id="cb7-18"><a href="#cb7-18"></a>        <span class="co"># Detect keypoints</span></span>
<span id="cb7-19"><a href="#cb7-19"></a>        <span class="cf">if</span> name <span class="kw">in</span> [<span class="st">'SIFT'</span>, <span class="st">'ORB'</span>, <span class="st">'BRISK'</span>]:</span>
<span id="cb7-20"><a href="#cb7-20"></a>            keypoints, descriptors <span class="op">=</span> detector.detectAndCompute(gray, <span class="va">None</span>)</span>
<span id="cb7-21"><a href="#cb7-21"></a>        <span class="cf">else</span>:  <span class="co"># FAST doesn't compute descriptors</span></span>
<span id="cb7-22"><a href="#cb7-22"></a>            keypoints <span class="op">=</span> detector.detect(gray, <span class="va">None</span>)</span>
<span id="cb7-23"><a href="#cb7-23"></a>            descriptors <span class="op">=</span> <span class="va">None</span></span>
<span id="cb7-24"><a href="#cb7-24"></a>        </span>
<span id="cb7-25"><a href="#cb7-25"></a>        <span class="co"># Draw keypoints</span></span>
<span id="cb7-26"><a href="#cb7-26"></a>        img_with_kp <span class="op">=</span> cv2.drawKeypoints(image, keypoints, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>))</span>
<span id="cb7-27"><a href="#cb7-27"></a>        </span>
<span id="cb7-28"><a href="#cb7-28"></a>        <span class="co"># Store results</span></span>
<span id="cb7-29"><a href="#cb7-29"></a>        results[name] <span class="op">=</span> {</span>
<span id="cb7-30"><a href="#cb7-30"></a>            <span class="st">'keypoints'</span>: <span class="bu">len</span>(keypoints),</span>
<span id="cb7-31"><a href="#cb7-31"></a>            <span class="st">'has_descriptors'</span>: descriptors <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb7-32"><a href="#cb7-32"></a>        }</span>
<span id="cb7-33"><a href="#cb7-33"></a>        </span>
<span id="cb7-34"><a href="#cb7-34"></a>        <span class="co"># Plot</span></span>
<span id="cb7-35"><a href="#cb7-35"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb7-36"><a href="#cb7-36"></a>        plt.imshow(img_with_kp)</span>
<span id="cb7-37"><a href="#cb7-37"></a>        plt.title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb7-38"><a href="#cb7-38"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb7-39"><a href="#cb7-39"></a>    </span>
<span id="cb7-40"><a href="#cb7-40"></a>    plt.tight_layout()</span>
<span id="cb7-41"><a href="#cb7-41"></a>    plt.show()</span>
<span id="cb7-42"><a href="#cb7-42"></a>    </span>
<span id="cb7-43"><a href="#cb7-43"></a>    <span class="co"># Print comparison</span></span>
<span id="cb7-44"><a href="#cb7-44"></a>    <span class="bu">print</span>(<span class="st">"Feature Detector Comparison:"</span>)</span>
<span id="cb7-45"><a href="#cb7-45"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb7-46"><a href="#cb7-46"></a>    <span class="cf">for</span> name, data <span class="kw">in</span> results.items():</span>
<span id="cb7-47"><a href="#cb7-47"></a>        desc_info <span class="op">=</span> <span class="st">"Yes"</span> <span class="cf">if</span> data[<span class="st">'has_descriptors'</span>] <span class="cf">else</span> <span class="st">"No"</span></span>
<span id="cb7-48"><a href="#cb7-48"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">:10}</span><span class="ss"> | </span><span class="sc">{</span>data[<span class="st">'keypoints'</span>]<span class="sc">:4}</span><span class="ss"> keypoints | Descriptors: </span><span class="sc">{</span>desc_info<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-49"><a href="#cb7-49"></a>    </span>
<span id="cb7-50"><a href="#cb7-50"></a>    <span class="cf">return</span> results</span>
<span id="cb7-51"><a href="#cb7-51"></a></span>
<span id="cb7-52"><a href="#cb7-52"></a><span class="co"># Compare detectors on your image</span></span>
<span id="cb7-53"><a href="#cb7-53"></a>comparison_results <span class="op">=</span> compare_feature_detectors(img1_rgb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="your-challenge-build-a-photo-organizer" class="level2" data-number="0.10">
<h2 data-number="0.10" class="anchored" data-anchor-id="your-challenge-build-a-photo-organizer"><span class="header-section-number">0.10</span> Your Challenge: Build a Photo Organizer</h2>
<p>Now it’s your turn! Build a system that can organize photos by finding similar images:</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">class</span> PhotoOrganizer:</span>
<span id="cb8-2"><a href="#cb8-2"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb8-3"><a href="#cb8-3"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb8-4"><a href="#cb8-4"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-5"><a href="#cb8-5"></a>        <span class="va">self</span>.photo_database <span class="op">=</span> {}</span>
<span id="cb8-6"><a href="#cb8-6"></a>    </span>
<span id="cb8-7"><a href="#cb8-7"></a>    <span class="kw">def</span> add_photo(<span class="va">self</span>, photo_id, image):</span>
<span id="cb8-8"><a href="#cb8-8"></a>        <span class="co">"""Add a photo to the database"""</span></span>
<span id="cb8-9"><a href="#cb8-9"></a>        <span class="co"># Your code here!</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>        <span class="co"># Hint: Extract features and store them with the photo ID</span></span>
<span id="cb8-11"><a href="#cb8-11"></a>        <span class="cf">pass</span></span>
<span id="cb8-12"><a href="#cb8-12"></a>    </span>
<span id="cb8-13"><a href="#cb8-13"></a>    <span class="kw">def</span> find_similar_photos(<span class="va">self</span>, query_image, threshold<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb8-14"><a href="#cb8-14"></a>        <span class="co">"""Find photos similar to the query image"""</span></span>
<span id="cb8-15"><a href="#cb8-15"></a>        <span class="co"># Your code here!</span></span>
<span id="cb8-16"><a href="#cb8-16"></a>        <span class="co"># Hint: Match features with all photos in database</span></span>
<span id="cb8-17"><a href="#cb8-17"></a>        <span class="cf">pass</span></span>
<span id="cb8-18"><a href="#cb8-18"></a>    </span>
<span id="cb8-19"><a href="#cb8-19"></a>    <span class="kw">def</span> organize_by_similarity(<span class="va">self</span>, images):</span>
<span id="cb8-20"><a href="#cb8-20"></a>        <span class="co">"""Group similar images together"""</span></span>
<span id="cb8-21"><a href="#cb8-21"></a>        <span class="co"># Your code here!</span></span>
<span id="cb8-22"><a href="#cb8-22"></a>        <span class="co"># Hint: Compare all images with each other</span></span>
<span id="cb8-23"><a href="#cb8-23"></a>        <span class="cf">pass</span></span>
<span id="cb8-24"><a href="#cb8-24"></a></span>
<span id="cb8-25"><a href="#cb8-25"></a><span class="co"># Test your photo organizer</span></span>
<span id="cb8-26"><a href="#cb8-26"></a>organizer <span class="op">=</span> PhotoOrganizer()</span>
<span id="cb8-27"><a href="#cb8-27"></a><span class="co"># Add your implementation!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="whats-coming-next" class="level2" data-number="0.11">
<h2 data-number="0.11" class="anchored" data-anchor-id="whats-coming-next"><span class="header-section-number">0.11</span> What’s Coming Next?</h2>
<p>In our next post, <a href="../06-why-deep-learning/"><strong>“Why Deep Learning? When Classical Methods Hit the Wall”</strong></a>, we’ll discover:</p>
<ul>
<li><strong>The limitations</strong> of classical computer vision</li>
<li><strong>Why neural networks</strong> changed everything</li>
<li><strong>Your first deep learning model</strong> for image classification</li>
<li><strong>Transfer learning</strong> (the secret to quick success)</li>
</ul>
<p>You’ve mastered the art of finding and matching features—next, we’ll explore how deep learning revolutionized computer vision!</p>
</section>
<section id="key-takeaways" class="level2" data-number="0.12">
<h2 data-number="0.12" class="anchored" data-anchor-id="key-takeaways"><span class="header-section-number">0.12</span> Key Takeaways</h2>
<ul>
<li><strong>Features are unique points</strong> that can be reliably found across images</li>
<li><strong>SIFT and ORB</strong> are powerful feature detectors with different strengths</li>
<li><strong>Feature matching</strong> enables object recognition and image stitching</li>
<li><strong>Homography</strong> describes geometric transformations between images</li>
<li><strong>Classical methods</strong> work great for many applications</li>
<li><strong>Feature-based approaches</strong> are still used in modern systems</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hands-On Lab
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ready to extract and match features in your own images? Try the complete interactive notebook: <a href="https://colab.research.google.com/drive/1Feature_Magic_Lab_123456"><strong>Feature Magic Lab</strong></a></p>
<p>Build panoramas, recognize objects, and explore the magic of feature detection!</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Series Navigation
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Previous</strong>: <a href="../04-finding-patterns/">Finding Patterns: Edges, Contours, and Shapes</a></li>
<li><strong>Next</strong>: <a href="../06-why-deep-learning/">Why Deep Learning? When Classical Methods Hit the Wall</a></li>
<li><strong>Series Home</strong>: <a href="../../../posts/series/computer-vision-foundations.html">Computer Vision Foundations</a></li>
</ul>
</div>
</div>
<hr>
<p><em>You’ve just learned one of the most powerful techniques in computer vision! Feature matching is used in everything from Google Photos to archaeological site reconstruction. Next, we’ll see why deep learning became necessary and how it builds on these foundations.</em></p>


<!-- -->

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>CC BY-NC-SA 4.0</div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{2025,
  author = {, Hasan},
  title = {Feature {Magic:} {What} {Makes} {Images} {Unique}},
  date = {2025-01-22},
  url = {https://hasangoni.quarto.pub/hasan-blog-post/posts/series/cv-foundations/05-feature-magic.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Hasan. 2025. <span>“Feature Magic: What Makes Images Unique.”</span>
January 22, 2025. <a href="https://hasangoni.quarto.pub/hasan-blog-post/posts/series/cv-foundations/05-feature-magic.html">https://hasangoni.quarto.pub/hasan-blog-post/posts/series/cv-foundations/05-feature-magic.html</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="yourusername/quarto_blog_hasan" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<script src="https://giscus.app/client.js" data-repo="HasanGoni/quarto_blog_hasan" data-repo-id="" data-category="General" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">---</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="an">title:</span><span class="co"> "Feature Magic: What Makes Images Unique"</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="an">author:</span><span class="co"> "Hasan"</span></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="an">date:</span><span class="co"> 2025-01-22</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="an">categories:</span><span class="co"> [computer-vision, features, keypoints, matching]</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="an">tags:</span><span class="co"> [sift, orb, keypoints, feature-matching, panorama]</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="an">image:</span><span class="co"> "https://images.unsplash.com/photo-1555664424-778a1e5e1b48?ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&amp;auto=format&amp;fit=crop&amp;w=2070&amp;q=80"</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="an">series:</span></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="co">  name: "Computer Vision Foundations"</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="co">  number: 5</span></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="an">format:</span></span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="co">  html: default</span></span>
<span id="cb9-14"><a href="#cb9-14"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb9-15"><a href="#cb9-15"></a><span class="co">---</span></span>
<span id="cb9-16"><a href="#cb9-16"></a></span>
<span id="cb9-17"><a href="#cb9-17"></a><span class="fu">## The Puzzle Piece Problem</span></span>
<span id="cb9-18"><a href="#cb9-18"></a></span>
<span id="cb9-19"><a href="#cb9-19"></a>Imagine you're doing a 1000-piece jigsaw puzzle. How do you know which pieces fit together? You look for **unique features**—distinctive colors, patterns, corners, and edges that help you match pieces.</span>
<span id="cb9-20"><a href="#cb9-20"></a></span>
<span id="cb9-21"><a href="#cb9-21"></a>Computer vision faces the same challenge: How do we find the same object in different photos? The answer lies in **feature detection**—finding unique, recognizable points that remain consistent even when the image changes.</span>
<span id="cb9-22"><a href="#cb9-22"></a></span>
<span id="cb9-23"><a href="#cb9-23"></a>Today, we'll unlock this superpower and teach computers to recognize objects across different photos, lighting conditions, and viewing angles!</span>
<span id="cb9-24"><a href="#cb9-24"></a></span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="fu">## What Are Features?</span></span>
<span id="cb9-26"><a href="#cb9-26"></a></span>
<span id="cb9-27"><a href="#cb9-27"></a>**Features** are distinctive points in an image that are:</span>
<span id="cb9-28"><a href="#cb9-28"></a><span class="ss">- </span>**Unique**: Stand out from their surroundings</span>
<span id="cb9-29"><a href="#cb9-29"></a><span class="ss">- </span>**Repeatable**: Can be found again in different images</span>
<span id="cb9-30"><a href="#cb9-30"></a><span class="ss">- </span>**Stable**: Don't change much with lighting or viewpoint</span>
<span id="cb9-31"><a href="#cb9-31"></a><span class="ss">- </span>**Informative**: Carry enough information for matching</span>
<span id="cb9-32"><a href="#cb9-32"></a></span>
<span id="cb9-33"><a href="#cb9-33"></a>Think of features as the "fingerprints" of an image!</span>
<span id="cb9-34"><a href="#cb9-34"></a></span>
<span id="cb9-35"><a href="#cb9-35"></a><span class="fu">## Your First Feature Detector: SIFT</span></span>
<span id="cb9-36"><a href="#cb9-36"></a></span>
<span id="cb9-37"><a href="#cb9-37"></a>**SIFT** (Scale-Invariant Feature Transform) is like having a super-detective that can find the same clues even if they're rotated, scaled, or slightly changed:</span>
<span id="cb9-38"><a href="#cb9-38"></a></span>
<span id="cb9-41"><a href="#cb9-41"></a><span class="in">```{python}</span></span>
<span id="cb9-42"><a href="#cb9-42"></a><span class="co">#| eval: false</span></span>
<span id="cb9-43"><a href="#cb9-43"></a><span class="im">import</span> cv2</span>
<span id="cb9-44"><a href="#cb9-44"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-45"><a href="#cb9-45"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-46"><a href="#cb9-46"></a></span>
<span id="cb9-47"><a href="#cb9-47"></a><span class="co"># Load two images of the same scene (or object from different angles)</span></span>
<span id="cb9-48"><a href="#cb9-48"></a>img1 <span class="op">=</span> cv2.imread(<span class="st">'image1.jpg'</span>)</span>
<span id="cb9-49"><a href="#cb9-49"></a>img2 <span class="op">=</span> cv2.imread(<span class="st">'image2.jpg'</span>)</span>
<span id="cb9-50"><a href="#cb9-50"></a></span>
<span id="cb9-51"><a href="#cb9-51"></a>img1_rgb <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)</span>
<span id="cb9-52"><a href="#cb9-52"></a>img2_rgb <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)</span>
<span id="cb9-53"><a href="#cb9-53"></a></span>
<span id="cb9-54"><a href="#cb9-54"></a><span class="co"># Convert to grayscale</span></span>
<span id="cb9-55"><a href="#cb9-55"></a>gray1 <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span>
<span id="cb9-56"><a href="#cb9-56"></a>gray2 <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span>
<span id="cb9-57"><a href="#cb9-57"></a></span>
<span id="cb9-58"><a href="#cb9-58"></a><span class="co"># Create SIFT detector</span></span>
<span id="cb9-59"><a href="#cb9-59"></a>sift <span class="op">=</span> cv2.SIFT_create()</span>
<span id="cb9-60"><a href="#cb9-60"></a></span>
<span id="cb9-61"><a href="#cb9-61"></a><span class="co"># Find keypoints and descriptors</span></span>
<span id="cb9-62"><a href="#cb9-62"></a>keypoints1, descriptors1 <span class="op">=</span> sift.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb9-63"><a href="#cb9-63"></a>keypoints2, descriptors2 <span class="op">=</span> sift.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb9-64"><a href="#cb9-64"></a></span>
<span id="cb9-65"><a href="#cb9-65"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss"> keypoints in image 1"</span>)</span>
<span id="cb9-66"><a href="#cb9-66"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss"> keypoints in image 2"</span>)</span>
<span id="cb9-67"><a href="#cb9-67"></a></span>
<span id="cb9-68"><a href="#cb9-68"></a><span class="co"># Draw keypoints</span></span>
<span id="cb9-69"><a href="#cb9-69"></a>img1_with_keypoints <span class="op">=</span> cv2.drawKeypoints(img1_rgb, keypoints1, <span class="va">None</span>, flags<span class="op">=</span>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span>
<span id="cb9-70"><a href="#cb9-70"></a>img2_with_keypoints <span class="op">=</span> cv2.drawKeypoints(img2_rgb, keypoints2, <span class="va">None</span>, flags<span class="op">=</span>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span>
<span id="cb9-71"><a href="#cb9-71"></a></span>
<span id="cb9-72"><a href="#cb9-72"></a><span class="co"># Display results</span></span>
<span id="cb9-73"><a href="#cb9-73"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb9-74"><a href="#cb9-74"></a></span>
<span id="cb9-75"><a href="#cb9-75"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-76"><a href="#cb9-76"></a>plt.imshow(img1_rgb)</span>
<span id="cb9-77"><a href="#cb9-77"></a>plt.title(<span class="st">"Original Image 1"</span>)</span>
<span id="cb9-78"><a href="#cb9-78"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-79"><a href="#cb9-79"></a></span>
<span id="cb9-80"><a href="#cb9-80"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-81"><a href="#cb9-81"></a>plt.imshow(img2_rgb)</span>
<span id="cb9-82"><a href="#cb9-82"></a>plt.title(<span class="st">"Original Image 2"</span>)</span>
<span id="cb9-83"><a href="#cb9-83"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-84"><a href="#cb9-84"></a></span>
<span id="cb9-85"><a href="#cb9-85"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb9-86"><a href="#cb9-86"></a>plt.imshow(img1_with_keypoints)</span>
<span id="cb9-87"><a href="#cb9-87"></a>plt.title(<span class="ss">f"SIFT Keypoints: </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-88"><a href="#cb9-88"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-89"><a href="#cb9-89"></a></span>
<span id="cb9-90"><a href="#cb9-90"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb9-91"><a href="#cb9-91"></a>plt.imshow(img2_with_keypoints)</span>
<span id="cb9-92"><a href="#cb9-92"></a>plt.title(<span class="ss">f"SIFT Keypoints: </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-93"><a href="#cb9-93"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-94"><a href="#cb9-94"></a></span>
<span id="cb9-95"><a href="#cb9-95"></a>plt.tight_layout()</span>
<span id="cb9-96"><a href="#cb9-96"></a>plt.show()</span>
<span id="cb9-97"><a href="#cb9-97"></a><span class="in">```</span></span>
<span id="cb9-98"><a href="#cb9-98"></a></span>
<span id="cb9-99"><a href="#cb9-99"></a>**🎯 Try it yourself!** <span class="co">[</span><span class="ot">Open in Colab</span><span class="co">](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-05-feature-magic.ipynb)</span></span>
<span id="cb9-100"><a href="#cb9-100"></a></span>
<span id="cb9-101"><a href="#cb9-101"></a><span class="fu">## The Faster Alternative: ORB</span></span>
<span id="cb9-102"><a href="#cb9-102"></a></span>
<span id="cb9-103"><a href="#cb9-103"></a>**ORB** (Oriented FAST and Rotated BRIEF) is like SIFT's speedy cousin—faster and free to use in commercial applications:</span>
<span id="cb9-104"><a href="#cb9-104"></a></span>
<span id="cb9-107"><a href="#cb9-107"></a><span class="in">```{python}</span></span>
<span id="cb9-108"><a href="#cb9-108"></a><span class="co">#| eval: false</span></span>
<span id="cb9-109"><a href="#cb9-109"></a><span class="co"># Create ORB detector</span></span>
<span id="cb9-110"><a href="#cb9-110"></a>orb <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb9-111"><a href="#cb9-111"></a></span>
<span id="cb9-112"><a href="#cb9-112"></a><span class="co"># Find keypoints and descriptors</span></span>
<span id="cb9-113"><a href="#cb9-113"></a>orb_kp1, orb_desc1 <span class="op">=</span> orb.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb9-114"><a href="#cb9-114"></a>orb_kp2, orb_desc2 <span class="op">=</span> orb.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb9-115"><a href="#cb9-115"></a></span>
<span id="cb9-116"><a href="#cb9-116"></a><span class="bu">print</span>(<span class="ss">f"ORB found </span><span class="sc">{</span><span class="bu">len</span>(orb_kp1)<span class="sc">}</span><span class="ss"> keypoints in image 1"</span>)</span>
<span id="cb9-117"><a href="#cb9-117"></a><span class="bu">print</span>(<span class="ss">f"ORB found </span><span class="sc">{</span><span class="bu">len</span>(orb_kp2)<span class="sc">}</span><span class="ss"> keypoints in image 2"</span>)</span>
<span id="cb9-118"><a href="#cb9-118"></a></span>
<span id="cb9-119"><a href="#cb9-119"></a><span class="co"># Draw ORB keypoints</span></span>
<span id="cb9-120"><a href="#cb9-120"></a>img1_orb <span class="op">=</span> cv2.drawKeypoints(img1_rgb, orb_kp1, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), flags<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-121"><a href="#cb9-121"></a>img2_orb <span class="op">=</span> cv2.drawKeypoints(img2_rgb, orb_kp2, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), flags<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-122"><a href="#cb9-122"></a></span>
<span id="cb9-123"><a href="#cb9-123"></a><span class="co"># Compare SIFT vs ORB</span></span>
<span id="cb9-124"><a href="#cb9-124"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb9-125"><a href="#cb9-125"></a></span>
<span id="cb9-126"><a href="#cb9-126"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-127"><a href="#cb9-127"></a>plt.imshow(img1_with_keypoints)</span>
<span id="cb9-128"><a href="#cb9-128"></a>plt.title(<span class="ss">f"SIFT: </span><span class="sc">{</span><span class="bu">len</span>(keypoints1)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-129"><a href="#cb9-129"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-130"><a href="#cb9-130"></a></span>
<span id="cb9-131"><a href="#cb9-131"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-132"><a href="#cb9-132"></a>plt.imshow(img1_orb)</span>
<span id="cb9-133"><a href="#cb9-133"></a>plt.title(<span class="ss">f"ORB: </span><span class="sc">{</span><span class="bu">len</span>(orb_kp1)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-134"><a href="#cb9-134"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-135"><a href="#cb9-135"></a></span>
<span id="cb9-136"><a href="#cb9-136"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb9-137"><a href="#cb9-137"></a>plt.imshow(img2_with_keypoints)</span>
<span id="cb9-138"><a href="#cb9-138"></a>plt.title(<span class="ss">f"SIFT: </span><span class="sc">{</span><span class="bu">len</span>(keypoints2)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-139"><a href="#cb9-139"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-140"><a href="#cb9-140"></a></span>
<span id="cb9-141"><a href="#cb9-141"></a>plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb9-142"><a href="#cb9-142"></a>plt.imshow(img2_orb)</span>
<span id="cb9-143"><a href="#cb9-143"></a>plt.title(<span class="ss">f"ORB: </span><span class="sc">{</span><span class="bu">len</span>(orb_kp2)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-144"><a href="#cb9-144"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-145"><a href="#cb9-145"></a></span>
<span id="cb9-146"><a href="#cb9-146"></a>plt.tight_layout()</span>
<span id="cb9-147"><a href="#cb9-147"></a>plt.show()</span>
<span id="cb9-148"><a href="#cb9-148"></a><span class="in">```</span></span>
<span id="cb9-149"><a href="#cb9-149"></a></span>
<span id="cb9-150"><a href="#cb9-150"></a><span class="fu">## Feature Matching: Finding Connections</span></span>
<span id="cb9-151"><a href="#cb9-151"></a></span>
<span id="cb9-152"><a href="#cb9-152"></a>Now comes the exciting part—matching features between images to find the same objects or scenes:</span>
<span id="cb9-153"><a href="#cb9-153"></a></span>
<span id="cb9-156"><a href="#cb9-156"></a><span class="in">```{python}</span></span>
<span id="cb9-157"><a href="#cb9-157"></a><span class="co">#| eval: false</span></span>
<span id="cb9-158"><a href="#cb9-158"></a><span class="kw">def</span> match_features(desc1, desc2, matcher_type<span class="op">=</span><span class="st">'bf'</span>):</span>
<span id="cb9-159"><a href="#cb9-159"></a>    <span class="co">"""Match features between two images"""</span></span>
<span id="cb9-160"><a href="#cb9-160"></a>    </span>
<span id="cb9-161"><a href="#cb9-161"></a>    <span class="cf">if</span> matcher_type <span class="op">==</span> <span class="st">'bf'</span>:</span>
<span id="cb9-162"><a href="#cb9-162"></a>        <span class="co"># Brute Force matcher</span></span>
<span id="cb9-163"><a href="#cb9-163"></a>        bf <span class="op">=</span> cv2.BFMatcher()</span>
<span id="cb9-164"><a href="#cb9-164"></a>        matches <span class="op">=</span> bf.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-165"><a href="#cb9-165"></a>    <span class="cf">else</span>:</span>
<span id="cb9-166"><a href="#cb9-166"></a>        <span class="co"># FLANN matcher (faster for large datasets)</span></span>
<span id="cb9-167"><a href="#cb9-167"></a>        FLANN_INDEX_KDTREE <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-168"><a href="#cb9-168"></a>        index_params <span class="op">=</span> <span class="bu">dict</span>(algorithm<span class="op">=</span>FLANN_INDEX_KDTREE, trees<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb9-169"><a href="#cb9-169"></a>        search_params <span class="op">=</span> <span class="bu">dict</span>(checks<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb9-170"><a href="#cb9-170"></a>        flann <span class="op">=</span> cv2.FlannBasedMatcher(index_params, search_params)</span>
<span id="cb9-171"><a href="#cb9-171"></a>        matches <span class="op">=</span> flann.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-172"><a href="#cb9-172"></a>    </span>
<span id="cb9-173"><a href="#cb9-173"></a>    <span class="co"># Apply Lowe's ratio test to filter good matches</span></span>
<span id="cb9-174"><a href="#cb9-174"></a>    good_matches <span class="op">=</span> []</span>
<span id="cb9-175"><a href="#cb9-175"></a>    <span class="cf">for</span> match_pair <span class="kw">in</span> matches:</span>
<span id="cb9-176"><a href="#cb9-176"></a>        <span class="cf">if</span> <span class="bu">len</span>(match_pair) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb9-177"><a href="#cb9-177"></a>            m, n <span class="op">=</span> match_pair</span>
<span id="cb9-178"><a href="#cb9-178"></a>            <span class="cf">if</span> m.distance <span class="op">&lt;</span> <span class="fl">0.7</span> <span class="op">*</span> n.distance:</span>
<span id="cb9-179"><a href="#cb9-179"></a>                good_matches.append(m)</span>
<span id="cb9-180"><a href="#cb9-180"></a>    </span>
<span id="cb9-181"><a href="#cb9-181"></a>    <span class="cf">return</span> good_matches</span>
<span id="cb9-182"><a href="#cb9-182"></a></span>
<span id="cb9-183"><a href="#cb9-183"></a><span class="co"># Match SIFT features</span></span>
<span id="cb9-184"><a href="#cb9-184"></a>good_matches <span class="op">=</span> match_features(descriptors1, descriptors2)</span>
<span id="cb9-185"><a href="#cb9-185"></a><span class="bu">print</span>(<span class="ss">f"Found </span><span class="sc">{</span><span class="bu">len</span>(good_matches)<span class="sc">}</span><span class="ss"> good matches"</span>)</span>
<span id="cb9-186"><a href="#cb9-186"></a></span>
<span id="cb9-187"><a href="#cb9-187"></a><span class="co"># Draw matches</span></span>
<span id="cb9-188"><a href="#cb9-188"></a>matched_img <span class="op">=</span> cv2.drawMatches(</span>
<span id="cb9-189"><a href="#cb9-189"></a>    img1_rgb, keypoints1,</span>
<span id="cb9-190"><a href="#cb9-190"></a>    img2_rgb, keypoints2,</span>
<span id="cb9-191"><a href="#cb9-191"></a>    good_matches, <span class="va">None</span>,</span>
<span id="cb9-192"><a href="#cb9-192"></a>    flags<span class="op">=</span>cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS</span>
<span id="cb9-193"><a href="#cb9-193"></a>)</span>
<span id="cb9-194"><a href="#cb9-194"></a></span>
<span id="cb9-195"><a href="#cb9-195"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb9-196"><a href="#cb9-196"></a>plt.imshow(matched_img)</span>
<span id="cb9-197"><a href="#cb9-197"></a>plt.title(<span class="ss">f"Feature Matching: </span><span class="sc">{</span><span class="bu">len</span>(good_matches)<span class="sc">}</span><span class="ss"> matches found"</span>)</span>
<span id="cb9-198"><a href="#cb9-198"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-199"><a href="#cb9-199"></a>plt.show()</span>
<span id="cb9-200"><a href="#cb9-200"></a><span class="in">```</span></span>
<span id="cb9-201"><a href="#cb9-201"></a></span>
<span id="cb9-202"><a href="#cb9-202"></a><span class="fu">## Understanding Feature Descriptors</span></span>
<span id="cb9-203"><a href="#cb9-203"></a></span>
<span id="cb9-204"><a href="#cb9-204"></a>Each keypoint comes with a **descriptor**—a numerical "fingerprint" that describes the local area around that point:</span>
<span id="cb9-205"><a href="#cb9-205"></a></span>
<span id="cb9-208"><a href="#cb9-208"></a><span class="in">```{python}</span></span>
<span id="cb9-209"><a href="#cb9-209"></a><span class="co">#| eval: false</span></span>
<span id="cb9-210"><a href="#cb9-210"></a><span class="kw">def</span> visualize_feature_descriptors(image, keypoints, descriptors, num_features<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb9-211"><a href="#cb9-211"></a>    <span class="co">"""Visualize what feature descriptors look like"""</span></span>
<span id="cb9-212"><a href="#cb9-212"></a>    </span>
<span id="cb9-213"><a href="#cb9-213"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb9-214"><a href="#cb9-214"></a>    </span>
<span id="cb9-215"><a href="#cb9-215"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(num_features, <span class="bu">len</span>(keypoints))):</span>
<span id="cb9-216"><a href="#cb9-216"></a>        kp <span class="op">=</span> keypoints[i]</span>
<span id="cb9-217"><a href="#cb9-217"></a>        desc <span class="op">=</span> descriptors[i]</span>
<span id="cb9-218"><a href="#cb9-218"></a>        </span>
<span id="cb9-219"><a href="#cb9-219"></a>        <span class="co"># Extract patch around keypoint</span></span>
<span id="cb9-220"><a href="#cb9-220"></a>        x, y <span class="op">=</span> <span class="bu">int</span>(kp.pt[<span class="dv">0</span>]), <span class="bu">int</span>(kp.pt[<span class="dv">1</span>])</span>
<span id="cb9-221"><a href="#cb9-221"></a>        size <span class="op">=</span> <span class="bu">int</span>(kp.size)</span>
<span id="cb9-222"><a href="#cb9-222"></a>        </span>
<span id="cb9-223"><a href="#cb9-223"></a>        <span class="co"># Make sure we don't go out of bounds</span></span>
<span id="cb9-224"><a href="#cb9-224"></a>        x1 <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, x <span class="op">-</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb9-225"><a href="#cb9-225"></a>        y1 <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, y <span class="op">-</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb9-226"><a href="#cb9-226"></a>        x2 <span class="op">=</span> <span class="bu">min</span>(image.shape[<span class="dv">1</span>], x <span class="op">+</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb9-227"><a href="#cb9-227"></a>        y2 <span class="op">=</span> <span class="bu">min</span>(image.shape[<span class="dv">0</span>], y <span class="op">+</span> size<span class="op">//</span><span class="dv">2</span>)</span>
<span id="cb9-228"><a href="#cb9-228"></a>        </span>
<span id="cb9-229"><a href="#cb9-229"></a>        patch <span class="op">=</span> image[y1:y2, x1:x2]</span>
<span id="cb9-230"><a href="#cb9-230"></a>        </span>
<span id="cb9-231"><a href="#cb9-231"></a>        <span class="co"># Plot patch</span></span>
<span id="cb9-232"><a href="#cb9-232"></a>        plt.subplot(<span class="dv">2</span>, num_features, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb9-233"><a href="#cb9-233"></a>        <span class="cf">if</span> <span class="bu">len</span>(patch.shape) <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb9-234"><a href="#cb9-234"></a>            plt.imshow(patch)</span>
<span id="cb9-235"><a href="#cb9-235"></a>        <span class="cf">else</span>:</span>
<span id="cb9-236"><a href="#cb9-236"></a>            plt.imshow(patch, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-237"><a href="#cb9-237"></a>        plt.title(<span class="ss">f"Keypoint </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-238"><a href="#cb9-238"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-239"><a href="#cb9-239"></a>        </span>
<span id="cb9-240"><a href="#cb9-240"></a>        <span class="co"># Plot descriptor</span></span>
<span id="cb9-241"><a href="#cb9-241"></a>        plt.subplot(<span class="dv">2</span>, num_features, i <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> num_features)</span>
<span id="cb9-242"><a href="#cb9-242"></a>        plt.plot(desc)</span>
<span id="cb9-243"><a href="#cb9-243"></a>        plt.title(<span class="ss">f"Descriptor (128 values)"</span>)</span>
<span id="cb9-244"><a href="#cb9-244"></a>        plt.xlabel(<span class="st">"Dimension"</span>)</span>
<span id="cb9-245"><a href="#cb9-245"></a>        plt.ylabel(<span class="st">"Value"</span>)</span>
<span id="cb9-246"><a href="#cb9-246"></a>    </span>
<span id="cb9-247"><a href="#cb9-247"></a>    plt.tight_layout()</span>
<span id="cb9-248"><a href="#cb9-248"></a>    plt.show()</span>
<span id="cb9-249"><a href="#cb9-249"></a></span>
<span id="cb9-250"><a href="#cb9-250"></a><span class="co"># Visualize some feature descriptors</span></span>
<span id="cb9-251"><a href="#cb9-251"></a>visualize_feature_descriptors(img1_rgb, keypoints1, descriptors1)</span>
<span id="cb9-252"><a href="#cb9-252"></a><span class="in">```</span></span>
<span id="cb9-253"><a href="#cb9-253"></a></span>
<span id="cb9-254"><a href="#cb9-254"></a><span class="fu">## Real-World Application: Panorama Stitching</span></span>
<span id="cb9-255"><a href="#cb9-255"></a></span>
<span id="cb9-256"><a href="#cb9-256"></a>Let's build something amazing—a panorama stitcher that combines multiple photos into one wide image:</span>
<span id="cb9-257"><a href="#cb9-257"></a></span>
<span id="cb9-260"><a href="#cb9-260"></a><span class="in">```{python}</span></span>
<span id="cb9-261"><a href="#cb9-261"></a><span class="co">#| eval: false</span></span>
<span id="cb9-262"><a href="#cb9-262"></a><span class="kw">class</span> PanoramaStitcher:</span>
<span id="cb9-263"><a href="#cb9-263"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb9-264"><a href="#cb9-264"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.SIFT_create()</span>
<span id="cb9-265"><a href="#cb9-265"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher()</span>
<span id="cb9-266"><a href="#cb9-266"></a>    </span>
<span id="cb9-267"><a href="#cb9-267"></a>    <span class="kw">def</span> find_homography(<span class="va">self</span>, img1, img2):</span>
<span id="cb9-268"><a href="#cb9-268"></a>        <span class="co">"""Find transformation between two images"""</span></span>
<span id="cb9-269"><a href="#cb9-269"></a>        <span class="co"># Convert to grayscale</span></span>
<span id="cb9-270"><a href="#cb9-270"></a>        gray1 <span class="op">=</span> cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)</span>
<span id="cb9-271"><a href="#cb9-271"></a>        gray2 <span class="op">=</span> cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)</span>
<span id="cb9-272"><a href="#cb9-272"></a>        </span>
<span id="cb9-273"><a href="#cb9-273"></a>        <span class="co"># Find keypoints and descriptors</span></span>
<span id="cb9-274"><a href="#cb9-274"></a>        kp1, desc1 <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray1, <span class="va">None</span>)</span>
<span id="cb9-275"><a href="#cb9-275"></a>        kp2, desc2 <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray2, <span class="va">None</span>)</span>
<span id="cb9-276"><a href="#cb9-276"></a>        </span>
<span id="cb9-277"><a href="#cb9-277"></a>        <span class="co"># Match features</span></span>
<span id="cb9-278"><a href="#cb9-278"></a>        matches <span class="op">=</span> <span class="va">self</span>.matcher.knnMatch(desc1, desc2, k<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-279"><a href="#cb9-279"></a>        </span>
<span id="cb9-280"><a href="#cb9-280"></a>        <span class="co"># Filter good matches</span></span>
<span id="cb9-281"><a href="#cb9-281"></a>        good_matches <span class="op">=</span> []</span>
<span id="cb9-282"><a href="#cb9-282"></a>        <span class="cf">for</span> match_pair <span class="kw">in</span> matches:</span>
<span id="cb9-283"><a href="#cb9-283"></a>            <span class="cf">if</span> <span class="bu">len</span>(match_pair) <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb9-284"><a href="#cb9-284"></a>                m, n <span class="op">=</span> match_pair</span>
<span id="cb9-285"><a href="#cb9-285"></a>                <span class="cf">if</span> m.distance <span class="op">&lt;</span> <span class="fl">0.7</span> <span class="op">*</span> n.distance:</span>
<span id="cb9-286"><a href="#cb9-286"></a>                    good_matches.append(m)</span>
<span id="cb9-287"><a href="#cb9-287"></a>        </span>
<span id="cb9-288"><a href="#cb9-288"></a>        <span class="cf">if</span> <span class="bu">len</span>(good_matches) <span class="op">&lt;</span> <span class="dv">10</span>:</span>
<span id="cb9-289"><a href="#cb9-289"></a>            <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb9-290"><a href="#cb9-290"></a>        </span>
<span id="cb9-291"><a href="#cb9-291"></a>        <span class="co"># Extract matched points</span></span>
<span id="cb9-292"><a href="#cb9-292"></a>        src_pts <span class="op">=</span> np.float32([kp1[m.queryIdx].pt <span class="cf">for</span> m <span class="kw">in</span> good_matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-293"><a href="#cb9-293"></a>        dst_pts <span class="op">=</span> np.float32([kp2[m.trainIdx].pt <span class="cf">for</span> m <span class="kw">in</span> good_matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-294"><a href="#cb9-294"></a>        </span>
<span id="cb9-295"><a href="#cb9-295"></a>        <span class="co"># Find homography</span></span>
<span id="cb9-296"><a href="#cb9-296"></a>        homography, mask <span class="op">=</span> cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, <span class="fl">5.0</span>)</span>
<span id="cb9-297"><a href="#cb9-297"></a>        </span>
<span id="cb9-298"><a href="#cb9-298"></a>        <span class="cf">return</span> homography, mask</span>
<span id="cb9-299"><a href="#cb9-299"></a>    </span>
<span id="cb9-300"><a href="#cb9-300"></a>    <span class="kw">def</span> stitch_images(<span class="va">self</span>, img1, img2):</span>
<span id="cb9-301"><a href="#cb9-301"></a>        <span class="co">"""Stitch two images together"""</span></span>
<span id="cb9-302"><a href="#cb9-302"></a>        <span class="co"># Find homography</span></span>
<span id="cb9-303"><a href="#cb9-303"></a>        H, mask <span class="op">=</span> <span class="va">self</span>.find_homography(img1, img2)</span>
<span id="cb9-304"><a href="#cb9-304"></a>        </span>
<span id="cb9-305"><a href="#cb9-305"></a>        <span class="cf">if</span> H <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb9-306"><a href="#cb9-306"></a>            <span class="bu">print</span>(<span class="st">"Could not find enough matches to stitch images"</span>)</span>
<span id="cb9-307"><a href="#cb9-307"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb9-308"><a href="#cb9-308"></a>        </span>
<span id="cb9-309"><a href="#cb9-309"></a>        <span class="co"># Get dimensions</span></span>
<span id="cb9-310"><a href="#cb9-310"></a>        h1, w1 <span class="op">=</span> img1.shape[:<span class="dv">2</span>]</span>
<span id="cb9-311"><a href="#cb9-311"></a>        h2, w2 <span class="op">=</span> img2.shape[:<span class="dv">2</span>]</span>
<span id="cb9-312"><a href="#cb9-312"></a>        </span>
<span id="cb9-313"><a href="#cb9-313"></a>        <span class="co"># Get corners of both images</span></span>
<span id="cb9-314"><a href="#cb9-314"></a>        corners1 <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w1, <span class="dv">0</span>], [w1, h1], [<span class="dv">0</span>, h1]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-315"><a href="#cb9-315"></a>        corners2 <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w2, <span class="dv">0</span>], [w2, h2], [<span class="dv">0</span>, h2]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-316"><a href="#cb9-316"></a>        </span>
<span id="cb9-317"><a href="#cb9-317"></a>        <span class="co"># Transform corners of first image</span></span>
<span id="cb9-318"><a href="#cb9-318"></a>        corners1_transformed <span class="op">=</span> cv2.perspectiveTransform(corners1, H)</span>
<span id="cb9-319"><a href="#cb9-319"></a>        </span>
<span id="cb9-320"><a href="#cb9-320"></a>        <span class="co"># Combine all corners</span></span>
<span id="cb9-321"><a href="#cb9-321"></a>        all_corners <span class="op">=</span> np.concatenate((corners2, corners1_transformed), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-322"><a href="#cb9-322"></a>        </span>
<span id="cb9-323"><a href="#cb9-323"></a>        <span class="co"># Find bounding rectangle</span></span>
<span id="cb9-324"><a href="#cb9-324"></a>        [x_min, y_min] <span class="op">=</span> np.int32(all_corners.<span class="bu">min</span>(axis<span class="op">=</span><span class="dv">0</span>).ravel())</span>
<span id="cb9-325"><a href="#cb9-325"></a>        [x_max, y_max] <span class="op">=</span> np.int32(all_corners.<span class="bu">max</span>(axis<span class="op">=</span><span class="dv">0</span>).ravel())</span>
<span id="cb9-326"><a href="#cb9-326"></a>        </span>
<span id="cb9-327"><a href="#cb9-327"></a>        <span class="co"># Create translation matrix</span></span>
<span id="cb9-328"><a href="#cb9-328"></a>        translation <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>, <span class="op">-</span>x_min], [<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span>y_min], [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>]])</span>
<span id="cb9-329"><a href="#cb9-329"></a>        </span>
<span id="cb9-330"><a href="#cb9-330"></a>        <span class="co"># Warp first image</span></span>
<span id="cb9-331"><a href="#cb9-331"></a>        warped_img1 <span class="op">=</span> cv2.warpPerspective(img1, translation.dot(H), (x_max <span class="op">-</span> x_min, y_max <span class="op">-</span> y_min))</span>
<span id="cb9-332"><a href="#cb9-332"></a>        </span>
<span id="cb9-333"><a href="#cb9-333"></a>        <span class="co"># Place second image</span></span>
<span id="cb9-334"><a href="#cb9-334"></a>        warped_img1[<span class="op">-</span>y_min:h2 <span class="op">+</span> (<span class="op">-</span>y_min), <span class="op">-</span>x_min:w2 <span class="op">+</span> (<span class="op">-</span>x_min)] <span class="op">=</span> img2</span>
<span id="cb9-335"><a href="#cb9-335"></a>        </span>
<span id="cb9-336"><a href="#cb9-336"></a>        <span class="cf">return</span> warped_img1</span>
<span id="cb9-337"><a href="#cb9-337"></a></span>
<span id="cb9-338"><a href="#cb9-338"></a><span class="co"># Test panorama stitching (works best with overlapping images)</span></span>
<span id="cb9-339"><a href="#cb9-339"></a>stitcher <span class="op">=</span> PanoramaStitcher()</span>
<span id="cb9-340"><a href="#cb9-340"></a>panorama <span class="op">=</span> stitcher.stitch_images(img1_rgb, img2_rgb)</span>
<span id="cb9-341"><a href="#cb9-341"></a></span>
<span id="cb9-342"><a href="#cb9-342"></a><span class="cf">if</span> panorama <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb9-343"><a href="#cb9-343"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb9-344"><a href="#cb9-344"></a>    plt.imshow(panorama)</span>
<span id="cb9-345"><a href="#cb9-345"></a>    plt.title(<span class="st">"Panorama Stitched from Two Images"</span>)</span>
<span id="cb9-346"><a href="#cb9-346"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-347"><a href="#cb9-347"></a>    plt.show()</span>
<span id="cb9-348"><a href="#cb9-348"></a><span class="cf">else</span>:</span>
<span id="cb9-349"><a href="#cb9-349"></a>    <span class="bu">print</span>(<span class="st">"Could not create panorama - images might not overlap enough"</span>)</span>
<span id="cb9-350"><a href="#cb9-350"></a><span class="in">```</span></span>
<span id="cb9-351"><a href="#cb9-351"></a></span>
<span id="cb9-352"><a href="#cb9-352"></a><span class="fu">## Object Recognition with Feature Matching</span></span>
<span id="cb9-353"><a href="#cb9-353"></a></span>
<span id="cb9-354"><a href="#cb9-354"></a>Let's build a simple object recognition system:</span>
<span id="cb9-355"><a href="#cb9-355"></a></span>
<span id="cb9-358"><a href="#cb9-358"></a><span class="in">```{python}</span></span>
<span id="cb9-359"><a href="#cb9-359"></a><span class="co">#| eval: false</span></span>
<span id="cb9-360"><a href="#cb9-360"></a><span class="kw">class</span> ObjectRecognizer:</span>
<span id="cb9-361"><a href="#cb9-361"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb9-362"><a href="#cb9-362"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb9-363"><a href="#cb9-363"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-364"><a href="#cb9-364"></a>        <span class="va">self</span>.reference_objects <span class="op">=</span> {}</span>
<span id="cb9-365"><a href="#cb9-365"></a>    </span>
<span id="cb9-366"><a href="#cb9-366"></a>    <span class="kw">def</span> add_reference_object(<span class="va">self</span>, name, image):</span>
<span id="cb9-367"><a href="#cb9-367"></a>        <span class="co">"""Add a reference object to recognize"""</span></span>
<span id="cb9-368"><a href="#cb9-368"></a>        gray <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb9-369"><a href="#cb9-369"></a>        keypoints, descriptors <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(gray, <span class="va">None</span>)</span>
<span id="cb9-370"><a href="#cb9-370"></a>        </span>
<span id="cb9-371"><a href="#cb9-371"></a>        <span class="va">self</span>.reference_objects[name] <span class="op">=</span> {</span>
<span id="cb9-372"><a href="#cb9-372"></a>            <span class="st">'keypoints'</span>: keypoints,</span>
<span id="cb9-373"><a href="#cb9-373"></a>            <span class="st">'descriptors'</span>: descriptors,</span>
<span id="cb9-374"><a href="#cb9-374"></a>            <span class="st">'image'</span>: image</span>
<span id="cb9-375"><a href="#cb9-375"></a>        }</span>
<span id="cb9-376"><a href="#cb9-376"></a>        </span>
<span id="cb9-377"><a href="#cb9-377"></a>        <span class="bu">print</span>(<span class="ss">f"Added '</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">' with </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-378"><a href="#cb9-378"></a>    </span>
<span id="cb9-379"><a href="#cb9-379"></a>    <span class="kw">def</span> recognize_objects(<span class="va">self</span>, scene_image, min_matches<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb9-380"><a href="#cb9-380"></a>        <span class="co">"""Find reference objects in a scene"""</span></span>
<span id="cb9-381"><a href="#cb9-381"></a>        scene_gray <span class="op">=</span> cv2.cvtColor(scene_image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb9-382"><a href="#cb9-382"></a>        scene_kp, scene_desc <span class="op">=</span> <span class="va">self</span>.detector.detectAndCompute(scene_gray, <span class="va">None</span>)</span>
<span id="cb9-383"><a href="#cb9-383"></a>        </span>
<span id="cb9-384"><a href="#cb9-384"></a>        results <span class="op">=</span> []</span>
<span id="cb9-385"><a href="#cb9-385"></a>        </span>
<span id="cb9-386"><a href="#cb9-386"></a>        <span class="cf">for</span> obj_name, obj_data <span class="kw">in</span> <span class="va">self</span>.reference_objects.items():</span>
<span id="cb9-387"><a href="#cb9-387"></a>            <span class="co"># Match features</span></span>
<span id="cb9-388"><a href="#cb9-388"></a>            matches <span class="op">=</span> <span class="va">self</span>.matcher.match(obj_data[<span class="st">'descriptors'</span>], scene_desc)</span>
<span id="cb9-389"><a href="#cb9-389"></a>            </span>
<span id="cb9-390"><a href="#cb9-390"></a>            <span class="co"># Sort matches by distance (best first)</span></span>
<span id="cb9-391"><a href="#cb9-391"></a>            matches <span class="op">=</span> <span class="bu">sorted</span>(matches, key<span class="op">=</span><span class="kw">lambda</span> x: x.distance)</span>
<span id="cb9-392"><a href="#cb9-392"></a>            </span>
<span id="cb9-393"><a href="#cb9-393"></a>            <span class="cf">if</span> <span class="bu">len</span>(matches) <span class="op">&gt;=</span> min_matches:</span>
<span id="cb9-394"><a href="#cb9-394"></a>                <span class="co"># Extract matched points</span></span>
<span id="cb9-395"><a href="#cb9-395"></a>                obj_pts <span class="op">=</span> np.float32([obj_data[<span class="st">'keypoints'</span>][m.queryIdx].pt <span class="cf">for</span> m <span class="kw">in</span> matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-396"><a href="#cb9-396"></a>                scene_pts <span class="op">=</span> np.float32([scene_kp[m.trainIdx].pt <span class="cf">for</span> m <span class="kw">in</span> matches]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-397"><a href="#cb9-397"></a>                </span>
<span id="cb9-398"><a href="#cb9-398"></a>                <span class="co"># Find homography</span></span>
<span id="cb9-399"><a href="#cb9-399"></a>                H, mask <span class="op">=</span> cv2.findHomography(obj_pts, scene_pts, cv2.RANSAC, <span class="fl">5.0</span>)</span>
<span id="cb9-400"><a href="#cb9-400"></a>                </span>
<span id="cb9-401"><a href="#cb9-401"></a>                <span class="cf">if</span> H <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb9-402"><a href="#cb9-402"></a>                    <span class="co"># Get object dimensions</span></span>
<span id="cb9-403"><a href="#cb9-403"></a>                    h, w <span class="op">=</span> obj_data[<span class="st">'image'</span>].shape[:<span class="dv">2</span>]</span>
<span id="cb9-404"><a href="#cb9-404"></a>                    corners <span class="op">=</span> np.float32([[<span class="dv">0</span>, <span class="dv">0</span>], [w, <span class="dv">0</span>], [w, h], [<span class="dv">0</span>, h]]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-405"><a href="#cb9-405"></a>                    </span>
<span id="cb9-406"><a href="#cb9-406"></a>                    <span class="co"># Transform corners to scene</span></span>
<span id="cb9-407"><a href="#cb9-407"></a>                    scene_corners <span class="op">=</span> cv2.perspectiveTransform(corners, H)</span>
<span id="cb9-408"><a href="#cb9-408"></a>                    </span>
<span id="cb9-409"><a href="#cb9-409"></a>                    results.append({</span>
<span id="cb9-410"><a href="#cb9-410"></a>                        <span class="st">'name'</span>: obj_name,</span>
<span id="cb9-411"><a href="#cb9-411"></a>                        <span class="st">'corners'</span>: scene_corners,</span>
<span id="cb9-412"><a href="#cb9-412"></a>                        <span class="st">'matches'</span>: <span class="bu">len</span>(matches),</span>
<span id="cb9-413"><a href="#cb9-413"></a>                        <span class="st">'confidence'</span>: np.<span class="bu">sum</span>(mask) <span class="op">/</span> <span class="bu">len</span>(matches)</span>
<span id="cb9-414"><a href="#cb9-414"></a>                    })</span>
<span id="cb9-415"><a href="#cb9-415"></a>        </span>
<span id="cb9-416"><a href="#cb9-416"></a>        <span class="cf">return</span> results</span>
<span id="cb9-417"><a href="#cb9-417"></a>    </span>
<span id="cb9-418"><a href="#cb9-418"></a>    <span class="kw">def</span> visualize_recognition(<span class="va">self</span>, scene_image, results):</span>
<span id="cb9-419"><a href="#cb9-419"></a>        <span class="co">"""Visualize recognition results"""</span></span>
<span id="cb9-420"><a href="#cb9-420"></a>        result_img <span class="op">=</span> scene_image.copy()</span>
<span id="cb9-421"><a href="#cb9-421"></a>        </span>
<span id="cb9-422"><a href="#cb9-422"></a>        <span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb9-423"><a href="#cb9-423"></a>            <span class="co"># Draw bounding box</span></span>
<span id="cb9-424"><a href="#cb9-424"></a>            corners <span class="op">=</span> np.int32(result[<span class="st">'corners'</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb9-425"><a href="#cb9-425"></a>            cv2.polylines(result_img, [corners], <span class="va">True</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">3</span>)</span>
<span id="cb9-426"><a href="#cb9-426"></a>            </span>
<span id="cb9-427"><a href="#cb9-427"></a>            <span class="co"># Add label</span></span>
<span id="cb9-428"><a href="#cb9-428"></a>            cv2.putText(result_img, <span class="ss">f"</span><span class="sc">{</span>result[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>result[<span class="st">'confidence'</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>, </span>
<span id="cb9-429"><a href="#cb9-429"></a>                       <span class="bu">tuple</span>(corners[<span class="dv">0</span>]), cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.7</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb9-430"><a href="#cb9-430"></a>        </span>
<span id="cb9-431"><a href="#cb9-431"></a>        <span class="cf">return</span> result_img</span>
<span id="cb9-432"><a href="#cb9-432"></a></span>
<span id="cb9-433"><a href="#cb9-433"></a><span class="co"># Example usage (you would add your own reference objects)</span></span>
<span id="cb9-434"><a href="#cb9-434"></a>recognizer <span class="op">=</span> ObjectRecognizer()</span>
<span id="cb9-435"><a href="#cb9-435"></a></span>
<span id="cb9-436"><a href="#cb9-436"></a><span class="co"># Add a reference object (crop a distinctive part of your image)</span></span>
<span id="cb9-437"><a href="#cb9-437"></a>reference_obj <span class="op">=</span> img1_rgb[<span class="dv">100</span>:<span class="dv">300</span>, <span class="dv">100</span>:<span class="dv">300</span>]  <span class="co"># Example crop</span></span>
<span id="cb9-438"><a href="#cb9-438"></a>recognizer.add_reference_object(<span class="st">"Sample Object"</span>, reference_obj)</span>
<span id="cb9-439"><a href="#cb9-439"></a></span>
<span id="cb9-440"><a href="#cb9-440"></a><span class="co"># Try to find it in the scene</span></span>
<span id="cb9-441"><a href="#cb9-441"></a>recognition_results <span class="op">=</span> recognizer.recognize_objects(img2_rgb)</span>
<span id="cb9-442"><a href="#cb9-442"></a></span>
<span id="cb9-443"><a href="#cb9-443"></a><span class="cf">if</span> recognition_results:</span>
<span id="cb9-444"><a href="#cb9-444"></a>    result_img <span class="op">=</span> recognizer.visualize_recognition(img2_rgb, recognition_results)</span>
<span id="cb9-445"><a href="#cb9-445"></a>    </span>
<span id="cb9-446"><a href="#cb9-446"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb9-447"><a href="#cb9-447"></a>    </span>
<span id="cb9-448"><a href="#cb9-448"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-449"><a href="#cb9-449"></a>    plt.imshow(reference_obj)</span>
<span id="cb9-450"><a href="#cb9-450"></a>    plt.title(<span class="st">"Reference Object"</span>)</span>
<span id="cb9-451"><a href="#cb9-451"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-452"><a href="#cb9-452"></a>    </span>
<span id="cb9-453"><a href="#cb9-453"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-454"><a href="#cb9-454"></a>    plt.imshow(result_img)</span>
<span id="cb9-455"><a href="#cb9-455"></a>    plt.title(<span class="st">"Recognition Results"</span>)</span>
<span id="cb9-456"><a href="#cb9-456"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-457"><a href="#cb9-457"></a>    </span>
<span id="cb9-458"><a href="#cb9-458"></a>    plt.tight_layout()</span>
<span id="cb9-459"><a href="#cb9-459"></a>    plt.show()</span>
<span id="cb9-460"><a href="#cb9-460"></a>    </span>
<span id="cb9-461"><a href="#cb9-461"></a>    <span class="cf">for</span> result <span class="kw">in</span> recognition_results:</span>
<span id="cb9-462"><a href="#cb9-462"></a>        <span class="bu">print</span>(<span class="ss">f"Found '</span><span class="sc">{</span>result[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">' with </span><span class="sc">{</span>result[<span class="st">'matches'</span>]<span class="sc">}</span><span class="ss"> matches (confidence: </span><span class="sc">{</span>result[<span class="st">'confidence'</span>]<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb9-463"><a href="#cb9-463"></a><span class="cf">else</span>:</span>
<span id="cb9-464"><a href="#cb9-464"></a>    <span class="bu">print</span>(<span class="st">"No objects recognized in the scene"</span>)</span>
<span id="cb9-465"><a href="#cb9-465"></a><span class="in">```</span></span>
<span id="cb9-466"><a href="#cb9-466"></a></span>
<span id="cb9-467"><a href="#cb9-467"></a><span class="fu">## Feature Detection Comparison</span></span>
<span id="cb9-468"><a href="#cb9-468"></a></span>
<span id="cb9-469"><a href="#cb9-469"></a>Let's compare different feature detectors to understand their strengths:</span>
<span id="cb9-470"><a href="#cb9-470"></a></span>
<span id="cb9-473"><a href="#cb9-473"></a><span class="in">```{python}</span></span>
<span id="cb9-474"><a href="#cb9-474"></a><span class="co">#| eval: false</span></span>
<span id="cb9-475"><a href="#cb9-475"></a><span class="kw">def</span> compare_feature_detectors(image):</span>
<span id="cb9-476"><a href="#cb9-476"></a>    <span class="co">"""Compare different feature detection algorithms"""</span></span>
<span id="cb9-477"><a href="#cb9-477"></a>    gray <span class="op">=</span> cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)</span>
<span id="cb9-478"><a href="#cb9-478"></a>    </span>
<span id="cb9-479"><a href="#cb9-479"></a>    <span class="co"># Different detectors</span></span>
<span id="cb9-480"><a href="#cb9-480"></a>    detectors <span class="op">=</span> {</span>
<span id="cb9-481"><a href="#cb9-481"></a>        <span class="st">'SIFT'</span>: cv2.SIFT_create(),</span>
<span id="cb9-482"><a href="#cb9-482"></a>        <span class="st">'ORB'</span>: cv2.ORB_create(),</span>
<span id="cb9-483"><a href="#cb9-483"></a>        <span class="st">'FAST'</span>: cv2.FastFeatureDetector_create(),</span>
<span id="cb9-484"><a href="#cb9-484"></a>        <span class="st">'BRISK'</span>: cv2.BRISK_create()</span>
<span id="cb9-485"><a href="#cb9-485"></a>    }</span>
<span id="cb9-486"><a href="#cb9-486"></a>    </span>
<span id="cb9-487"><a href="#cb9-487"></a>    results <span class="op">=</span> {}</span>
<span id="cb9-488"><a href="#cb9-488"></a>    </span>
<span id="cb9-489"><a href="#cb9-489"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">15</span>))</span>
<span id="cb9-490"><a href="#cb9-490"></a>    </span>
<span id="cb9-491"><a href="#cb9-491"></a>    <span class="cf">for</span> i, (name, detector) <span class="kw">in</span> <span class="bu">enumerate</span>(detectors.items()):</span>
<span id="cb9-492"><a href="#cb9-492"></a>        <span class="co"># Detect keypoints</span></span>
<span id="cb9-493"><a href="#cb9-493"></a>        <span class="cf">if</span> name <span class="kw">in</span> [<span class="st">'SIFT'</span>, <span class="st">'ORB'</span>, <span class="st">'BRISK'</span>]:</span>
<span id="cb9-494"><a href="#cb9-494"></a>            keypoints, descriptors <span class="op">=</span> detector.detectAndCompute(gray, <span class="va">None</span>)</span>
<span id="cb9-495"><a href="#cb9-495"></a>        <span class="cf">else</span>:  <span class="co"># FAST doesn't compute descriptors</span></span>
<span id="cb9-496"><a href="#cb9-496"></a>            keypoints <span class="op">=</span> detector.detect(gray, <span class="va">None</span>)</span>
<span id="cb9-497"><a href="#cb9-497"></a>            descriptors <span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-498"><a href="#cb9-498"></a>        </span>
<span id="cb9-499"><a href="#cb9-499"></a>        <span class="co"># Draw keypoints</span></span>
<span id="cb9-500"><a href="#cb9-500"></a>        img_with_kp <span class="op">=</span> cv2.drawKeypoints(image, keypoints, <span class="va">None</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>))</span>
<span id="cb9-501"><a href="#cb9-501"></a>        </span>
<span id="cb9-502"><a href="#cb9-502"></a>        <span class="co"># Store results</span></span>
<span id="cb9-503"><a href="#cb9-503"></a>        results[name] <span class="op">=</span> {</span>
<span id="cb9-504"><a href="#cb9-504"></a>            <span class="st">'keypoints'</span>: <span class="bu">len</span>(keypoints),</span>
<span id="cb9-505"><a href="#cb9-505"></a>            <span class="st">'has_descriptors'</span>: descriptors <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span></span>
<span id="cb9-506"><a href="#cb9-506"></a>        }</span>
<span id="cb9-507"><a href="#cb9-507"></a>        </span>
<span id="cb9-508"><a href="#cb9-508"></a>        <span class="co"># Plot</span></span>
<span id="cb9-509"><a href="#cb9-509"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">2</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb9-510"><a href="#cb9-510"></a>        plt.imshow(img_with_kp)</span>
<span id="cb9-511"><a href="#cb9-511"></a>        plt.title(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span><span class="bu">len</span>(keypoints)<span class="sc">}</span><span class="ss"> keypoints"</span>)</span>
<span id="cb9-512"><a href="#cb9-512"></a>        plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-513"><a href="#cb9-513"></a>    </span>
<span id="cb9-514"><a href="#cb9-514"></a>    plt.tight_layout()</span>
<span id="cb9-515"><a href="#cb9-515"></a>    plt.show()</span>
<span id="cb9-516"><a href="#cb9-516"></a>    </span>
<span id="cb9-517"><a href="#cb9-517"></a>    <span class="co"># Print comparison</span></span>
<span id="cb9-518"><a href="#cb9-518"></a>    <span class="bu">print</span>(<span class="st">"Feature Detector Comparison:"</span>)</span>
<span id="cb9-519"><a href="#cb9-519"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb9-520"><a href="#cb9-520"></a>    <span class="cf">for</span> name, data <span class="kw">in</span> results.items():</span>
<span id="cb9-521"><a href="#cb9-521"></a>        desc_info <span class="op">=</span> <span class="st">"Yes"</span> <span class="cf">if</span> data[<span class="st">'has_descriptors'</span>] <span class="cf">else</span> <span class="st">"No"</span></span>
<span id="cb9-522"><a href="#cb9-522"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">:10}</span><span class="ss"> | </span><span class="sc">{</span>data[<span class="st">'keypoints'</span>]<span class="sc">:4}</span><span class="ss"> keypoints | Descriptors: </span><span class="sc">{</span>desc_info<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-523"><a href="#cb9-523"></a>    </span>
<span id="cb9-524"><a href="#cb9-524"></a>    <span class="cf">return</span> results</span>
<span id="cb9-525"><a href="#cb9-525"></a></span>
<span id="cb9-526"><a href="#cb9-526"></a><span class="co"># Compare detectors on your image</span></span>
<span id="cb9-527"><a href="#cb9-527"></a>comparison_results <span class="op">=</span> compare_feature_detectors(img1_rgb)</span>
<span id="cb9-528"><a href="#cb9-528"></a><span class="in">```</span></span>
<span id="cb9-529"><a href="#cb9-529"></a></span>
<span id="cb9-530"><a href="#cb9-530"></a><span class="fu">## Your Challenge: Build a Photo Organizer</span></span>
<span id="cb9-531"><a href="#cb9-531"></a></span>
<span id="cb9-532"><a href="#cb9-532"></a>Now it's your turn! Build a system that can organize photos by finding similar images:</span>
<span id="cb9-533"><a href="#cb9-533"></a></span>
<span id="cb9-536"><a href="#cb9-536"></a><span class="in">```{python}</span></span>
<span id="cb9-537"><a href="#cb9-537"></a><span class="co">#| eval: false</span></span>
<span id="cb9-538"><a href="#cb9-538"></a><span class="kw">class</span> PhotoOrganizer:</span>
<span id="cb9-539"><a href="#cb9-539"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb9-540"><a href="#cb9-540"></a>        <span class="va">self</span>.detector <span class="op">=</span> cv2.ORB_create()</span>
<span id="cb9-541"><a href="#cb9-541"></a>        <span class="va">self</span>.matcher <span class="op">=</span> cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-542"><a href="#cb9-542"></a>        <span class="va">self</span>.photo_database <span class="op">=</span> {}</span>
<span id="cb9-543"><a href="#cb9-543"></a>    </span>
<span id="cb9-544"><a href="#cb9-544"></a>    <span class="kw">def</span> add_photo(<span class="va">self</span>, photo_id, image):</span>
<span id="cb9-545"><a href="#cb9-545"></a>        <span class="co">"""Add a photo to the database"""</span></span>
<span id="cb9-546"><a href="#cb9-546"></a>        <span class="co"># Your code here!</span></span>
<span id="cb9-547"><a href="#cb9-547"></a>        <span class="co"># Hint: Extract features and store them with the photo ID</span></span>
<span id="cb9-548"><a href="#cb9-548"></a>        <span class="cf">pass</span></span>
<span id="cb9-549"><a href="#cb9-549"></a>    </span>
<span id="cb9-550"><a href="#cb9-550"></a>    <span class="kw">def</span> find_similar_photos(<span class="va">self</span>, query_image, threshold<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb9-551"><a href="#cb9-551"></a>        <span class="co">"""Find photos similar to the query image"""</span></span>
<span id="cb9-552"><a href="#cb9-552"></a>        <span class="co"># Your code here!</span></span>
<span id="cb9-553"><a href="#cb9-553"></a>        <span class="co"># Hint: Match features with all photos in database</span></span>
<span id="cb9-554"><a href="#cb9-554"></a>        <span class="cf">pass</span></span>
<span id="cb9-555"><a href="#cb9-555"></a>    </span>
<span id="cb9-556"><a href="#cb9-556"></a>    <span class="kw">def</span> organize_by_similarity(<span class="va">self</span>, images):</span>
<span id="cb9-557"><a href="#cb9-557"></a>        <span class="co">"""Group similar images together"""</span></span>
<span id="cb9-558"><a href="#cb9-558"></a>        <span class="co"># Your code here!</span></span>
<span id="cb9-559"><a href="#cb9-559"></a>        <span class="co"># Hint: Compare all images with each other</span></span>
<span id="cb9-560"><a href="#cb9-560"></a>        <span class="cf">pass</span></span>
<span id="cb9-561"><a href="#cb9-561"></a></span>
<span id="cb9-562"><a href="#cb9-562"></a><span class="co"># Test your photo organizer</span></span>
<span id="cb9-563"><a href="#cb9-563"></a>organizer <span class="op">=</span> PhotoOrganizer()</span>
<span id="cb9-564"><a href="#cb9-564"></a><span class="co"># Add your implementation!</span></span>
<span id="cb9-565"><a href="#cb9-565"></a><span class="in">```</span></span>
<span id="cb9-566"><a href="#cb9-566"></a></span>
<span id="cb9-567"><a href="#cb9-567"></a><span class="fu">## What's Coming Next?</span></span>
<span id="cb9-568"><a href="#cb9-568"></a></span>
<span id="cb9-569"><a href="#cb9-569"></a>In our next post, <span class="co">[</span><span class="ot">**"Why Deep Learning? When Classical Methods Hit the Wall"**</span><span class="co">](../06-why-deep-learning/)</span>, we'll discover:</span>
<span id="cb9-570"><a href="#cb9-570"></a></span>
<span id="cb9-571"><a href="#cb9-571"></a><span class="ss">- </span>**The limitations** of classical computer vision</span>
<span id="cb9-572"><a href="#cb9-572"></a><span class="ss">- </span>**Why neural networks** changed everything</span>
<span id="cb9-573"><a href="#cb9-573"></a><span class="ss">- </span>**Your first deep learning model** for image classification</span>
<span id="cb9-574"><a href="#cb9-574"></a><span class="ss">- </span>**Transfer learning** (the secret to quick success)</span>
<span id="cb9-575"><a href="#cb9-575"></a></span>
<span id="cb9-576"><a href="#cb9-576"></a>You've mastered the art of finding and matching features—next, we'll explore how deep learning revolutionized computer vision!</span>
<span id="cb9-577"><a href="#cb9-577"></a></span>
<span id="cb9-578"><a href="#cb9-578"></a><span class="fu">## Key Takeaways</span></span>
<span id="cb9-579"><a href="#cb9-579"></a></span>
<span id="cb9-580"><a href="#cb9-580"></a><span class="ss">- </span>**Features are unique points** that can be reliably found across images</span>
<span id="cb9-581"><a href="#cb9-581"></a><span class="ss">- </span>**SIFT and ORB** are powerful feature detectors with different strengths</span>
<span id="cb9-582"><a href="#cb9-582"></a><span class="ss">- </span>**Feature matching** enables object recognition and image stitching</span>
<span id="cb9-583"><a href="#cb9-583"></a><span class="ss">- </span>**Homography** describes geometric transformations between images</span>
<span id="cb9-584"><a href="#cb9-584"></a><span class="ss">- </span>**Classical methods** work great for many applications</span>
<span id="cb9-585"><a href="#cb9-585"></a><span class="ss">- </span>**Feature-based approaches** are still used in modern systems</span>
<span id="cb9-586"><a href="#cb9-586"></a></span>
<span id="cb9-587"><a href="#cb9-587"></a>:::{.callout-tip}</span>
<span id="cb9-588"><a href="#cb9-588"></a><span class="fu">## Hands-On Lab</span></span>
<span id="cb9-589"><a href="#cb9-589"></a>Ready to extract and match features in your own images? Try the complete interactive notebook: <span class="co">[</span><span class="ot">**Feature Magic Lab**</span><span class="co">](https://colab.research.google.com/drive/1Feature_Magic_Lab_123456)</span></span>
<span id="cb9-590"><a href="#cb9-590"></a></span>
<span id="cb9-591"><a href="#cb9-591"></a>Build panoramas, recognize objects, and explore the magic of feature detection!</span>
<span id="cb9-592"><a href="#cb9-592"></a>:::</span>
<span id="cb9-593"><a href="#cb9-593"></a></span>
<span id="cb9-594"><a href="#cb9-594"></a>:::{.callout-note}</span>
<span id="cb9-595"><a href="#cb9-595"></a><span class="fu">## Series Navigation</span></span>
<span id="cb9-596"><a href="#cb9-596"></a><span class="ss">- </span>**Previous**: <span class="co">[</span><span class="ot">Finding Patterns: Edges, Contours, and Shapes</span><span class="co">](../04-finding-patterns/)</span></span>
<span id="cb9-597"><a href="#cb9-597"></a><span class="ss">- </span>**Next**: <span class="co">[</span><span class="ot">Why Deep Learning? When Classical Methods Hit the Wall</span><span class="co">](../06-why-deep-learning/)</span></span>
<span id="cb9-598"><a href="#cb9-598"></a><span class="ss">- </span>**Series Home**: <span class="co">[</span><span class="ot">Computer Vision Foundations</span><span class="co">](../computer-vision-foundations.qmd)</span></span>
<span id="cb9-599"><a href="#cb9-599"></a>:::</span>
<span id="cb9-600"><a href="#cb9-600"></a></span>
<span id="cb9-601"><a href="#cb9-601"></a>---</span>
<span id="cb9-602"><a href="#cb9-602"></a></span>
<span id="cb9-603"><a href="#cb9-603"></a>*You've just learned one of the most powerful techniques in computer vision! Feature matching is used in everything from Google Photos to archaeological site reconstruction. Next, we'll see why deep learning became necessary and how it builds on these foundations.* </span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>