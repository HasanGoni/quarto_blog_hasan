{
  "hash": "a0a33d0215d083e9a2afabac3344a37f",
  "result": {
    "markdown": "---\ntitle: Why Deep Learning? When Classical Methods Hit the Wall\nauthor: Hasan\ndate: '2025-01-22'\ncategories:\n  - computer-vision\n  - deep-learning\n  - neural-networks\n  - pytorch\ntags:\n  - cnn\n  - transfer-learning\n  - pytorch\n  - classification\nimage: 'https://images.unsplash.com/photo-1677442136019-21780ecad995?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2032&q=80'\ntoc: true\nseries:\n  name: Computer Vision Foundations\n  number: 6\nformat:\n  html: default\n---\n\n## The Great Computer Vision Crisis of 2010\n\nPicture this: It's 2010, and computer vision researchers are frustrated. They've spent decades perfecting edge detection, feature matching, and object recognition. Their algorithms can find corners, match keypoints, and even stitch panoramas.\n\nBut there's one problem they can't solve: **telling cats from dogs.**\n\nSeriously! While a 3-year-old child could easily distinguish between cats and dogs, the best computer vision systems struggled with this \"simple\" task. The classical approach required hand-crafting features for every possible variationâ€”different breeds, lighting conditions, poses, backgrounds. It was like trying to write rules for every possible way a cat could look. Impossible!\n\nThen something revolutionary happened...\n\n## The ImageNet Moment: 2012\n\nIn 2012, a team led by Alex Krizhevsky entered the ImageNet competition with something called **AlexNet**â€”a deep neural network. The results were shocking:\n\n- **Previous best accuracy**: 74.3%\n- **AlexNet accuracy**: 84.7%\n- **Improvement**: A massive 10+ percentage point jump!\n\nThis wasn't just an incremental improvementâ€”it was a paradigm shift. Deep learning had arrived, and computer vision would never be the same.\n\n## What Makes Deep Learning Different?\n\nLet's understand why neural networks succeeded where classical methods struggled:\n\n### Classical Approach: Hand-Crafted Features\n```python\n# Classical computer vision pipeline\ndef classical_cat_detector(image):\n    # Step 1: Extract hand-crafted features\n    edges = detect_edges(image)\n    corners = detect_corners(image)\n    textures = analyze_textures(image)\n    \n    # Step 2: Combine features with rules\n    if (pointy_ears and whiskers and fur_texture):\n        return \"cat\"\n    else:\n        return \"not_cat\"\n```\n\n**Problems:**\n- Features had to be manually designed\n- Rules were brittle and specific\n- Couldn't adapt to new variations\n- Required domain expertise\n\n### Deep Learning Approach: Learned Features\n```python\n# Deep learning pipeline\ndef deep_cat_detector(image):\n    # The network learns its own features!\n    features = neural_network.extract_features(image)\n    prediction = neural_network.classify(features)\n    return prediction\n```\n\n**Advantages:**\n- Features are learned automatically\n- Adapts to data variations\n- Improves with more data\n- Works across different domains\n\n## Your First Neural Network\n\nLet's build a simple neural network to understand the magic:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Simple neural network for image classification\nclass SimpleNet(nn.Module):\n    def __init__(self, num_classes=2):  # 2 classes: cat vs dog\n        super(SimpleNet, self).__init__()\n        \n        # Flatten 224x224x3 image to 150,528 features\n        self.flatten = nn.Flatten()\n        \n        # Simple fully connected layers\n        self.fc1 = nn.Linear(224 * 224 * 3, 512)\n        self.relu1 = nn.ReLU()\n        self.dropout1 = nn.Dropout(0.5)\n        \n        self.fc2 = nn.Linear(512, 128)\n        self.relu2 = nn.ReLU()\n        self.dropout2 = nn.Dropout(0.5)\n        \n        self.fc3 = nn.Linear(128, num_classes)\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.dropout1(self.relu1(self.fc1(x)))\n        x = self.dropout2(self.relu2(self.fc2(x)))\n        x = self.fc3(x)\n        return x\n\n# Create the network\nsimple_net = SimpleNet(num_classes=2)\nprint(\"Simple Neural Network:\")\nprint(simple_net)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in simple_net.parameters())\nprint(f\"\\nTotal parameters: {total_params:,}\")\n```\n:::\n\n\n**ðŸŽ¯ Try it yourself!** [Open in Colab](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-06-why-deep-learning.ipynb)\n\n## The Convolutional Revolution\n\nBut waitâ€”there's a problem with our simple network. It treats each pixel independently, ignoring spatial relationships. That's like reading a book by looking at each letter separately!\n\nEnter **Convolutional Neural Networks (CNNs)**â€”networks designed specifically for images:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ConvNet, self).__init__()\n        \n        # Convolutional layers (feature extractors)\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        \n        # Pooling layers (downsampling)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Fully connected layers (classifier)\n        self.fc1 = nn.Linear(128 * 28 * 28, 512)  # 224/8 = 28 after 3 pooling layers\n        self.fc2 = nn.Linear(512, num_classes)\n        \n        # Activation and regularization\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.5)\n    \n    def forward(self, x):\n        # Feature extraction\n        x = self.pool(self.relu(self.conv1(x)))  # 224x224 -> 112x112\n        x = self.pool(self.relu(self.conv2(x)))  # 112x112 -> 56x56\n        x = self.pool(self.relu(self.conv3(x)))  # 56x56 -> 28x28\n        \n        # Flatten and classify\n        x = x.view(x.size(0), -1)  # Flatten\n        x = self.dropout(self.relu(self.fc1(x)))\n        x = self.fc2(x)\n        \n        return x\n\n# Create CNN\ncnn = ConvNet(num_classes=2)\nprint(\"Convolutional Neural Network:\")\nprint(cnn)\n\n# Count parameters\ncnn_params = sum(p.numel() for p in cnn.parameters())\nprint(f\"\\nCNN parameters: {cnn_params:,}\")\nprint(f\"Simple net parameters: {total_params:,}\")\nprint(f\"CNN has {(total_params - cnn_params) / total_params * 100:.1f}% fewer parameters!\")\n```\n:::\n\n\n## Understanding Convolutions: The Sliding Window\n\nLet's visualize what convolutions actually do:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef visualize_convolution():\n    \"\"\"Show how convolution works\"\"\"\n    # Create a simple image\n    image = np.array([\n        [1, 1, 1, 0, 0],\n        [0, 1, 1, 1, 0],\n        [0, 0, 1, 1, 1],\n        [0, 0, 1, 1, 0],\n        [0, 1, 1, 0, 0]\n    ])\n    \n    # Edge detection kernel\n    kernel = np.array([\n        [-1, -1, -1],\n        [-1,  8, -1],\n        [-1, -1, -1]\n    ])\n    \n    # Apply convolution manually\n    result = np.zeros((3, 3))\n    \n    plt.figure(figsize=(15, 5))\n    \n    # Show original image\n    plt.subplot(1, 4, 1)\n    plt.imshow(image, cmap='gray')\n    plt.title(\"Original Image\")\n    plt.axis('off')\n    \n    # Show kernel\n    plt.subplot(1, 4, 2)\n    plt.imshow(kernel, cmap='RdBu')\n    plt.title(\"Edge Detection Kernel\")\n    plt.axis('off')\n    \n    # Show convolution process\n    for i in range(3):\n        for j in range(3):\n            patch = image[i:i+3, j:j+3]\n            result[i, j] = np.sum(patch * kernel)\n    \n    plt.subplot(1, 4, 3)\n    plt.imshow(result, cmap='gray')\n    plt.title(\"Convolution Result\")\n    plt.axis('off')\n    \n    # Show using PyTorch\n    image_tensor = torch.FloatTensor(image).unsqueeze(0).unsqueeze(0)\n    kernel_tensor = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n    \n    conv_layer = nn.Conv2d(1, 1, 3, bias=False)\n    conv_layer.weight.data = kernel_tensor\n    \n    pytorch_result = conv_layer(image_tensor).squeeze().detach().numpy()\n    \n    plt.subplot(1, 4, 4)\n    plt.imshow(pytorch_result, cmap='gray')\n    plt.title(\"PyTorch Result\")\n    plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_convolution()\n```\n:::\n\n\n## Transfer Learning: Standing on Giants' Shoulders\n\nHere's the secret that makes deep learning practical: **Transfer Learning**. Instead of training from scratch, we use pre-trained models and adapt them to our needs:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport torchvision.models as models\n\n# Load a pre-trained ResNet model\npretrained_model = models.resnet18(pretrained=True)\nprint(\"Pre-trained ResNet-18:\")\nprint(pretrained_model)\n\n# Modify for our task (cat vs dog classification)\nnum_classes = 2\npretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, num_classes)\n\nprint(f\"\\nModified final layer for {num_classes} classes\")\nprint(f\"Final layer: {pretrained_model.fc}\")\n\n# Freeze early layers (optional)\nfor param in pretrained_model.parameters():\n    param.requires_grad = False\n\n# Only train the final layer\nfor param in pretrained_model.fc.parameters():\n    param.requires_grad = True\n\ntrainable_params = sum(p.numel() for p in pretrained_model.parameters() if p.requires_grad)\ntotal_params = sum(p.numel() for p in pretrained_model.parameters())\n\nprint(f\"\\nTrainable parameters: {trainable_params:,}\")\nprint(f\"Total parameters: {total_params:,}\")\nprint(f\"Training only {trainable_params/total_params*100:.1f}% of parameters!\")\n```\n:::\n\n\n## Your First Image Classifier\n\nLet's build a complete image classification system:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nclass ImageClassifier:\n    def __init__(self, model_name='resnet18', num_classes=2):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"Using device: {self.device}\")\n        \n        # Load pre-trained model\n        if model_name == 'resnet18':\n            self.model = models.resnet18(pretrained=True)\n            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n        \n        self.model = self.model.to(self.device)\n        \n        # Define transforms\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.classes = ['cat', 'dog']  # Update based on your classes\n    \n    def predict(self, image):\n        \"\"\"Predict class of a single image\"\"\"\n        self.model.eval()\n        \n        # Preprocess image\n        if isinstance(image, np.ndarray):\n            from PIL import Image\n            image = Image.fromarray(image)\n        \n        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n        \n        # Make prediction\n        with torch.no_grad():\n            outputs = self.model(input_tensor)\n            probabilities = torch.softmax(outputs, dim=1)\n            predicted_class = torch.argmax(probabilities, dim=1).item()\n            confidence = probabilities[0][predicted_class].item()\n        \n        return {\n            'class': self.classes[predicted_class],\n            'confidence': confidence,\n            'probabilities': probabilities.cpu().numpy()[0]\n        }\n    \n    def predict_batch(self, images):\n        \"\"\"Predict classes for multiple images\"\"\"\n        results = []\n        for image in images:\n            result = self.predict(image)\n            results.append(result)\n        return results\n\n# Create classifier\nclassifier = ImageClassifier()\n\n# Test with a sample image (you would load your own)\ndef test_classifier(image_path):\n    from PIL import Image\n    \n    # Load image\n    image = Image.open(image_path)\n    \n    # Make prediction\n    result = classifier.predict(image)\n    \n    # Display result\n    plt.figure(figsize=(10, 6))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title(f\"Input Image\")\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    plt.bar(classifier.classes, result['probabilities'])\n    plt.title(f\"Prediction: {result['class']} ({result['confidence']:.2f})\")\n    plt.ylabel(\"Probability\")\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return result\n\n# Test the classifier\n# result = test_classifier('your_image.jpg')\n```\n:::\n\n\n## Visualizing What Neural Networks Learn\n\nOne of the coolest things about deep learning is visualizing what the network actually learns:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef visualize_filters(model, layer_name='conv1'):\n    \"\"\"Visualize the filters learned by a convolutional layer\"\"\"\n    \n    # Get the layer\n    layer = dict(model.named_modules())[layer_name]\n    \n    # Get the weights\n    weights = layer.weight.data.cpu()\n    \n    # Normalize weights for visualization\n    weights = (weights - weights.min()) / (weights.max() - weights.min())\n    \n    # Plot filters\n    num_filters = min(16, weights.shape[0])  # Show first 16 filters\n    \n    plt.figure(figsize=(12, 8))\n    \n    for i in range(num_filters):\n        plt.subplot(4, 4, i + 1)\n        \n        if weights.shape[1] == 3:  # RGB filters\n            # Transpose from (C, H, W) to (H, W, C)\n            filter_img = weights[i].permute(1, 2, 0)\n            plt.imshow(filter_img)\n        else:  # Grayscale filters\n            plt.imshow(weights[i, 0], cmap='gray')\n        \n        plt.title(f\"Filter {i+1}\")\n        plt.axis('off')\n    \n    plt.suptitle(f\"Learned Filters in {layer_name}\")\n    plt.tight_layout()\n    plt.show()\n\n# Visualize filters from our pre-trained model\nvisualize_filters(pretrained_model, 'conv1')\n```\n:::\n\n\n## Feature Maps: Seeing Through the Network's Eyes\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\ndef visualize_feature_maps(model, image, layer_name='layer1'):\n    \"\"\"Visualize feature maps from a specific layer\"\"\"\n    \n    # Hook to capture feature maps\n    feature_maps = []\n    \n    def hook_fn(module, input, output):\n        feature_maps.append(output.cpu())\n    \n    # Register hook\n    layer = dict(model.named_modules())[layer_name]\n    hook = layer.register_forward_hook(hook_fn)\n    \n    # Forward pass\n    model.eval()\n    with torch.no_grad():\n        _ = model(image.unsqueeze(0))\n    \n    # Remove hook\n    hook.remove()\n    \n    # Get feature maps\n    fmaps = feature_maps[0].squeeze(0)  # Remove batch dimension\n    \n    # Plot feature maps\n    num_maps = min(16, fmaps.shape[0])\n    \n    plt.figure(figsize=(12, 8))\n    \n    for i in range(num_maps):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(fmaps[i], cmap='viridis')\n        plt.title(f\"Feature Map {i+1}\")\n        plt.axis('off')\n    \n    plt.suptitle(f\"Feature Maps from {layer_name}\")\n    plt.tight_layout()\n    plt.show()\n\n# Create a sample input\nsample_input = torch.randn(3, 224, 224)\nvisualize_feature_maps(pretrained_model, sample_input)\n```\n:::\n\n\n## The Deep Learning Advantage: Why It Works\n\nLet's compare classical vs deep learning approaches on a real problem:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef compare_approaches(image):\n    \"\"\"Compare classical and deep learning approaches\"\"\"\n    \n    plt.figure(figsize=(15, 10))\n    \n    # Original image\n    plt.subplot(2, 3, 1)\n    plt.imshow(image)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n    \n    # Classical approach: hand-crafted features\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    \n    # Edge features\n    edges = cv2.Canny(gray, 50, 150)\n    plt.subplot(2, 3, 2)\n    plt.imshow(edges, cmap='gray')\n    plt.title(\"Classical: Edge Features\")\n    plt.axis('off')\n    \n    # Texture features (using LBP-like approach)\n    from skimage.feature import local_binary_pattern\n    lbp = local_binary_pattern(gray, 24, 8, method='uniform')\n    plt.subplot(2, 3, 3)\n    plt.imshow(lbp, cmap='gray')\n    plt.title(\"Classical: Texture Features\")\n    plt.axis('off')\n    \n    # Deep learning approach: learned features\n    # Transform image for the model\n    transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    input_tensor = transform(image).unsqueeze(0)\n    \n    # Get feature maps from different layers\n    feature_maps = []\n    \n    def get_features(name):\n        def hook(model, input, output):\n            feature_maps.append((name, output.cpu()))\n        return hook\n    \n    # Register hooks\n    pretrained_model.layer1.register_forward_hook(get_features('Low-level'))\n    pretrained_model.layer3.register_forward_hook(get_features('Mid-level'))\n    pretrained_model.layer4.register_forward_hook(get_features('High-level'))\n    \n    # Forward pass\n    pretrained_model.eval()\n    with torch.no_grad():\n        _ = pretrained_model(input_tensor)\n    \n    # Visualize learned features\n    for i, (name, fmaps) in enumerate(feature_maps):\n        plt.subplot(2, 3, 4 + i)\n        # Average across channels for visualization\n        avg_fmap = torch.mean(fmaps.squeeze(0), dim=0)\n        plt.imshow(avg_fmap, cmap='viridis')\n        plt.title(f\"Deep Learning: {name} Features\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Compare approaches (you would use your own image)\n# compare_approaches(your_image)\n```\n:::\n\n\n## Why Deep Learning Won\n\nHere's why deep learning revolutionized computer vision:\n\n### 1. **Automatic Feature Learning**\n- No need to hand-craft features\n- Learns optimal representations for the task\n- Adapts to data variations\n\n### 2. **Hierarchical Representations**\n- Low-level features (edges, textures)\n- Mid-level features (parts, patterns)  \n- High-level features (objects, concepts)\n\n### 3. **End-to-End Learning**\n- Optimizes entire pipeline together\n- Features and classifier learned jointly\n- Better overall performance\n\n### 4. **Scalability**\n- Performance improves with more data\n- Can handle complex, real-world variations\n- Generalizes across domains\n\n## The Modern Deep Learning Pipeline\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nclass ModernVisionPipeline:\n    def __init__(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        # 1. Data preprocessing\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(p=0.5),  # Data augmentation\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ])\n        \n        # 2. Model architecture\n        self.model = models.resnet50(pretrained=True)\n        \n        # 3. Transfer learning setup\n        # Freeze early layers\n        for param in list(self.model.parameters())[:-10]:\n            param.requires_grad = False\n        \n        # 4. Optimizer and loss\n        self.optimizer = optim.Adam(\n            filter(lambda p: p.requires_grad, self.model.parameters()),\n            lr=0.001\n        )\n        self.criterion = nn.CrossEntropyLoss()\n    \n    def train_step(self, images, labels):\n        \"\"\"Single training step\"\"\"\n        self.model.train()\n        \n        # Forward pass\n        outputs = self.model(images)\n        loss = self.criterion(outputs, labels)\n        \n        # Backward pass\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        return loss.item()\n    \n    def evaluate(self, images, labels):\n        \"\"\"Evaluation step\"\"\"\n        self.model.eval()\n        \n        with torch.no_grad():\n            outputs = self.model(images)\n            _, predicted = torch.max(outputs, 1)\n            accuracy = (predicted == labels).float().mean()\n        \n        return accuracy.item()\n\n# Create modern pipeline\npipeline = ModernVisionPipeline()\nprint(\"Modern deep learning pipeline ready!\")\n```\n:::\n\n\n## What's Coming Next?\n\nIn our next post, [**\"Modern Vision Models: CNNs, Vision Transformers, and DINOv2\"**](../07-modern-vision-models/), we'll explore:\n\n- **State-of-the-art architectures** (ResNet, EfficientNet, Vision Transformers)\n- **Foundation models** like DINOv2\n- **Self-supervised learning** (learning without labels)\n- **Building your own DINOv2 feature extractor**\n\nYou've just learned why deep learning revolutionized computer visionâ€”next, we'll explore the cutting-edge models that are shaping the future!\n\n## Key Takeaways\n\n- **Classical methods hit a wall** with complex real-world variations\n- **Deep learning learns features automatically** instead of hand-crafting them\n- **CNNs are designed for images** with spatial understanding\n- **Transfer learning** makes deep learning practical for everyone\n- **Hierarchical features** enable understanding at multiple levels\n- **Modern pipelines** combine data augmentation, pre-training, and fine-tuning\n\n:::{.callout-tip}\n## Hands-On Lab\nReady to build your first deep learning classifier? Try the complete interactive notebook: [**Deep Learning Basics Lab**](https://colab.research.google.com/drive/1Deep_Learning_Basics_123456)\n\nTrain your own cat vs dog classifier and see the power of neural networks!\n:::\n\n:::{.callout-note}\n## Series Navigation\n- **Previous**: [Feature Magic: What Makes Images Unique](../05-feature-magic/)\n- **Next**: [Modern Vision Models: CNNs, Vision Transformers, and DINOv2](../07-modern-vision-models/)\n- **Series Home**: [Computer Vision Foundations](../computer-vision-foundations.qmd)\n:::\n\n---\n\n*You've just witnessed the deep learning revolution! From struggling with cat vs dog classification to achieving superhuman performance on complex tasksâ€”this is why deep learning changed everything. Next, we'll explore the latest and greatest models that are pushing the boundaries even further.* \n\n",
    "supporting": [
      "06-why-deep-learning_files"
    ],
    "filters": [],
    "includes": {}
  }
}