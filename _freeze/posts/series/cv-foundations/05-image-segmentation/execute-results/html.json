{
  "hash": "116b0306436495eb29bdda7a04169c51",
  "result": {
    "markdown": "---\ntitle: 'Image Segmentation: Dividing and Conquering'\nauthor: Hasan\ndate: '2025-01-23'\ncategories:\n  - computer-vision\n  - segmentation\n  - morphology\n  - thresholding\ntags:\n  - segmentation\n  - thresholding\n  - watershed\n  - erosion\n  - dilation\n  - morphology\n  - contours\nimage: images/segmentation-header.jpg\ntoc: true\nseries:\n  name: Computer Vision Foundations\n  number: 5\nformat:\n  html: default\n---\n\n![Image segmentation concept - dividing images into meaningful regions](images/segmentation-header.jpg)\n\n## The Art of Divide and Conquer\n\nImagine you're looking at a crowded photo and trying to identify individual people. Your brain automatically separates the image into distinct regions—faces, bodies, background objects. This is exactly what **image segmentation** does: it divides an image into meaningful parts that we can analyze separately.\n\nToday, we'll master the classical techniques that form the foundation of modern computer vision. From simple thresholding to advanced morphological operations, you'll learn to segment images like a pro!\n\n:::{.callout-tip}\n**Try it yourself!** Open this [interactive Colab notebook](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-05-image-segmentation.ipynb) to experiment with segmentation techniques as we build this tutorial.\n:::\n\n## What is Image Segmentation?\n\n**Image segmentation** is the process of partitioning an image into multiple segments or regions. Each segment represents something meaningful—objects, boundaries, or areas of interest.\n\nThink of it like:\n- **Coloring book**: Each region gets its own color\n- **Jigsaw puzzle**: Breaking the image into pieces\n- **Map making**: Dividing territory into districts\n\n![Segmentation demonstration with multiple objects](images/segmentation-demo.jpg)\n\nThis synthetic image shows perfect segmentation targets:\n- **Bright objects** on dark background\n- **Different intensities** for various techniques\n- **Multiple shapes** to test robustness\n- **Noise elements** to challenge algorithms\n\n## Technique 1: Thresholding - The Foundation\n\n**Thresholding** is the simplest segmentation technique. It converts grayscale images to binary (black and white) by setting a threshold value.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load our synthetic segmentation demo image\nimg = cv2.imread('images/segmentation-demo.jpg')\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Simple thresholding\ndef apply_thresholding(image, threshold_value=127):\n    \"\"\"Apply different thresholding techniques\"\"\"\n    \n    # Simple binary thresholding\n    _, binary = cv2.threshold(image, threshold_value, 255, cv2.THRESH_BINARY)\n    \n    # Adaptive thresholding (handles varying lighting)\n    adaptive_mean = cv2.adaptiveThreshold(\n        image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2\n    )\n    \n    adaptive_gaussian = cv2.adaptiveThreshold(\n        image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n    )\n    \n    # Otsu's thresholding (automatically finds best threshold)\n    _, otsu = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    return binary, adaptive_mean, adaptive_gaussian, otsu\n\n# Apply different thresholding techniques\nbinary, adaptive_mean, adaptive_gaussian, otsu = apply_thresholding(gray)\n\n# Display results\nplt.figure(figsize=(20, 12))\n\nplt.subplot(2, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original Image\")\nplt.axis('off')\n\nplt.subplot(2, 3, 2)\nplt.imshow(gray, cmap='gray')\nplt.title(\"Grayscale\")\nplt.axis('off')\n\nplt.subplot(2, 3, 3)\nplt.imshow(binary, cmap='gray')\nplt.title(\"Binary Thresholding (T=127)\")\nplt.axis('off')\n\nplt.subplot(2, 3, 4)\nplt.imshow(adaptive_mean, cmap='gray')\nplt.title(\"Adaptive Mean Thresholding\")\nplt.axis('off')\n\nplt.subplot(2, 3, 5)\nplt.imshow(adaptive_gaussian, cmap='gray')\nplt.title(\"Adaptive Gaussian Thresholding\")\nplt.axis('off')\n\nplt.subplot(2, 3, 6)\nplt.imshow(otsu, cmap='gray')\nplt.title(\"Otsu's Automatic Thresholding\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"🎯 Thresholding Results:\")\nprint(f\"- Binary: Simple threshold at 127\")\nprint(f\"- Adaptive Mean: Local neighborhood average\")\nprint(f\"- Adaptive Gaussian: Weighted neighborhood average\")\nprint(f\"- Otsu: Automatically found optimal threshold\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-2-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🎯 Thresholding Results:\n- Binary: Simple threshold at 127\n- Adaptive Mean: Local neighborhood average\n- Adaptive Gaussian: Weighted neighborhood average\n- Otsu: Automatically found optimal threshold\n```\n:::\n:::\n\n\n**🔥 Amazing!** Each technique handles different scenarios:\n- **Binary**: Works when lighting is uniform\n- **Adaptive**: Handles varying lighting conditions\n- **Otsu**: Automatically finds the best threshold\n\n## Technique 2: Morphological Operations - Shape Surgery\n\n**Morphological operations** are like performing surgery on shapes. They can clean up noise, separate connected objects, or fill gaps.\n\n### The Core Operations\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Load our morphological demo image (designed for these operations)\nmorph_img = cv2.imread('images/morphological-demo.jpg', cv2.IMREAD_GRAYSCALE)\n\ndef demonstrate_morphological_operations(image):\n    \"\"\"Show the four basic morphological operations\"\"\"\n    \n    # Define structuring element (kernel)\n    kernel = np.ones((5, 5), np.uint8)\n    \n    # Basic operations\n    erosion = cv2.erode(image, kernel, iterations=1)\n    dilation = cv2.dilate(image, kernel, iterations=1)\n    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n    closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n    \n    # Advanced operations\n    gradient = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n    blackhat = cv2.morphologyEx(image, cv2.MORPH_BLACKHAT, kernel)\n    \n    return erosion, dilation, opening, closing, gradient, tophat, blackhat\n\n# Apply morphological operations\nerosion, dilation, opening, closing, gradient, tophat, blackhat = demonstrate_morphological_operations(morph_img)\n\n# Display results\nplt.figure(figsize=(20, 15))\n\nplt.subplot(3, 3, 1)\nplt.imshow(morph_img, cmap='gray')\nplt.title(\"Original (with noise and gaps)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 2)\nplt.imshow(erosion, cmap='gray')\nplt.title(\"Erosion (shrinks objects)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 3)\nplt.imshow(dilation, cmap='gray')\nplt.title(\"Dilation (expands objects)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 4)\nplt.imshow(opening, cmap='gray')\nplt.title(\"Opening (removes noise)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 5)\nplt.imshow(closing, cmap='gray')\nplt.title(\"Closing (fills gaps)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 6)\nplt.imshow(gradient, cmap='gray')\nplt.title(\"Gradient (edge detection)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 7)\nplt.imshow(tophat, cmap='gray')\nplt.title(\"Top Hat (small bright objects)\")\nplt.axis('off')\n\nplt.subplot(3, 3, 8)\nplt.imshow(blackhat, cmap='gray')\nplt.title(\"Black Hat (small dark objects)\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"🔧 Morphological Operations Explained:\")\nprint(\"- Erosion: Shrinks white regions (removes noise)\")\nprint(\"- Dilation: Expands white regions (fills small gaps)\")\nprint(\"- Opening: Erosion followed by dilation (removes small noise)\")\nprint(\"- Closing: Dilation followed by erosion (fills gaps in objects)\")\nprint(\"- Gradient: Difference between dilation and erosion (edges)\")\nprint(\"- Top Hat: Original minus opening (small bright features)\")\nprint(\"- Black Hat: Closing minus original (small dark features)\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-3-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🔧 Morphological Operations Explained:\n- Erosion: Shrinks white regions (removes noise)\n- Dilation: Expands white regions (fills small gaps)\n- Opening: Erosion followed by dilation (removes small noise)\n- Closing: Dilation followed by erosion (fills gaps in objects)\n- Gradient: Difference between dilation and erosion (edges)\n- Top Hat: Original minus opening (small bright features)\n- Black Hat: Closing minus original (small dark features)\n```\n:::\n:::\n\n\n### Understanding Kernels\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Different kernel shapes for different effects\ndef show_kernel_effects():\n    \"\"\"Demonstrate how different kernels affect morphological operations\"\"\"\n    \n    # Create different kernels\n    kernels = {\n        'Rectangle 3x3': np.ones((3, 3), np.uint8),\n        'Rectangle 7x7': np.ones((7, 7), np.uint8),\n        'Cross': cv2.getStructuringElement(cv2.MORPH_CROSS, (5, 5)),\n        'Ellipse': cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n    }\n    \n    results = {}\n    for name, kernel in kernels.items():\n        # Apply opening operation with different kernels\n        result = cv2.morphologyEx(morph_img, cv2.MORPH_OPEN, kernel)\n        results[name] = result\n    \n    return kernels, results\n\nkernels, kernel_results = show_kernel_effects()\n\n# Visualize kernel effects\nplt.figure(figsize=(20, 10))\n\nplt.subplot(2, 5, 1)\nplt.imshow(morph_img, cmap='gray')\nplt.title(\"Original\")\nplt.axis('off')\n\nfor i, (name, result) in enumerate(kernel_results.items(), 2):\n    plt.subplot(2, 5, i)\n    plt.imshow(result, cmap='gray')\n    plt.title(f\"Opening with {name}\")\n    plt.axis('off')\n\n# Show the kernels themselves\nfor i, (name, kernel) in enumerate(kernels.items(), 6):\n    plt.subplot(2, 5, i)\n    plt.imshow(kernel * 255, cmap='gray')\n    plt.title(f\"{name} Kernel\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"🎯 Kernel Shape Effects:\")\nprint(\"- Rectangle: General-purpose, preserves rectangular features\")\nprint(\"- Cross: Connects horizontal/vertical elements\")\nprint(\"- Ellipse: Preserves circular/curved features\")\nprint(\"- Size matters: Larger kernels = stronger effects\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-4-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🎯 Kernel Shape Effects:\n- Rectangle: General-purpose, preserves rectangular features\n- Cross: Connects horizontal/vertical elements\n- Ellipse: Preserves circular/curved features\n- Size matters: Larger kernels = stronger effects\n```\n:::\n:::\n\n\n## Technique 3: Watershed Segmentation - Flooding Algorithm\n\n**Watershed segmentation** treats the image like a topographic map and \"floods\" it to separate regions. Perfect for separating touching objects!\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy import ndimage\nfrom skimage.segmentation import watershed\n\ndef watershed_segmentation(image):\n    \"\"\"Apply watershed segmentation to separate touching objects\"\"\"\n    \n    # Convert to grayscale if needed\n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n    \n    # Apply threshold to get binary image\n    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # Remove noise with morphological opening\n    kernel = np.ones((3, 3), np.uint8)\n    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n    \n    # Find sure background area\n    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n    \n    # Find sure foreground area using distance transform\n    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n    \n    # Find unknown region\n    sure_fg = np.uint8(sure_fg)\n    unknown = cv2.subtract(sure_bg, sure_fg)\n    \n    # Marker labelling\n    _, markers = cv2.connectedComponents(sure_fg)\n    \n    # Add one to all labels so that sure background is not 0, but 1\n    markers = markers + 1\n    \n    # Mark the region of unknown with zero\n    markers[unknown == 255] = 0\n    \n    # Apply watershed\n    if len(image.shape) == 3:\n        markers = cv2.watershed(image, markers)\n        result = image.copy()\n        result[markers == -1] = [255, 0, 0]  # Mark boundaries in red\n    else:\n        # For grayscale, create a color version for visualization\n        result = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n        markers_watershed = cv2.watershed(result, markers)\n        result[markers_watershed == -1] = [255, 0, 0]\n    \n    return binary, sure_bg, sure_fg, unknown, markers, result\n\n# Apply watershed to our demo image\nbinary, sure_bg, sure_fg, unknown, markers, watershed_result = watershed_segmentation(img_rgb)\n\n# Display watershed process\nplt.figure(figsize=(20, 15))\n\nplt.subplot(3, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original Image\")\nplt.axis('off')\n\nplt.subplot(3, 3, 2)\nplt.imshow(binary, cmap='gray')\nplt.title(\"Binary Threshold\")\nplt.axis('off')\n\nplt.subplot(3, 3, 3)\nplt.imshow(sure_bg, cmap='gray')\nplt.title(\"Sure Background\")\nplt.axis('off')\n\nplt.subplot(3, 3, 4)\nplt.imshow(sure_fg, cmap='gray')\nplt.title(\"Sure Foreground\")\nplt.axis('off')\n\nplt.subplot(3, 3, 5)\nplt.imshow(unknown, cmap='gray')\nplt.title(\"Unknown Region\")\nplt.axis('off')\n\nplt.subplot(3, 3, 6)\nplt.imshow(markers, cmap='tab20')\nplt.title(\"Markers\")\nplt.axis('off')\n\nplt.subplot(3, 3, 7)\nplt.imshow(watershed_result)\nplt.title(\"Watershed Result\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"🌊 Watershed Segmentation Steps:\")\nprint(\"1. Threshold to get binary image\")\nprint(\"2. Find sure background (dilated objects)\")\nprint(\"3. Find sure foreground (distance transform peaks)\")\nprint(\"4. Mark unknown regions between sure areas\")\nprint(\"5. Apply watershed algorithm to flood from markers\")\nprint(\"6. Red lines show the watershed boundaries!\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-5-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🌊 Watershed Segmentation Steps:\n1. Threshold to get binary image\n2. Find sure background (dilated objects)\n3. Find sure foreground (distance transform peaks)\n4. Mark unknown regions between sure areas\n5. Apply watershed algorithm to flood from markers\n6. Red lines show the watershed boundaries!\n```\n:::\n:::\n\n\n## Technique 4: Contour-Based Segmentation\n\n**Contours** are the boundaries of objects. We can use them to segment and analyze individual objects.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndef contour_segmentation(image):\n    \"\"\"Find and analyze contours for segmentation\"\"\"\n    \n    # Convert to grayscale\n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n    \n    # Apply threshold\n    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # Find contours\n    contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Create result image\n    result = image.copy() if len(image.shape) == 3 else cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n    \n    # Analyze each contour\n    contour_info = []\n    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n    \n    for i, contour in enumerate(contours):\n        # Calculate contour properties\n        area = cv2.contourArea(contour)\n        perimeter = cv2.arcLength(contour, True)\n        \n        # Filter small contours (noise)\n        if area > 500:  # Minimum area threshold\n            # Get bounding rectangle\n            x, y, w, h = cv2.boundingRect(contour)\n            \n            # Get center\n            M = cv2.moments(contour)\n            if M[\"m00\"] != 0:\n                cx = int(M[\"m10\"] / M[\"m00\"])\n                cy = int(M[\"m01\"] / M[\"m00\"])\n            else:\n                cx, cy = 0, 0\n            \n            # Draw contour and info\n            color = colors[i % len(colors)]\n            cv2.drawContours(result, [contour], -1, color, 3)\n            cv2.rectangle(result, (x, y), (x + w, y + h), color, 2)\n            cv2.circle(result, (cx, cy), 5, color, -1)\n            \n            # Add text\n            cv2.putText(result, f\"#{i+1}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n            \n            contour_info.append({\n                'id': i+1,\n                'area': area,\n                'perimeter': perimeter,\n                'center': (cx, cy),\n                'bounding_box': (x, y, w, h)\n            })\n    \n    return binary, result, contour_info\n\n# Apply contour segmentation\nbinary_contours, contour_result, contour_info = contour_segmentation(img_rgb)\n\n# Display results\nplt.figure(figsize=(15, 8))\n\nplt.subplot(1, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original Image\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(binary_contours, cmap='gray')\nplt.title(\"Binary Image\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(contour_result)\nplt.title(\"Contour Segmentation\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Print contour analysis\nprint(\"🔍 Contour Analysis Results:\")\nprint(\"-\" * 50)\nfor info in contour_info:\n    print(f\"Object #{info['id']}:\")\n    print(f\"  Area: {info['area']:.0f} pixels\")\n    print(f\"  Perimeter: {info['perimeter']:.1f} pixels\")\n    print(f\"  Center: {info['center']}\")\n    print(f\"  Bounding box: {info['bounding_box']}\")\n    print()\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-6-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🔍 Contour Analysis Results:\n--------------------------------------------------\nObject #1:\n  Area: 2736 pixels\n  Perimeter: 197.8 pixels\n  Center: (650, 500)\n  Bounding box: (620, 470, 61, 61)\n\nObject #2:\n  Area: 15000 pixels\n  Perimeter: 582.8 pixels\n  Center: (150, 449)\n  Bounding box: (50, 350, 201, 151)\n\nObject #3:\n  Area: 42662 pixels\n  Perimeter: 1073.3 pixels\n  Center: (425, 416)\n  Bounding box: (300, 300, 301, 251)\n\nObject #4:\n  Area: 1890 pixels\n  Perimeter: 164.9 pixels\n  Center: (700, 300)\n  Bounding box: (675, 275, 51, 51)\n\nObject #5:\n  Area: 1200 pixels\n  Perimeter: 131.9 pixels\n  Center: (100, 250)\n  Bounding box: (80, 230, 41, 41)\n\nObject #6:\n  Area: 20000 pixels\n  Perimeter: 600.0 pixels\n  Center: (500, 150)\n  Bounding box: (400, 100, 201, 101)\n\nObject #7:\n  Area: 19854 pixels\n  Perimeter: 529.9 pixels\n  Center: (200, 150)\n  Bounding box: (120, 70, 161, 161)\n\n```\n:::\n:::\n\n\n## Real-World Application: Document Cleaning\n\nLet's combine multiple techniques to clean up a noisy document:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef document_cleaning_pipeline(image):\n    \"\"\"Complete pipeline for cleaning scanned documents\"\"\"\n    \n    # Step 1: Convert to grayscale\n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n    \n    # Step 2: Apply adaptive thresholding\n    binary = cv2.adaptiveThreshold(\n        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n    )\n    \n    # Step 3: Remove noise with opening\n    kernel_noise = np.ones((2, 2), np.uint8)\n    denoised = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_noise)\n    \n    # Step 4: Fill gaps in text with closing\n    kernel_fill = np.ones((3, 3), np.uint8)\n    filled = cv2.morphologyEx(denoised, cv2.MORPH_CLOSE, kernel_fill)\n    \n    # Step 5: Enhance text with dilation\n    kernel_enhance = np.ones((2, 2), np.uint8)\n    enhanced = cv2.dilate(filled, kernel_enhance, iterations=1)\n    \n    return gray, binary, denoised, filled, enhanced\n\n# Apply document cleaning to our morphological demo\ngray_doc, binary_doc, denoised_doc, filled_doc, enhanced_doc = document_cleaning_pipeline(morph_img)\n\n# Display the cleaning pipeline\nplt.figure(figsize=(20, 12))\n\nplt.subplot(2, 3, 1)\nplt.imshow(gray_doc, cmap='gray')\nplt.title(\"1. Original Grayscale\")\nplt.axis('off')\n\nplt.subplot(2, 3, 2)\nplt.imshow(binary_doc, cmap='gray')\nplt.title(\"2. Adaptive Threshold\")\nplt.axis('off')\n\nplt.subplot(2, 3, 3)\nplt.imshow(denoised_doc, cmap='gray')\nplt.title(\"3. Noise Removal (Opening)\")\nplt.axis('off')\n\nplt.subplot(2, 3, 4)\nplt.imshow(filled_doc, cmap='gray')\nplt.title(\"4. Gap Filling (Closing)\")\nplt.axis('off')\n\nplt.subplot(2, 3, 5)\nplt.imshow(enhanced_doc, cmap='gray')\nplt.title(\"5. Text Enhancement (Dilation)\")\nplt.axis('off')\n\n# Show before/after comparison\nplt.subplot(2, 3, 6)\ncomparison = np.hstack([gray_doc, enhanced_doc])\nplt.imshow(comparison, cmap='gray')\nplt.title(\"Before → After\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"📄 Document Cleaning Pipeline:\")\nprint(\"✅ Adaptive thresholding handles varying lighting\")\nprint(\"✅ Opening removes small noise pixels\")\nprint(\"✅ Closing fills gaps in letters\")\nprint(\"✅ Dilation strengthens text strokes\")\nprint(\"🎯 Result: Clean, readable text!\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-7-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n📄 Document Cleaning Pipeline:\n✅ Adaptive thresholding handles varying lighting\n✅ Opening removes small noise pixels\n✅ Closing fills gaps in letters\n✅ Dilation strengthens text strokes\n🎯 Result: Clean, readable text!\n```\n:::\n:::\n\n\n## Segmentation Comparison Tool\n\nLet's create a tool to compare all segmentation techniques side by side:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef compare_segmentation_techniques(image):\n    \"\"\"Compare multiple segmentation techniques on the same image\"\"\"\n    \n    # Convert to grayscale\n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image\n    \n    techniques = {}\n    \n    # 1. Simple thresholding\n    _, techniques['Binary Threshold'] = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n    \n    # 2. Otsu's thresholding\n    _, techniques['Otsu Threshold'] = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # 3. Adaptive thresholding\n    techniques['Adaptive Threshold'] = cv2.adaptiveThreshold(\n        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n    )\n    \n    # 4. Morphological opening\n    kernel = np.ones((5, 5), np.uint8)\n    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    techniques['Morphological Opening'] = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n    \n    # 5. Morphological closing\n    techniques['Morphological Closing'] = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n    \n    return techniques\n\n# Compare techniques on our demo image\ntechniques = compare_segmentation_techniques(img_rgb)\n\n# Display comparison\nplt.figure(figsize=(20, 15))\n\nplt.subplot(2, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original Image\")\nplt.axis('off')\n\nfor i, (name, result) in enumerate(techniques.items(), 2):\n    plt.subplot(2, 3, i)\n    plt.imshow(result, cmap='gray')\n    plt.title(name)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"🎯 Technique Comparison:\")\nprint(\"- Binary: Simple but effective for uniform lighting\")\nprint(\"- Otsu: Automatically finds optimal threshold\")\nprint(\"- Adaptive: Handles varying lighting conditions\")\nprint(\"- Opening: Removes noise while preserving object shape\")\nprint(\"- Closing: Fills gaps and connects broken parts\")\n```\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-8-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n🎯 Technique Comparison:\n- Binary: Simple but effective for uniform lighting\n- Otsu: Automatically finds optimal threshold\n- Adaptive: Handles varying lighting conditions\n- Opening: Removes noise while preserving object shape\n- Closing: Fills gaps and connects broken parts\n```\n:::\n:::\n\n\n## Your Challenge: Medical Image Segmentation\n\nNow it's your turn! Here's a framework for a medical image segmentation system:\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nclass MedicalImageSegmenter:\n    def __init__(self):\n        self.techniques = {\n            'threshold': self.threshold_segment,\n            'morphological': self.morphological_segment,\n            'watershed': self.watershed_segment,\n            'contour': self.contour_segment\n        }\n    \n    def threshold_segment(self, image, method='otsu'):\n        \"\"\"Apply thresholding segmentation\"\"\"\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        else:\n            gray = image\n            \n        if method == 'otsu':\n            _, result = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        elif method == 'adaptive':\n            result = cv2.adaptiveThreshold(\n                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n            )\n        else:\n            _, result = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n        \n        return result\n    \n    def morphological_segment(self, image, operation='opening', kernel_size=5):\n        \"\"\"Apply morphological operations\"\"\"\n        # First get binary image\n        binary = self.threshold_segment(image, 'otsu')\n        \n        # Apply morphological operation\n        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n        \n        if operation == 'opening':\n            result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n        elif operation == 'closing':\n            result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n        elif operation == 'gradient':\n            result = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)\n        else:\n            result = binary\n            \n        return result\n    \n    def watershed_segment(self, image):\n        \"\"\"Apply watershed segmentation\"\"\"\n        # This is a simplified version\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        else:\n            gray = image\n            \n        # Apply threshold\n        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        \n        # Distance transform\n        dist_transform = cv2.distanceTransform(binary, cv2.DIST_L2, 5)\n        \n        # Find local maxima\n        _, markers = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n        \n        return markers.astype(np.uint8)\n    \n    def contour_segment(self, image, min_area=100):\n        \"\"\"Segment using contours\"\"\"\n        binary = self.threshold_segment(image, 'otsu')\n        \n        # Find contours\n        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        # Create result image\n        result = np.zeros_like(binary)\n        \n        # Draw significant contours\n        for contour in contours:\n            if cv2.contourArea(contour) > min_area:\n                cv2.drawContours(result, [contour], -1, 255, -1)\n        \n        return result\n    \n    def analyze_segments(self, segmented_image):\n        \"\"\"Analyze segmented regions\"\"\"\n        # Find connected components\n        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image)\n        \n        analysis = {\n            'num_objects': num_labels - 1,  # Subtract background\n            'total_area': np.sum(stats[1:, cv2.CC_STAT_AREA]),  # Exclude background\n            'average_area': np.mean(stats[1:, cv2.CC_STAT_AREA]) if num_labels > 1 else 0,\n            'largest_area': np.max(stats[1:, cv2.CC_STAT_AREA]) if num_labels > 1 else 0\n        }\n        \n        return analysis\n\n# Example usage\nsegmenter = MedicalImageSegmenter()\n\n# Apply different techniques to our demo image\nresults = {}\nfor name, method in segmenter.techniques.items():\n    if name == 'morphological':\n        results[name] = method(img_rgb, 'opening')\n    else:\n        results[name] = method(img_rgb)\n\n# Analyze results\nprint(\"🏥 Medical Image Segmentation Analysis:\")\nprint(\"=\" * 50)\n\nfor name, result in results.items():\n    analysis = segmenter.analyze_segments(result)\n    print(f\"\\n{name.upper()} TECHNIQUE:\")\n    print(f\"  Objects detected: {analysis['num_objects']}\")\n    print(f\"  Total area: {analysis['total_area']} pixels\")\n    print(f\"  Average area: {analysis['average_area']:.1f} pixels\")\n    print(f\"  Largest area: {analysis['largest_area']} pixels\")\n\n# Visualize results\nplt.figure(figsize=(20, 10))\n\nplt.subplot(2, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original Image\")\nplt.axis('off')\n\nfor i, (name, result) in enumerate(results.items(), 2):\n    plt.subplot(2, 3, i)\n    plt.imshow(result, cmap='gray')\n    plt.title(f\"{name.title()} Segmentation\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n💡 Challenge: Try this framework on medical images!\")\nprint(\"- X-rays: Segment bones from soft tissue\")\nprint(\"- MRI scans: Identify different brain regions\")\nprint(\"- Cell images: Count and measure individual cells\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n🏥 Medical Image Segmentation Analysis:\n==================================================\n\nTHRESHOLD TECHNIQUE:\n  Objects detected: 7\n  Total area: 104849 pixels\n  Average area: 14978.4 pixels\n  Largest area: 43177 pixels\n\nMORPHOLOGICAL TECHNIQUE:\n  Objects detected: 7\n  Total area: 104810 pixels\n  Average area: 14972.9 pixels\n  Largest area: 43177 pixels\n\nWATERSHED TECHNIQUE:\n  Objects detected: 3\n  Total area: 4742 pixels\n  Average area: 1580.7 pixels\n  Largest area: 2375 pixels\n\nCONTOUR TECHNIQUE:\n  Objects detected: 7\n  Total area: 104849 pixels\n  Average area: 14978.4 pixels\n  Largest area: 43177 pixels\n\n💡 Challenge: Try this framework on medical images!\n- X-rays: Segment bones from soft tissue\n- MRI scans: Identify different brain regions\n- Cell images: Count and measure individual cells\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](05-image-segmentation_files/figure-html/cell-9-output-2.png){}\n:::\n:::\n\n\n## Key Takeaways\n\n- **Thresholding** is your first line of defense - simple but powerful\n- **Morphological operations** are like image surgery tools - they reshape and clean\n- **Watershed** excels at separating touching objects\n- **Contour analysis** gives you detailed object measurements\n- **Combine techniques** for robust real-world applications\n\n## What's Coming Next?\n\nIn our next post, [**\"Feature Magic: What Makes Images Unique\"**](06-feature-magic.qmd), we'll discover:\n\n- **SIFT and ORB** feature detectors\n- **Feature matching** between images\n- **Object recognition** using keypoints\n- **Panorama stitching** with feature alignment\n\nYou've mastered the art of dividing images into meaningful parts—next, we'll learn to find the unique fingerprints that make each image special!\n\n:::{.callout-tip}\n## Hands-On Lab\nReady to segment your own images? Try the complete interactive notebook: [**Image Segmentation Lab**](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-05-image-segmentation.ipynb)\n\nExperiment with medical images, document cleaning, and object counting!\n:::\n\n:::{.callout-note}\n## Series Navigation\n- **Previous**: [Finding Patterns: Edges, Contours, and Shapes](04-finding-patterns.qmd)\n- **Next**: [Feature Magic: What Makes Images Unique](06-feature-magic.qmd)\n- **Series Home**: [Computer Vision Foundations](../computer-vision-foundations.qmd)\n:::\n\n---\n\n*You've just learned the fundamental techniques for breaking images into meaningful parts! Segmentation is used everywhere from medical imaging to autonomous vehicles. Next, we'll explore how to find unique features that make images recognizable.* \n\n",
    "supporting": [
      "05-image-segmentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}