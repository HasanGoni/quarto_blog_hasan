{
  "hash": "3e5d3e18de70e83c6b0bd7e8574a8bec",
  "result": {
    "markdown": "---\ntitle: 'OpenCV Essentials: Your First Computer Vision Toolkit'\nauthor: Hasan\ndate: '2025-01-22'\ncategories:\n  - computer-vision\n  - opencv\n  - image-processing\ntags:\n  - opencv\n  - python\n  - resize\n  - crop\n  - rotate\n  - filters\nimage: 'https://images.unsplash.com/photo-1551033406-611cf9a28f67?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2067&q=80'\ntoc: true\nseries:\n  name: Computer Vision Foundations\n  number: 3\nformat:\n  html: default\n---\n\n## Meet Your New Best Friend: OpenCV\n\nImagine you're a carpenter, and someone hands you the ultimate toolboxâ€”every tool you could ever need, perfectly organized and ready to use. That's OpenCV for computer vision! \n\n**OpenCV** (Open Source Computer Vision Library) is like having a Swiss Army knife that can:\n- Resize photos faster than Photoshop\n- Find faces in crowds\n- Track moving objects\n- Apply Instagram-worthy filters\n- And about 2,500+ other amazing things!\n\nThe best part? It's completely free and used by everyone from Google to your neighbor's startup.\n\n## The Origin Story\n\nBack in 1999, Intel created OpenCV to accelerate computer vision research. Fast forward 25 years, and it's become the **#1 computer vision library** in the world. Every self-driving car, security camera, and photo app uses OpenCV under the hood.\n\nToday, we're going to master the essential 20% that gives you 80% of the power!\n\n## Your First OpenCV Adventure\nYou can use any photo. Just make sure it's in the same folder as this notebook or provide the full path.\nLet's start with the basicsâ€”loading and displaying an image:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load an image (OpenCV reads in BGR format by default)\nimg = cv2.imread('images/image.jpg')\n\n# Convert BGR to RGB (for matplotlib display)\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nprint(f\"Image shape: {img_rgb.shape}\")\nprint(f\"Image size: {img_rgb.size} total pixels\")\n\n# Display the image\nplt.figure(figsize=(10, 6))\nplt.imshow(img_rgb)\nplt.title(\"Your Photo Loaded with OpenCV!\")\nplt.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nImage shape: (627, 1200, 3)\nImage size: 2257200 total pixels\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-2-output-2.png){}\n:::\n:::\n\n\n**ðŸŽ¯ Try it yourself!** [Open in Colab](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-03-opencv-essentials.ipynb)\n\n## The Essential Operations: Your Daily Toolkit\n\n### 1. Resizing: Making Images Fit\n\nThink of resizing like adjusting a picture frameâ€”sometimes you need it bigger, sometimes smaller:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Original image\nheight, width = img_rgb.shape[:2]\nprint(f\"Original size: {width} x {height}\")\n\n# Method 1: Specify exact dimensions\nresized_exact = cv2.resize(img_rgb, (400, 300))\n\n# Method 2: Scale by percentage\nscale_percent = 50  # 50% of original size\nnew_width = int(width * scale_percent / 100)\nnew_height = int(height * scale_percent / 100)\nresized_scaled = cv2.resize(img_rgb, (new_width, new_height))\n\n# Method 3: Keep aspect ratio (the smart way!)\ndef resize_with_aspect_ratio(image, width=None, height=None):\n    h, w = image.shape[:2]\n    \n    if width is None and height is None:\n        return image\n    \n    if width is None:\n        # Calculate width based on height\n        ratio = height / h\n        width = int(w * ratio)\n    else:\n        # Calculate height based on width\n        ratio = width / w\n        height = int(h * ratio)\n    \n    return cv2.resize(image, (width, height))\n\nresized_smart = resize_with_aspect_ratio(img_rgb, width=400)\n\n# Show the results\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.imshow(resized_exact)\nplt.title(f\"Exact: 400x300\\n(might be distorted)\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(resized_scaled)\nplt.title(f\"Scaled: 50%\\n{new_width}x{new_height}\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(resized_smart)\nplt.title(f\"Smart Resize\\nAspect ratio preserved\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal size: 1200 x 627\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-3-output-2.png){}\n:::\n:::\n\n\n### 2. Cropping: Focus on What Matters\n\nCropping is like using scissors on a digital photoâ€”you keep the interesting part and throw away the rest:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Cropping is just array slicing!\nheight, width = img_rgb.shape[:2]\n\n# Center crop (most common)\ncrop_size = 300\nstart_x = (width - crop_size) // 2\nstart_y = (height - crop_size) // 2\ncenter_crop = img_rgb[start_y:start_y+crop_size, start_x:start_x+crop_size]\n\n# Top-left crop\ntop_left_crop = img_rgb[0:300, 0:300]\n\n# Bottom-right crop\nbottom_right_crop = img_rgb[height-300:height, width-300:width]\n\n# Custom crop function\ndef smart_crop(image, x, y, width, height):\n    \"\"\"Crop with bounds checking\"\"\"\n    h, w = image.shape[:2]\n    \n    # Make sure we don't go out of bounds\n    x = max(0, min(x, w - width))\n    y = max(0, min(y, h - height))\n    width = min(width, w - x)\n    height = min(height, h - y)\n    \n    return image[y:y+height, x:x+width]\n\ncustom_crop = smart_crop(img_rgb, 100, 50, 400, 300)\n\n# Display results\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\nplt.imshow(center_crop)\nplt.title(\"Center Crop\")\nplt.axis('off')\n\nplt.subplot(2, 2, 2)\nplt.imshow(top_left_crop)\nplt.title(\"Top-Left Crop\")\nplt.axis('off')\n\nplt.subplot(2, 2, 3)\nplt.imshow(bottom_right_crop)\nplt.title(\"Bottom-Right Crop\")\nplt.axis('off')\n\nplt.subplot(2, 2, 4)\nplt.imshow(custom_crop)\nplt.title(\"Custom Crop\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\n### 3. Rotation: Spinning Photos Like a DJ\n\nSometimes your photo is sideways, or you want a creative angle. OpenCV makes rotation easy:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef rotate_image(image, angle):\n    \"\"\"Rotate image by angle (in degrees)\"\"\"\n    height, width = image.shape[:2]\n    \n    # Get rotation matrix\n    center = (width // 2, height // 2)\n    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n    \n    # Apply rotation\n    rotated = cv2.warpAffine(image, rotation_matrix, (width, height))\n    return rotated\n\ndef rotate_and_crop(image, angle):\n    \"\"\"Rotate and crop to remove black borders\"\"\"\n    height, width = image.shape[:2]\n    center = (width // 2, height // 2)\n    \n    # Calculate new dimensions to avoid black borders\n    angle_rad = np.radians(abs(angle))\n    new_width = int(width * np.cos(angle_rad) + height * np.sin(angle_rad))\n    new_height = int(height * np.cos(angle_rad) + width * np.sin(angle_rad))\n    \n    # Get rotation matrix\n    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n    \n    # Adjust translation\n    rotation_matrix[0, 2] += (new_width - width) / 2\n    rotation_matrix[1, 2] += (new_height - height) / 2\n    \n    # Apply rotation\n    rotated = cv2.warpAffine(image, rotation_matrix, (new_width, new_height))\n    return rotated\n\n# Try different rotations\nangles = [15, 45, 90, 180]\nplt.figure(figsize=(15, 10))\n\nfor i, angle in enumerate(angles):\n    rotated = rotate_image(img_rgb, angle)\n    \n    plt.subplot(2, 2, i+1)\n    plt.imshow(rotated)\n    plt.title(f\"Rotated {angle}Â°\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\n### 4. Flipping: Mirror, Mirror on the Wall\n\nFlipping is like looking in a mirrorâ€”super simple but very useful:\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Horizontal flip (left-right mirror)\nflipped_horizontal = cv2.flip(img_rgb, 1)\n\n# Vertical flip (upside down)\nflipped_vertical = cv2.flip(img_rgb, 0)\n\n# Both directions (180Â° rotation equivalent)\nflipped_both = cv2.flip(img_rgb, -1)\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 4, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original\")\nplt.axis('off')\n\nplt.subplot(1, 4, 2)\nplt.imshow(flipped_horizontal)\nplt.title(\"Horizontal Flip\")\nplt.axis('off')\n\nplt.subplot(1, 4, 3)\nplt.imshow(flipped_vertical)\nplt.title(\"Vertical Flip\")\nplt.axis('off')\n\nplt.subplot(1, 4, 4)\nplt.imshow(flipped_both)\nplt.title(\"Both Directions\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\n## Color Space Adventures\n\nRemember how we learned about RGB? OpenCV knows many other color spaces too! Each one is useful for different tasks:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Convert to different color spaces\ngray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\nhsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\nlab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n\nplt.figure(figsize=(15, 10))\n\n# Original RGB\nplt.subplot(2, 3, 1)\nplt.imshow(img_rgb)\nplt.title(\"RGB (Red, Green, Blue)\")\nplt.axis('off')\n\n# Grayscale\nplt.subplot(2, 3, 2)\nplt.imshow(gray, cmap='gray')\nplt.title(\"Grayscale\")\nplt.axis('off')\n\n# HSV channels\nplt.subplot(2, 3, 3)\nplt.imshow(hsv[:, :, 0], cmap='hsv')  # Hue\nplt.title(\"HSV - Hue Channel\")\nplt.axis('off')\n\nplt.subplot(2, 3, 4)\nplt.imshow(hsv[:, :, 1], cmap='gray')  # Saturation\nplt.title(\"HSV - Saturation Channel\")\nplt.axis('off')\n\nplt.subplot(2, 3, 5)\nplt.imshow(hsv[:, :, 2], cmap='gray')  # Value\nplt.title(\"HSV - Value Channel\")\nplt.axis('off')\n\n# LAB\nplt.subplot(2, 3, 6)\nplt.imshow(lab[:, :, 0], cmap='gray')\nplt.title(\"LAB - Lightness Channel\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Color space info:\")\nprint(f\"RGB shape: {img_rgb.shape}\")\nprint(f\"Grayscale shape: {gray.shape}\")\nprint(f\"HSV shape: {hsv.shape}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-7-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nColor space info:\nRGB shape: (627, 1200, 3)\nGrayscale shape: (627, 1200)\nHSV shape: (627, 1200, 3)\n```\n:::\n:::\n\n\n## Your First Image Filters\n\nNow for the fun partâ€”applying filters to make your photos look amazing!\n\n### Blur Effects: Softening the World\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Convert to grayscale for cleaner examples\ngray_img = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n\n# Different types of blur\ngaussian_blur = cv2.GaussianBlur(gray_img, (15, 15), 0)\nmedian_blur = cv2.medianBlur(gray_img, 15)\nbilateral_blur = cv2.bilateralFilter(gray_img, 15, 80, 80)\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 4, 1)\nplt.imshow(gray_img, cmap='gray')\nplt.title(\"Original\")\nplt.axis('off')\n\nplt.subplot(1, 4, 2)\nplt.imshow(gaussian_blur, cmap='gray')\nplt.title(\"Gaussian Blur\\n(smooth)\")\nplt.axis('off')\n\nplt.subplot(1, 4, 3)\nplt.imshow(median_blur, cmap='gray')\nplt.title(\"Median Blur\\n(noise reduction)\")\nplt.axis('off')\n\nplt.subplot(1, 4, 4)\nplt.imshow(bilateral_blur, cmap='gray')\nplt.title(\"Bilateral Filter\\n(edge-preserving)\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\n### Sharpening: Making Everything Pop\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Create a sharpening kernel\nsharpening_kernel = np.array([\n    [0, -1, 0],\n    [-1, 5, -1],\n    [0, -1, 0]\n])\n\n# Apply the kernel\nsharpened = cv2.filter2D(gray_img, -1, sharpening_kernel)\n\n# Alternative: Unsharp masking (more sophisticated)\nblurred = cv2.GaussianBlur(gray_img, (0, 0), 2.0)\nunsharp_mask = cv2.addWeighted(gray_img, 1.5, blurred, -0.5, 0)\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 3, 1)\nplt.imshow(gray_img, cmap='gray')\nplt.title(\"Original\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(sharpened, cmap='gray')\nplt.title(\"Kernel Sharpening\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(unsharp_mask, cmap='gray')\nplt.title(\"Unsharp Masking\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-9-output-1.png){}\n:::\n:::\n\n\n## Building Your First Photo Editor\n\nLet's combine everything we've learned into a simple photo editor:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ndef photo_editor(image, operation='original', **kwargs):\n    \"\"\"A simple photo editor with multiple operations\"\"\"\n    \n    if operation == 'resize':\n        width = kwargs.get('width', 400)\n        return resize_with_aspect_ratio(image, width=width)\n    \n    elif operation == 'crop':\n        x, y, w, h = kwargs.get('crop_box', (100, 100, 300, 300))\n        return smart_crop(image, x, y, w, h)\n    \n    elif operation == 'rotate':\n        angle = kwargs.get('angle', 45)\n        return rotate_image(image, angle)\n    \n    elif operation == 'flip':\n        direction = kwargs.get('direction', 'horizontal')\n        if direction == 'horizontal':\n            return cv2.flip(image, 1)\n        elif direction == 'vertical':\n            return cv2.flip(image, 0)\n        else:\n            return cv2.flip(image, -1)\n    \n    elif operation == 'blur':\n        kernel_size = kwargs.get('kernel_size', 15)\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n        return cv2.cvtColor(blurred, cv2.COLOR_GRAY2RGB)\n    \n    elif operation == 'brightness':\n        value = kwargs.get('value', 50)\n        return np.clip(image.astype(np.int16) + value, 0, 255).astype(np.uint8)\n    \n    else:\n        return image\n\n# Demo the photo editor\noperations = [\n    ('original', {}),\n    ('resize', {'width': 300}),\n    ('rotate', {'angle': 15}),\n    ('brightness', {'value': 50}),\n    ('blur', {'kernel_size': 21}),\n    ('flip', {'direction': 'horizontal'})\n]\n\nplt.figure(figsize=(18, 12))\n\nfor i, (op, params) in enumerate(operations):\n    result = photo_editor(img_rgb, op, **params)\n    \n    plt.subplot(2, 3, i+1)\n    if len(result.shape) == 2:  # Grayscale\n        plt.imshow(result, cmap='gray')\n    else:\n        plt.imshow(result)\n    plt.title(f\"{op.title()}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\n## Real-World Applications\n\nNow you might be wondering: \"This is cool, but when would I actually use this?\" Here are some real examples:\n\n### 1. **Photo Processing Pipeline**\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ndef process_photo_batch(image_path):\n    \"\"\"Process a photo for social media\"\"\"\n    # Load image\n    img = cv2.imread(image_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    # Resize for Instagram (square format)\n    img_resized = resize_with_aspect_ratio(img_rgb, width=1080)\n    \n    # Center crop to square\n    h, w = img_resized.shape[:2]\n    size = min(h, w)\n    start_x = (w - size) // 2\n    start_y = (h - size) // 2\n    img_square = img_resized[start_y:start_y+size, start_x:start_x+size]\n    \n    # Apply slight blur for dreamy effect\n    img_final = cv2.GaussianBlur(img_square, (3, 3), 0)\n    \n    return img_final\n```\n:::\n\n\n### 2. **Document Scanner**\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\ndef scan_document(image):\n    \"\"\"Simple document scanner\"\"\"\n    # Convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    \n    # Apply adaptive thresholding (makes text crisp)\n    binary = cv2.adaptiveThreshold(\n        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n        cv2.THRESH_BINARY, 11, 2\n    )\n    \n    return binary\n\n# Try it on your image (if it has text)\nscanned = scan_document(img_rgb)\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original\")\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(scanned, cmap='gray')\nplt.title(\"Scanned Document\")\nplt.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\n## The Power of Combining Operations\n\nThe real magic happens when you combine multiple operations:\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ndef instagram_filter(image):\n    \"\"\"Create an Instagram-style vintage filter\"\"\"\n    # Step 1: Slight blur for dreamy effect\n    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n    \n    # Step 2: Increase saturation (convert to HSV)\n    hsv = cv2.cvtColor(blurred, cv2.COLOR_RGB2HSV)\n    hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.3, 0, 255)  # Boost saturation\n    enhanced = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n    \n    # Step 3: Warm color temperature (add yellow tint)\n    warm = enhanced.copy().astype(np.float32)\n    warm[:, :, 0] = np.clip(warm[:, :, 0] * 1.1, 0, 255)  # More red\n    warm[:, :, 1] = np.clip(warm[:, :, 1] * 1.05, 0, 255)  # More green\n    \n    return warm.astype(np.uint8)\n\n# Apply the filter\nfiltered = instagram_filter(img_rgb)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.imshow(img_rgb)\nplt.title(\"Original\")\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(filtered)\nplt.title(\"Instagram Filter\")\nplt.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\n## Your Homework: Build Something Cool!\n\nBefore we move to the next post, try these challenges:\n\n### ðŸŽ¯ **Challenge 1: Photo Collage Maker**\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndef create_collage(images, grid_size=(2, 2)):\n    \"\"\"Create a photo collage\"\"\"\n    rows, cols = grid_size\n    \n    # Resize all images to same size\n    target_size = (300, 300)\n    resized_images = []\n    \n    for img in images[:rows*cols]:  # Take only what we need\n        resized = cv2.resize(img, target_size)\n        resized_images.append(resized)\n    \n    # Create the collage\n    row_images = []\n    for r in range(rows):\n        row_imgs = resized_images[r*cols:(r+1)*cols]\n        if len(row_imgs) == cols:\n            row_combined = np.hstack(row_imgs)\n            row_images.append(row_combined)\n    \n    if len(row_images) == rows:\n        collage = np.vstack(row_images)\n        return collage\n    \n    return None\n\n# Try it with multiple copies of your image (or different images)\nimages = [img_rgb, cv2.flip(img_rgb, 1), rotate_image(img_rgb, 90), filtered]\ncollage = create_collage(images)\n\nif collage is not None:\n    plt.figure(figsize=(10, 10))\n    plt.imshow(collage)\n    plt.title(\"Your Photo Collage\")\n    plt.axis('off')\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-14-output-1.png){}\n:::\n:::\n\n\n### ðŸŽ¯ **Challenge 2: Color Palette Extractor**\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndef extract_dominant_colors(image, k=5):\n    \"\"\"Extract dominant colors from an image\"\"\"\n    # Reshape image to be a list of pixels\n    pixels = image.reshape(-1, 3)\n    pixels = np.float32(pixels)\n    \n    # Use k-means clustering to find dominant colors\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n    \n    # Convert back to uint8\n    centers = np.uint8(centers)\n    \n    return centers\n\n# Extract colors\ncolors = extract_dominant_colors(img_rgb)\n\n# Display the palette\nplt.figure(figsize=(12, 3))\nfor i, color in enumerate(colors):\n    plt.subplot(1, len(colors), i+1)\n    color_patch = np.full((100, 100, 3), color, dtype=np.uint8)\n    plt.imshow(color_patch)\n    plt.title(f\"RGB: {color}\")\n    plt.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](03-opencv-essentials_files/figure-html/cell-15-output-1.png){}\n:::\n:::\n\n\n## What's Next?\n\nIn our next post, [**\"Finding Patterns: Edges, Contours, and Shapes\"**](../04-finding-patterns/), we'll discover how computers find objects in images:\n\n- Edge detection (finding boundaries)\n- Contour detection (finding shapes)\n- Shape analysis (counting objects)\n- Your first object detector!\n\nYou now have a solid foundation in image manipulation. Next, we'll teach computers to *understand* what they're seeing!\n\n## Key Takeaways\n\n- **OpenCV is your Swiss Army knife** for computer vision\n- **Basic operations** (resize, crop, rotate, flip) are the building blocks\n- **Color spaces** give you different ways to analyze images\n- **Filters** can enhance or stylize your images\n- **Combining operations** creates powerful effects\n\n:::{.callout-tip}\n## Hands-On Lab\nReady to experiment with all these techniques? Try the complete interactive notebook: [**OpenCV Essentials Lab**](https://colab.research.google.com/github/hasanpasha/quarto_blog_hasan/blob/main/notebooks/cv-foundations-03-opencv-essentials.ipynb)\n\nUpload your own photos and build your own filters!\n:::\n\n:::{.callout-note}\n## Series Navigation\n- **Previous**: [Images as Data: How Computers See the World](02-images-as-data.qmd)\n- **Next**: [Finding Patterns: Edges, Contours, and Shapes](04-finding-patterns.qmd)\n- **Series Home**: [Computer Vision Foundations](../computer-vision-foundations.qmd)\n:::\n\n---\n\n*You've just mastered the essential tools of computer vision! In the next post, we'll use these tools to teach computers to find and recognize objects in images.* \n\n",
    "supporting": [
      "03-opencv-essentials_files"
    ],
    "filters": [],
    "includes": {}
  }
}